<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[PF4J循环依赖问题排查]]></title>
    <url>%2F2023%2F11%2F12%2FPF4J%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5%2F</url>
    <content type="text"><![CDATA[现象在线推理服务上线的过程中出现pf4j循环依赖的问题，同时有两个定时任务执行了插件加载的逻辑，并且都出现了org.pf4j.DependencyResolver$CyclicDependencyException: Cyclic dependencies pf4j01 现场处理方式：重启机器，算法包加载正常，推理流量执行正常 问题：pf4j中的dependencies指的是在plugin.properties中配置的依赖的其他插件，判责引擎算法包中并没有配置，为什么会出现循环依赖？ pf4j02 问题排查1、对插件操作加锁存在并发问题，可能同时加载多个算法包（或是对一个算法包重复加载） pf4j03 非原子性操作 pf4j04 2、pf4j是线程不安全的 在分析代码之前，我们先看下pf4j在解析依赖过程中的类图关系，neighbors（维护依赖之间关系的map）是Resolver的一个成员变量 pf4j05 很显然，问题是在加载插件的时候出现的，先看一下pf4j加载插件的代码org.pf4j.AbstractPluginManager#loadPlugin123456789101112131415public String loadPlugin(Path pluginPath) &#123; if ((pluginPath == null) || Files.notExists(pluginPath)) &#123; throw new IllegalArgumentException(String.format("Specified plugin %s does not exist!", pluginPath)); &#125; log.debug("Loading plugin from '&#123;&#125;'", pluginPath); // 加载、读取插件配置文件等，构建pluginWrapper PluginWrapper pluginWrapper = loadPluginFromPath(pluginPath); // 解析、加载插件的依赖 resolvePlugins(); return pluginWrapper.getDescriptor().getPluginId();&#125; 我们主要看下这一步resolvePlugins();org.pf4j.AbstractPluginManager#resolvePlugins1234567891011121314151617protected void resolvePlugins() &#123; // retrieves the plugins descriptors List&lt;PluginDescriptor&gt; descriptors = new ArrayList&lt;&gt;(); for (PluginWrapper plugin : plugins.values()) &#123; descriptors.add(plugin.getDescriptor()); &#125; // 这行代码是核心，后面会分析到 DependencyResolver.Result result = dependencyResolver.resolve(descriptors); // 这个异常是不是很眼熟了！全局唯一出现的地方 if (result.hasCyclicDependency()) &#123; throw new DependencyResolver.CyclicDependencyException(); &#125; // ......&#125; 紧接着看下什么情况会出现cyclicDependency为trueorg.pf4j.DependencyResolver.Result#Result123456789101112131415public boolean hasCyclicDependency() &#123; return cyclicDependency;&#125;Result(List&lt;String&gt; sortedPlugins) &#123; if (sortedPlugins == null) &#123; cyclicDependency = true; this.sortedPlugins = Collections.emptyList(); &#125; else &#123; this.sortedPlugins = new ArrayList&lt;&gt;(sortedPlugins); &#125; notFoundDependencies = new ArrayList&lt;&gt;(); wrongVersionDependencies = new ArrayList&lt;&gt;();&#125; 问题转换为寻找sortedPlugins为null情况，我们回到上面提到的这段核心代码，看看如何构造Result的org.pf4j.AbstractPluginManager#resolvePlugins1234567891011121314151617181920212223242526DependencyResolver.Result result = dependencyResolver.resolve(descriptors);org.pf4j.DependencyResolver#resolvepublic Result resolve(List&lt;PluginDescriptor&gt; plugins) &#123; dependenciesGraph = new DirectedGraph&lt;&gt;(); dependentsGraph = new DirectedGraph&lt;&gt;(); // populate graphs Map&lt;String, PluginDescriptor&gt; pluginByIds = new HashMap&lt;&gt;(); for (PluginDescriptor plugin : plugins) &#123; addPlugin(plugin); pluginByIds.put(plugin.getPluginId(), plugin); &#125; log.debug("Graph: &#123;&#125;", dependenciesGraph); // get a sorted list of dependencies List&lt;String&gt; sortedPlugins = dependenciesGraph.reverseTopologicalSort(); log.debug("Plugins order: &#123;&#125;", sortedPlugins); // create the result object Result result = new Result(sortedPlugins); // ...... return result;&#125; 紧抓矛盾点sortedPlugins，不要跟丢了！org.pf4j.util.DirectedGraph#reverseTopologicalSort12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public List&lt;V&gt; reverseTopologicalSort() &#123; List&lt;V&gt; list = topologicalSort(); if (list == null) &#123; return null; &#125; Collections.reverse(list); return list;&#125;public List&lt;V&gt; topologicalSort() &#123; // 初始化入度 Map&lt;V, Integer&gt; degree = inDegree(); // 初始化0入度栈，将入度为0的压入栈 Stack&lt;V&gt; zeroVertices = new Stack&lt;&gt;(); // stack as good as any here for (V v : degree.keySet()) &#123; if (degree.get(v) == 0) &#123; zeroVertices.push(v); &#125; &#125; // 拓扑排序的结果 List&lt;V&gt; result = new ArrayList&lt;&gt;(); while (!zeroVertices.isEmpty()) &#123; // 弹出一个0入度的元素，放入排序结果中 V vertex = zeroVertices.pop(); result.add(vertex); // 依赖当前0入度元素的入度-1 for (V neighbor : neighbors.get(vertex)) &#123; degree.put(neighbor, degree.get(neighbor) - 1); // 如果已经入度为0，压入0入度栈 if (degree.get(neighbor) == 0) &#123; zeroVertices.push(neighbor); &#125; &#125; &#125; // 找到出现null的地方了！！！ // 校验排序结果是否与插件元素图数量一致，如果不一致则为存在循环依赖 if (result.size() != neighbors.size()) &#123; return null; &#125; return result;&#125;/** * 初始化入度，如果没有依赖其他插件为0，依赖了一个插件即为1，依此类推 */public Map&lt;V, Integer&gt; inDegree() &#123; Map&lt;V, Integer&gt; result = new HashMap&lt;&gt;(); for (V vertex : neighbors.keySet()) &#123; result.put(vertex, 0); // all in-degrees are 0 &#125; for (V from : neighbors.keySet()) &#123; for (V to : neighbors.get(from)) &#123; result.put(to, result.get(to) + 1); // increment in-degree &#125; &#125; return result;&#125; 到这一步我们已经找到了result.size() != neighbors.size()就是出现插件循环依赖的直接原因，我们这行打上多线程debug断点，尝试本地复现一下：123456789101112131415public static void main(String[] args) &#123; // create the plugin manager PluginManager pluginManager = new DefaultPluginManager(); Path path = Paths.get("/Users/wusiqi14/Documents/temp/sj_plugin_framework/sj_algorithm_algorithm_deploy_demo-1.0.8-20231026.085014-8.zip"); Thread thread = new Thread(() -&gt; pluginManager.loadPlugin(path)); thread.setName("wsq01"); Thread thread1 = new Thread(() -&gt; pluginManager.loadPlugin(path)); thread1.setName("wsq02"); thread.start(); thread1.start();&#125; 多次运行代码后出现了预期的异常： pf4j06 可以看到，neighbors出现了并发问题，size为2但对应的entry只有一个 pf4j07 neighbors具体的实现是HashMap，在并发场景是有机会出现问题的1private Map&lt;V, List&lt;V&gt;&gt; neighbors = new HashMap&lt;&gt;(); 在本地测试过程中还出现了其他并发问题： pf4j08 unresolvedPlugins是AbstractPluginManager下的成员变量，对应的实现是线程不安全的ArrayList 问题修复 对插件管理对象pluginManager上全局锁 同时考虑到插件加载、回滚、删除三个定时任务，会出现并发获取锁失败的问题，所以可以把这3个操作放在一个定时任务里面处理 总结 pf4j是线程不安全的，涉及插件的操作都需要考虑这个问题 加锁过程需要是原子性的 目前对单个plugin加锁的方案是有问题的，因为DefaultPluginManager是所有插件共用的，即使修复上面对单个插件加锁的原子性，当面对一个服务部署多个算法包的时候，还是会出现并发的问题 附录拓扑排序：https://zhuanlan.zhihu.com/p/135094687]]></content>
      <categories>
        <category>问题排查</category>
      </categories>
      <tags>
        <tag>PF4J</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单元测试]]></title>
    <url>%2F2023%2F09%2F23%2F%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[浅谈单元测试这是单元测试吗？1234567891011121314151617181920212223@Log4j2@RunWith(SpringJUnit4ClassRunner.class)@SpringBootTest(classes = &#123;CpsApplication.class&#125;)public class FeatureServiceTest &#123; @Resource private FeatureService featureService; @Test public void getFeatureTest() &#123; // 构造入参 FeatureInputData featureInputData = new FeatureInputData(); featureInputData.setAlgoKey("AlgoKey"); featureInputData.setStrategyKey("StrategyKey"); featureInputData.setVersion("v0.0.1"); featureInputData.setFeatureType(FeatureTypeEnum.ALL); // 方法调用 FeatureOutputData featureData = featureService.getFeatureData(featureInputData); Assert.assertNotNull(featureData); &#125;&#125; 单元测试、集成测试的区别单元测试（模块测试）：是针对程序模块来进行正确性检验的测试工作，程序单元是应用的最小可测试部件。 在过程化编程中，一个单元就是单个程序、函数、过程等 对于面向对象编程，最小单元就是方法，包括基类、抽象类、或者派生类中的方法 集成测试：启动应用，连db等中间件。 系统级别测试：全链路，涉及的应用都要部署起来。包括端到端测试、链路测试、自动化回归测试、UI测试等。 单元测试 集成测试 系统级别测试 编写人员 开发 开发 开发 / 测试 编写场地 生产代码仓库内 生产代码仓库内 生产代码仓库内 / 生产代码仓库外 编写时间 代码发布前 代码发布前 代码发布前 / 代码发布后 编写成本 低 中 高 编写难度 低 中 高 反馈速度 极快，秒级 较慢，分钟级 慢，天级别 覆盖面积 代码行覆盖60-80% 分支覆盖40-60% 功能级别覆盖HappyPath 核心保障链路 环境依赖 代码级别，不依赖环境 依赖日常或本地环境 依赖预发或生产环境 外部依赖模拟 全部模拟 部分模拟 不模拟，完全使用真实环境 JunitJUint是Java编程语言的单元测试框架，用于编写和运行可重复的自动化测试。 Quick Start一个简单的目标测试方法：12345public class NumberUtil &#123; public static int add(int a, int b) &#123; return a + b; &#125;&#125; 引入maven依赖：123456&lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; 单元测试代码：12345678public class NumberUtilTest &#123; @Test public void addTest() &#123; int res = NumberUtil.add(1, 1); Assert.assertEquals("add方法结果异常", 2, res); &#125;&#125; @Test在junit4中，定义一个测试方法只需要在方法前加上@Test就行了。注意：测试方法必须是public void，即公共、无返回数据。可以抛出异常。 Junit提供的断言测试方法 断言 描述 void assertEquals([String message],expected value,actual value) 断言两个值相等 void assertTrue([String message],boolean condition) 断言一个条件为真 void assertFalse([String message],boolean condition) 断言一个条件为假 void assertNotNull([String message],java.lang.Object object) 断言一个对象不为空 void assertNull([String message],java.lang.Object object) 断言一个对象为空 void assertSame([String message],java.lang.Object expected,java.lang.Object actual) 断言两个对象引用相同的对象 void assertNotSame([String message],java.lang.Object unexpected,java.lang.Object actual) 断言两个对象不是引用同一个对象 void assertArrayEquals([String message],expectedArray,resultArray) 断言预期数组和结果数组相等 Junit生命周期123456789101112131415161718192021222324252627282930313233public class LifeCircleTest &#123; @BeforeClass public static void beforeClass() &#123; System.out.println("in before class"); &#125; @AfterClass public static void afterClass() &#123; System.out.println("in after class"); &#125; @Before public void before() &#123; System.out.println("in before"); &#125; @After public void after() &#123; System.out.println("in after"); &#125; @Test public void testCase() &#123; System.out.println("in test case"); &#125; @Test public void testCase() &#123; System.out.println("in test case"); &#125;&#125; 运行结果： unit_test01 异常测试1234567891011121314public class ExceptionTest &#123; @Test() public void exceptionTest() &#123; int a = 0; int b = 1 / a; &#125; @Test(expected = ArithmeticException.class) public void noExceptionTest() &#123; int a = 0; int b = 1 / a; &#125;&#125; 运行结果： unit_test02 超时时间测试123456789101112public class TimeoutTest &#123; @Test(timeout = 1000) public void timeoutFailTest() throws InterruptedException &#123; Thread.sleep(5000); &#125; @Test(timeout = 6000) public void timeoutSuccessTest() throws InterruptedException &#123; Thread.sleep(5000); &#125;&#125; 运行结果： unit_test03 Spring 单测1234567891011121314151617181920212223@Log4j2@RunWith(SpringJUnit4ClassRunner.class)@SpringBootTest(classes = &#123;CpsApplication.class&#125;)public class FeatureServiceTest &#123; @Resource private FeatureService featureService; @Test public void getFeatureTest() &#123; // 构造入参 FeatureInputData featureInputData = new FeatureInputData(); featureInputData.setAlgoKey("AlgoKey"); featureInputData.setStrategyKey("StrategyKey"); featureInputData.setVersion("v0.0.1"); featureInputData.setFeatureType(FeatureTypeEnum.ALL); // 方法调用 FeatureOutputData featureData = featureService.getFeatureData(featureInputData); Assert.assertNotNull(featureData); &#125;&#125; @Runwith就是放在测试类名之前，用来确定这个类怎么运行的。也可以不标注，会使用默认运行器JUnit4.class。 @RunWith(JUnit4.class) junit4的默认运行器 @RunWith(Parameterized.class) 参数化运行器，配合@Parameters使用junit的参数化功能 @RunWith(Suite.class) @SuiteClasses({ATest.class,BTest.class,CTest.class})测试集运行器配合使用测试集功能 @RunWith(SpringJUnit4ClassRunner.class)集成了spring的一些功能 … 其他能力参数化测试@RunWith(Parameterized.class)套件测试@RunWith(Suite.class)测试顺序@FixMethodOrder(MethodSorters.NAME_ASCENDING) Mockito什么是 Mock 测试我们在写单元测试时，总会遇到类似这些问题： 构造的入参，对于极值、异常边界场景不好复现，相关的逻辑测不到，只能依靠测试环境或预发跑，运气不好可能要改好几次代码重启机器验证，费时费力 依赖别人接口，可能需要别人协助测试环境数据库插数才能跑通 依赖的别人的接口还没有开发完，为了不影响提测，如何完成单元测试 编写的单元测试依赖测试数据库的数据，每次跑都要数据库改数 对service层加了逻辑，跑单元测试本地验证的时候，由于种种原因，本地环境跑不起来，折腾半天跑起来验证完了，下次开发需求又遇到了另一个问题本地环境启动报错 我就想dubug到某一行代码，但是逻辑复杂，东拼西凑的参数就是走不到，自己看代码逻辑还要去问别人接口的返回值逻辑 unit_test04 Mock有模仿、伪造的含义。Mock测试就是在测试过程中，对于某些不容易构造或者不容易获取的对象，用一个虚拟的对象来创建以便测试的测试方法。 为什么选择MockitoEasyMock与Mockito的对比文章：https://code.google.com/archive/p/mockito/wikis/MockitoVSEasyMock.wikiMockito官网的与EasyMock对比文章：https://github.com/mockito/mockito/wiki/Mockito-vs-EasyMock 其各有优劣，但主要还是Mockito的社区相对于其它Mock框架比较活跃。 Quick Start简单的目标测试方法：1234567public UserVO queryUserByUserId(Long userId) &#123; UserVO userVO = userDAO.queryByUserId(userId); if (userVO == null) &#123; log.warn("查询用户[&#123;&#125;]为空", userId); &#125; return userVO;&#125; 引入maven依赖：123456789101112&lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.mockito&lt;/groupId&gt; &lt;artifactId&gt;mockito-core&lt;/artifactId&gt; &lt;version&gt;3.7.7&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; 单元测试代码：123456789101112131415161718192021222324252627@RunWith(MockitoJUnitRunner.class)public class UserServiceTest &#123; /** mock依赖对象 */ @Mock private UserDAO userDAO; /** 测试对象 */ @InjectMocks private UserService userService; @Test public void queryUserByUserId_Succeed() &#123; // 构造出参 UserVO userVO = new UserVO(); userVO.setUserName("username"); userVO.setAge(18); // queryByUserId方法打桩 Mockito.doReturn(userVO).when(userDAO).queryByUserId(any()); // 实际测试方法 UserVO res = userService.queryUserByUserId(10000L); Assert.assertEquals(userVO.getUserName(), res.getUserName()); &#125;&#125; @InjectMocks作用于真实执行对象，即上文提及的A，针对实现类使用，不能作用在接口上。@Mock 作用于需要mock的对象，即上文提及的B、C，对其进行虚拟、伪造。any() 函数名 匹配类型 any() 所有对象类型 anyInt() 基本类型 int、非 null 的 Integer 类型 anyChar() 基本类型 char、非 null 的 Character 类型 anyShort() 基本类型 short、非 null 的 Short 类型 anyBoolean() 基本类型 boolean、非 null 的 Boolean 类型 anyDouble() 基本类型 double、非 null 的 Double 类型 anyFloat() 基本类型 float、非 null 的 Float 类型 anyLong() 基本类型 long、非 null 的 Long 类型 anyByte() 基本类型 byte、非 null 的 Byte 类型 anyString() String 类型(不能是 null) anyList() List&lt;T&gt; 类型(不能是 null) anyMap() Map&lt;K, V&gt;类型(不能是 null) anyCollection() Collection&lt;T&gt;类型(不能是 null) anySet() Set&lt;T&gt;类型(不能是 null) any(Class&lt;T&gt; type) type类型的对象(不能是 null) isNull() null isNotNull() 非 null PowerMock为什么需要PowerMock补充Mockito使用继承的方式实现mock的，用CGLIB生成mock对象代替真实的对象进行执行，所以无法mock私有方法、静态方法、Final方法。 PowerMock会根据你的mock要求，去修改写在注解@PrepareForTest里的class文件（当前测试类会自动加入注解中），以满足特殊的mock需求。例如：去除final方法的final标识，在静态方法的最前面加入自己的虚拟实现等。 Quick Start简单的目标测试方法1234public UserVO queryUser(Long userId) &#123; UserPO userPO = userDAO.queryByUser(userId); return UserServiceConverter.convertUserVo(userPO);&#125; 单元测试代码12345678910111213141516171819202122232425262728293031@RunWith(PowerMockRunner.class)@PrepareForTest( &#123; UserServiceConverter.class &#125;)public class UserServiceTest &#123; /** 模拟依赖对象 */ @Mock private UserDAO userDAO; /** 定义测试对象 */ @InjectMocks private UserService userService; @Test public void testQueryUser_Succeed() &#123; PowerMockito.mockStatic(UserServiceConverter.class); UserVO userVO = new EasyRandom().nextObject(UserVO.class); PowerMockito.when(UserServiceConverter.convertUserVo(Mockito.any())).thenReturn(userVO); UserPO userPO = new UserPO(); userPO.setUserName(userVO.getUserName()); userPO.setAge(userVO.getAge()); doReturn(userPO).when(userDAO).queryByUser(anyLong()); UserVO res = userService.queryUser(0L); Assert.assertEquals(userVO.getUserName(), res.getUserName()); &#125;&#125; @RunWith(PowerMockRunner.class)我们用了 PowerMockRunner ，MockitoJUnitRunner 就不能用了。但不要担心， @Mock 等注解还能用。@PrepareForTest告诉PowerMock准备测试某些类。需要使用此注释定义的类通常是需要进行字节码操作的类。这包括final类，带有final，private，static或本地方法的类，这些方法应该被mock，并且类应该在实例化时返回一个模拟对象。 工具easy-randomMock对象，构造pojo的每个属性，不需要自己逐个属性设置 引入maven依赖：123456&lt;dependency&gt; &lt;groupId&gt;org.jeasy&lt;/groupId&gt; &lt;artifactId&gt;easy-random-core&lt;/artifactId&gt; &lt;version&gt;4.2.0&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; 代码示例：123456@Testpublic void testQueryUser_Succeed() &#123; PowerMockito.mockStatic(UserServiceConverter.class); UserVO userVO = new EasyRandom().nextObject(UserVO.class); System.out.println(JSON.toJSONString(userVO));&#125; 运行结果： unit_test05 TestMeTestMe是Idea的插件，可以自动生成单元测试模板 unit_test06 Alt+Shift+Q选择Junit4&amp;Mockito生成模板： unit_test07 对于代码： unit_test08 生成的模板： unit_test09 本地查看单测覆盖率查看某个单测类的覆盖率： unit_test10 运行结果： unit_test11 查看某个包的单测覆盖率： unit_test12 单测实战我们结合下面这三个问题，一起来思考一下如何写一个好的单测： 需要写几个单元测试方法？ ValidationUtil.validate等方法需要mock吗？ 需要校验哪些参数？1234567891011121314151617181920212223242526/** * 查询用户 * * @param companyId 公司标识 * @param startIndex 开始序号 * @param pageSize 分页大小 * @return 用户分页数据 */public PageInfo&lt;UserVO&gt; queryUser(Long companyId, Long startIndex, Integer pageSize) &#123; //入参校验 if(ValidationUtil.validate(companyId))&#123; throw new IllegalArgumentException("Invalid company Id"); &#125; // 查询用户数据 // 查询用户数据: 总共数量 Long totalSize = userDAO.countByCompany(companyId); // 查询接口数据: 数据列表 List&lt;UserVO&gt; dataList = null; if (NumberHelper.isPositive(totalSize)) &#123; dataList = userDAO.queryByCompany(companyId, startIndex, pageSize); &#125; // 返回分页数据 return new PageInfo&lt;&gt;(dataList);&#125; 参考示例：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485@RunWith(MockitoJUnitRunner.class)public class UserServiceTest &#123; /** 模拟依赖对象 */ /** 用户DAO */ @Mock private UserDAO userDAO; /** 定义测试对象 */ /** 用户服务 */ @InjectMocks private UserService userService; /** * 测试: 查询用户-入参校验 */ @Test public void testQueryUser_Fail_WithBadInput() &#123; // 模拟依赖方法: userDAO.countByCompany Long companyId = 123L; Long startIndex = 90L; Integer pageSize = 10; Throwable throwable = catchThrowable(() -&gt; userService.queryUser(companyId, startIndex, pageSize)); Assert.assertTrue(throwable instanceof IllegalArgumentException); &#125; /** * 测试: 查询用户-无数据 */ @Test public void testQueryUser_Succeed_NoData() &#123; // 模拟依赖方法 // 模拟依赖方法: userDAO.countByCompany Long companyId = 12L; Long startIndex = 90L; Integer pageSize = 10; Mockito.doReturn(0L).when(userDAO).countByCompany(companyId); // 调用测试方法 PageInfo&lt;UserVO&gt; pageData = userService.queryUser(companyId, startIndex, pageSize); Assert.assertEquals(0, pageData.getSize()); // 验证依赖方法 // 验证依赖方法: userDAO.countByCompany Mockito.verify(userDAO).countByCompany(companyId); // 验证依赖对象 Mockito.verifyNoMoreInteractions(userDAO); &#125; /** * 测试: 查询用户-有数据 */ @Test public void testQueryUser_Succeed_WithData() &#123; // 模拟依赖方法: userDAO.countByCompany Long companyId = 12L; Mockito.doReturn(91L).when(userDAO).countByCompany(companyId); // 模拟依赖方法: userDAO.queryByCompany Long startIndex = 90L; Integer pageSize = 10; UserVO userVO = new EasyRandom().nextObject(UserVO.class); ArrayList&lt;UserVO&gt; userVOS = Lists.newArrayList(userVO); Mockito.doReturn(userVOS).when(userDAO).queryByCompany(companyId, startIndex, pageSize); // 调用测试方法 PageInfo&lt;UserVO&gt; pageData = userService.queryUser(companyId, startIndex, pageSize); Assert.assertEquals(1, pageData.getSize()); Assert.assertEquals(userVO.getUserName(), pageData.getList().get(0).getUserName()); Assert.assertEquals(userVO.getAge(), pageData.getList().get(0).getAge()); // 验证依赖方法 // 验证依赖方法: userDAO.countByCompany Mockito.verify(userDAO).countByCompany(companyId); // 验证依赖方法: userDAO.queryByCompany Mockito.verify(userDAO).queryByCompany(companyId, startIndex, pageSize); // 验证依赖对象 Mockito.verifyNoMoreInteractions(userDAO); &#125;&#125; 需要加上verify的原因： 验证mock的方法是否有调用及调用次数 入参是否正确 单元测试最佳实践【强制】单元测试需要写在各自模块下的test包下，路径与实际代码一致 【强制】单元测试覆盖率的统计是以执行过测试代码为准，假如有多个分支逻辑，单测里面必须覆盖所有逻辑 【强制】返回结果必须做断言判断，看情况判断具体字段，每层关注点不一样，最主要的是关注有效性，哪个地方容易出问题单元测试要更详细，单元测试的有效性保证代码质量 manager层：正常manager层只关心事务及缓存相关，若无特殊逻辑则简单校验即可 service层：重点为service层的逻辑分支需全部覆盖，关键字段、逻辑需判断是否符合预期 rpc层：需判断调用方的返回参数是否为空，校验必须字段是否符合预期。部分抛异常再自己捕获的不需要mock异常情况 带有属性转换的必须单独抽离到assember类，单元测试判断入参出参是否正确 provider层、mq层： 既要包含调用JSF的功能测试类，也要有单独Mock单元测试 带有属性转换的必须单独抽离到assember类，单元测试判断入参出参是否正确 对于JSF功能测试这种单元测试需要在类名加上@ignore注解，以免gitrunner执行这样的单元测试，避免浪费不必要的资源 api层：配置忽略，不需要写单元测试 domain层：配置忽略，不需要写单元测试 common层：对于工具类等需要单独写单元测试 【强制】核心业务、核心应用、核心模块的增量代码确保单元测试通过 【推荐】编写单元测试代码遵守BCDE原则，以保证被测试模块的交付质量 B:Border，边界值测试，包括循环边界、特殊取值、特殊时间点、数序等 C:Correct，正确的输入，并得到预期的结果 D:Design，与设计文档相结合，来编写单元测试 E:Error，强制错误信息输入(如:非法数据、异常流程、非业务允许输入等)，并得到预期的结果 【推荐】不要对单元测试存在如下误解 那是测试同学干的事情 单元测试代码不需要维护 单元测试与线上故障没有辩证关系 附录FIRST原则F-FAST(快速原则)单元测试应该是可以快速运行的，在各种测试方法中，单元测试的运行速度是最快的，通常应该在几分钟内运行完毕I-Independent(独立原则)单元测试应该是可以独立运行的，单元测试用例互相无强依赖，无对外部资源的强依赖R-Repeatable(可重复原则)单元测试应该可以稳定重复的运行，并且每次运行的结果都是相同的S-Self Validating(自我验证原则)单元测试应该是用例自动进行验证的，不能依赖人工验证T-Timely(及时原则）单元测试必须及时的进行编写，更新和维护，以保证用例可以随着业务代码的变化动态的保障质量 AIR原则A-Automatic(自动化原则)单元测试应该是自动运行，自动校验，自动给出结果I-Independent(独立原则)单元测试应该是独立运行，互相之间无依赖，对外部资源无依赖，多次运行之间无依赖R-Repeatable(可重复原则)单元测试是可重复运行的，每次的结果都稳定可靠 Junit注解说明@Test在junit3中，是通过对测试类和测试方法的命名来确定是否是测试，且所有的测试类必须继承junit的测试基类。在junit4中，定义一个测试方法变得简单很多，只需要在方法前加上@Test就行了。注意：测试方法必须是public void，即公共、无返回数据。可以抛出异常。 @Ignore有时候我们想暂时不运行某些测试方法\测试类，可以在方法前加上这个注解。在运行结果中，junit会统计忽略的用例数，来提醒你。 @BeforeClass当我们运行几个有关联的用例时，可能会在数据准备或其它前期准备中执行一些相同的命令，这个时候为了让代码更清晰，更少冗余，可以将公用的部分提取出来，放在一个方法里，并为这个方法注解@BeforeClass。意思是在测试类里所有用例运行之前，运行一次这个方法。例如创建数据库连接、读取文件等。注意：方法名可以任意，但必须是public static void，即公开、静态、无返回。这个方法只会运行一次。 @AfterClass跟@BeforeClass对应，在测试类里所有用例运行之后，运行一次。用于处理一些测试后续工作，例如清理数据，恢复现场。注意：同样必须是public static void，即公开、静态、无返回。这个方法只会运行一次。 @Before与@BeforeClass的区别在于，@Before不止运行一次，它会在每个用例运行之前都运行一次。主要用于一些独立于用例之间的准备工作。比如两个用例都需要读取数据库里的用户A信息，但第一个用例会删除这个用户A，而第二个用例需要修改用户A。那么可以用@BeforeClass创建数据库连接。用@Before来插入一条用户A信息。注意：必须是public void，不能为static。不止运行一次，根据用例数而定。 @After与@Before对应。 @Runwith 首先要分清几个概念：测试方法、测试类、测试集、测试运行器。 其中测试方法就是用@Test注解的一些函数。 测试类是包含一个或多个测试方法的一个Test.java文件。 测试集是一个suite，可能包含多个测试类。 测试运行器则决定了用什么方式偏好去运行这些测试集/类/方法。 而@Runwith就是放在测试类名之前，用来确定这个类怎么运行的。也可以不标注，会使用默认运行器。常见的运行器有： @RunWith(Parameterized.class) 参数化运行器，配合@Parameters使用junit的参数化功能 @RunWith(Suite.class) @SuiteClasses({ATest.class,BTest.class,CTest.class})测试集运行器配合使用测试集功能 @RunWith(JUnit4.class) junit4的默认运行器 @RunWith(JUnit38ClassRunner.class) 用于兼容junit3.8的运行器 一些其它运行器具备更多功能。例如@RunWith(SpringJUnit4ClassRunner.class)集成了spring的一些功能 @Parameters 用于使用参数化功能。]]></content>
      <categories>
        <category>单元测试</category>
      </categories>
      <tags>
        <tag>Junit</tag>
        <tag>Mockito</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[频繁FullGC问题排查]]></title>
    <url>%2F2023%2F08%2F02%2F%E9%A2%91%E7%B9%81FullGC%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5%2F</url>
    <content type="text"><![CDATA[现象当我们还沉浸在神机平台上线了第一个推理服务喜悦中，一个个报警打破了这个美丽的早上。伴随着早上的业务高峰，JVM频繁出现了FullGC的问题。大家都明白，对于Java程序猿来说，频繁FullGC是不能接受的，于是开启了我们问题排查之旅。 aviator1 结合着堆外内存起伏以及GC日志，不难发现是MetaSpace触发的FullGC。 aviator2 问题定位可以看到经过FullGC后MetaSpace内存是有回落的，那MetaSpace中的类满足什么条件才能够被当成垃圾被卸载回收呢？ 该类所有的实例都已经被回收 加载该类的ClassLoader已经被回收 该类对应的java.lang.Class对象没有被任何地方引用 依据上面的思路，我们dump出MetaSpace和heap aviator3 着重观察了一下Class对象的Incoming references，如下图： aviator4 可以看到存在接近8万个由Scrip_${timestamp}_${idx}类型的Class，且都指向了com.googlecode.aviator.ClassExpression，看到这里我们就看到了希望，由于AB分流的模块中使用了表达式引擎AviatorEvaluator，推测是有不停的动态创建类的过程，且类没有被回收，我们回到我们代码中继续探寻问题的根源。 这是编译表达式的入口：123456789101112131415161718192021/** * 编译流量框定表达式 * * @param express 流量表达式字符串 * @return 流量表达式 */@Overridepublic Expression checkExpress(String express) &#123; Expression expression = null; try &#123; expression = AviatorEvaluator.compile(express); &#125; catch (Exception e) &#123; log.error("编译流量框定表达式出现异常", e); &#125; return expression;&#125;public static Expression compile(String expression) &#123; // 可以看到默认是使用无缓存的策略进行编译的 return compile(expression, false);&#125; 继续跟进来compile方法，主要分为缓存和无缓存两个策略，我们先看下无缓存的入口innerCompile方法：123456789101112131415161718192021222324252627public Expression compile(final String expression, final boolean cached) &#123; if (expression != null &amp;&amp; expression.trim().length() != 0) &#123; if (cached) &#123; FutureTask&lt;Expression&gt; task = (FutureTask)this.cacheExpressions.get(expression); if (task != null) &#123; return this.getCompiledExpression(expression, task); &#125; else &#123; task = new FutureTask(new Callable&lt;Expression&gt;() &#123; public Expression call() throws Exception &#123; return AviatorEvaluatorInstance.this.innerCompile(expression, cached); &#125; &#125;); FutureTask&lt;Expression&gt; existedTask = (FutureTask)this.cacheExpressions.putIfAbsent(expression, task); if (existedTask == null) &#123; existedTask = task; task.run(); &#125; return this.getCompiledExpression(expression, existedTask); &#125; &#125; else &#123; // 走无缓存的方式 return this.innerCompile(expression, cached); &#125; &#125; else &#123; throw new CompileExpressionErrorException("Blank expression"); &#125;&#125; 编译过程主要分为文法分析、初始化编码生成器、预发解析器生成、预发解析这四个过程，不过和我们排查问题相关的主要是初始化编码生成器和预发解析两个阶段，所以我们也只看这个两个过程。1234567891011121314private Expression innerCompile(String expression, boolean cached) &#123; // 文法分析 ExpressionLexer lexer = new ExpressionLexer(this, expression); // 初始化编码生成器 CodeGenerator codeGenerator = this.newCodeGenerator(cached); // 预发解析器生成 ExpressionParser parser = new ExpressionParser(this, lexer, codeGenerator); // 预发解析，实例化Class，最终的Expression对象 Expression exp = parser.parse(); if (this.getOptionValue(Options.TRACE_EVAL).bool) &#123; ((BaseExpression)exp).setExpression(expression); &#125; return exp;&#125; 我们直接先看一下编码生成器的初始化阶段，这个过程主要是生成一个类加载器且封装成一个ASMCodeGenerator：1234567891011121314151617181920212223242526272829303132333435363738394041424344public CodeGenerator newCodeGenerator(boolean cached) &#123; AviatorClassLoader classLoader = this.getAviatorClassLoader(cached); return this.newCodeGenerator(classLoader);&#125;public AviatorClassLoader getAviatorClassLoader(boolean cached) &#123; // 无缓存策略都会创建一个AviatorClassLoader类加载器 return cached ? this.aviatorClassLoader : new AviatorClassLoader(Thread.currentThread().getContextClassLoader());&#125;public CodeGenerator newCodeGenerator(AviatorClassLoader classLoader) &#123; switch (this.getOptimizeLevel()) &#123; case 0: ASMCodeGenerator asmCodeGenerator = new ASMCodeGenerator(this, classLoader, this.traceOutputStream, this.getOptionValue(Options.TRACE).bool); asmCodeGenerator.start(); return asmCodeGenerator; case 1: // 默认走EVAL return new OptimizeCodeGenerator(this, classLoader, this.traceOutputStream, this.getOptionValue(Options.TRACE).bool); default: throw new IllegalArgumentException("Unknow option " + this.getOptimizeLevel()); &#125;&#125;public OptimizeCodeGenerator(AviatorEvaluatorInstance instance, ClassLoader classLoader, OutputStream traceOutStream, boolean trace) &#123; this.instance = instance; this.codeGen = new ASMCodeGenerator(instance, (AviatorClassLoader)classLoader, traceOutStream, trace); this.trace = trace;&#125;public ASMCodeGenerator(AviatorEvaluatorInstance instance, AviatorClassLoader classLoader, OutputStream traceOut, boolean trace) &#123; this.currentLabel = START_LABEL; this.l0stack = new Stack(); this.l1stack = new Stack(); this.methodMetaDataStack = new ArrayDeque(); this.classLoader = classLoader; this.instance = instance; this.compileEnv = new Env(); this.compileEnv.setInstance(this.instance); // 看到这有没有觉得很熟悉了呢，没错，这就是我们在MAT中看到的class this.className = "Script_" + System.currentTimeMillis() + "_" + CLASS_COUNTER.getAndIncrement(); this.classWriter = new ClassWriter(2); this.visitClass();&#125; 紧跟着看下语法解析阶段，这也是创建Class和Expression对象的地方了：12345678910111213141516171819202122232425262728293031public Expression parse() &#123; this.statement(); if (this.lookhead != null) &#123; this.reportSyntaxError("Unexpect token '" + this.currentTokenLexeme() + "'"); &#125; // 主要看下这个实例化方法 return this.codeGenerator.getResult();&#125;public Expression getResult() &#123; this.end(); byte[] bytes = this.classWriter.toByteArray(); try &#123; // 这里就是生成Class对象的地方了 Class&lt;?&gt; defineClass = ClassDefiner.defineClass(this.className, Expression.class, bytes, this.classLoader); Constructor&lt;?&gt; constructor = defineClass.getConstructor(AviatorEvaluatorInstance.class, List.class); ClassExpression exp = (ClassExpression)constructor.newInstance(this.instance, new ArrayList(this.varTokens.keySet())); exp.setLambdaBootstraps(this.lambdaBootstraps); exp.setFuncsArgs(this.funcsArgs); return exp; &#125; catch (ExpressionRuntimeException var5) &#123; throw var5; &#125; catch (Throwable var6) &#123; if (var6.getCause() instanceof ExpressionRuntimeException) &#123; throw (ExpressionRuntimeException)var6.getCause(); &#125; else &#123; throw new CompileExpressionErrorException("define class error", var6); &#125; &#125;&#125; 柳暗花明又一村！可以得出我们的结论了，无缓存的策略下，每次编译表达式都会创建一个ClassLoader和Class，因而MetaSpace的空间会逐步被占满。 问题解决问题的解决方案也很简单，我们使用上带缓存的编译方法就可以了！12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * 编译流量框定表达式 * * @param express 流量表达式字符串 * @return 流量表达式 */@Overridepublic Expression checkExpress(String express) &#123; Expression expression = null; try &#123; // 看这里！ expression = AviatorEvaluator.compile(express, true); &#125; catch (Exception e) &#123; log.error("编译流量框定表达式出现异常", e); &#125; return expression;&#125;public static Expression compile(String expression, boolean cached) &#123; return getInstance().compile(expression, cached);&#125;我们继续刨根问底，看看使用缓存的策略是如何生成Expression的：public Expression compile(final String expression, final boolean cached) &#123; if (expression != null &amp;&amp; expression.trim().length() != 0) &#123; if (cached) &#123; // 从缓存中取 FutureTask&lt;Expression&gt; task = (FutureTask)this.cacheExpressions.get(expression); if (task != null) &#123; return this.getCompiledExpression(expression, task); &#125; else &#123; task = new FutureTask(new Callable&lt;Expression&gt;() &#123; public Expression call() throws Exception &#123; // 还是调用无缓存策略的innerCompile方法 return AviatorEvaluatorInstance.this.innerCompile(expression, cached); &#125; &#125;); // 将结果放入缓存中 FutureTask&lt;Expression&gt; existedTask = (FutureTask)this.cacheExpressions.putIfAbsent(expression, task); if (existedTask == null) &#123; existedTask = task; task.run(); &#125; return this.getCompiledExpression(expression, existedTask); &#125; &#125; else &#123; return this.innerCompile(expression, cached); &#125; &#125; else &#123; throw new CompileExpressionErrorException("Blank expression"); &#125;&#125; 在使用了缓存的策略后，MetaSpace保持稳定，也没有出现频繁FullGC的情况了，至此我们的问题排查，优化过程就告一段落啦～ aviator5 aviator6 总结在我们开发的过程中，不可避免的要接触一些陌生的框架，我们并不排斥新的东西，但我们在使用前要了解其是如何实现的、有什么优劣势，即使做不到知其所以然，我们也可以度娘一下其他人是如何使用的，有哪些可能会踩什么的坑！汲取前人的教训，我们会在保障系统稳定性的道路上，走的更加的安心和舒心～]]></content>
      <categories>
        <category>问题排查</category>
      </categories>
      <tags>
        <tag>FullGC</tag>
        <tag>MetaSpace</tag>
        <tag>aviator</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程阻塞问题排查]]></title>
    <url>%2F2023%2F08%2F02%2F%E7%BA%BF%E7%A8%8B%E9%98%BB%E5%A1%9E%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5%2F</url>
    <content type="text"><![CDATA[现象线上服务机器，没有生产日志，JSF接口状态正常 问题通过jstack发现异常1234567891011121314151617181920212223242526272829&quot;JSF-BZ-22000-22-T-552&quot; #908 daemon prio=5 os_prio=0 tid=0x00007f925c02c000 nid=0x28dcf waiting for monitor entry [0x00007f8cc82c0000] java.lang.Thread.State: BLOCKED (on object monitor) at org.apache.logging.log4j.core.appender.OutputStreamManager.writeBytes(OutputStreamManager.java:352) - waiting to lock &lt;0x00000006c09d6730&gt; (a org.apache.logging.log4j.core.appender.OutputStreamManager)// ...&quot;JSF-BZ-22000-22-T-335&quot; #691 daemon prio=5 os_prio=0 tid=0x00007f9270016800 nid=0x28811 runnable [0x00007f9187af9000] java.lang.Thread.State: RUNNABLE at java.io.FileOutputStream.writeBytes(Native Method) at java.io.FileOutputStream.write(FileOutputStream.java:326) at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122) - locked &lt;0x00000006c056d8a0&gt; (a java.io.BufferedOutputStream) at java.io.PrintStream.write(PrintStream.java:480) - locked &lt;0x00000006c052f620&gt; (a java.io.PrintStream) at org.apache.logging.log4j.core.util.CloseShieldOutputStream.write(CloseShieldOutputStream.java:53) at org.apache.logging.log4j.core.appender.OutputStreamManager.writeToDestination(OutputStreamManager.java:250) - locked &lt;0x00000006c09d6730&gt; (a org.apache.logging.log4j.core.appender.OutputStreamManager) at org.apache.logging.log4j.core.appender.OutputStreamManager.flushBuffer(OutputStreamManager.java:283) - locked &lt;0x00000006c09d6730&gt; (a org.apache.logging.log4j.core.appender.OutputStreamManager) at org.apache.logging.log4j.core.appender.OutputStreamManager.drain(OutputStreamManager.java:343) at org.apache.logging.log4j.core.layout.TextEncoderHelper.drainIfByteBufferFull(TextEncoderHelper.java:258) - locked &lt;0x00000006c09d6730&gt; (a org.apache.logging.log4j.core.appender.OutputStreamManager) at org.apache.logging.log4j.core.layout.TextEncoderHelper.writeAndEncodeAsMuchAsPossible(TextEncoderHelper.java:197) at org.apache.logging.log4j.core.layout.TextEncoderHelper.encodeChunkedText(TextEncoderHelper.java:157) - locked &lt;0x00000006c09d6730&gt; (a org.apache.logging.log4j.core.appender.OutputStreamManager) Locked ownable synchronizers: - &lt;0x0000000703465430&gt; (a java.util.concurrent.ThreadPoolExecutor$Worker) 可以看到几乎所有杰夫线程在都被阻塞在OutputStreamManager.writeBytes上，等待锁释放。 在 https://issues.apache.org/jira/browse/LOG4J2-880 上找到了答案，大概意思是记录日志的时候，如果往控制台打印输出日志的话，会把日志写入缓存，控制台会从缓存中取，但比如控制台没取，这时候控制台会暂停输出，不从缓存中取东西，缓存内容就不会清，日志程序会一直往里写，直到写满，线程就会停止写入，等待缓存可用，表现在程序里，就是writeBytes函数不返回，持有的锁不释放。 部署在docker中的时候，因为docker容器会一直获取标准输出的内容，自己记录docker日志，但是当缓存中的东西比较多的时候，比如日志长度特别长，docker没办法及时清空缓存，也会导致log4j出现这个问题。 解决方案生产系统中无需往标准输入输出写日志，将日志配置文件中ConsoleAppender组件去除，问题得以解决。]]></content>
      <categories>
        <category>问题排查</category>
      </categories>
      <tags>
        <tag>JSF</tag>
        <tag>Log4J</tag>
        <tag>线程池</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[频繁young gc问题排查]]></title>
    <url>%2F2023%2F08%2F02%2F%E9%A2%91%E7%B9%81young-gc%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5%2F</url>
    <content type="text"><![CDATA[现象实习生对新开发的推理接口进行压测时，发现tp99异常，大概在9000ms左右 acr1 young gc也十分频繁，还伴随着2次的full gc acr2 cpu使用率也飙升到了100% acr3 问题通过jstask发现大量线程处于CaseFormat.convert方法中12345678910111213&quot;JSF-BZ-22000-23-T-110&quot; #247 daemon prio=5 os_prio=0 tid=0x00007fb0d8110800 nid=0x527 runnable [0x00007faf366ed000] java.lang.Thread.State: RUNNABLE at java.util.Arrays.copyOfRange(Arrays.java:3664) at java.lang.String.&lt;init&gt;(String.java:207) at java.lang.StringBuilder.toString(StringBuilder.java:407) at com.google.common.base.CaseFormat.convert(CaseFormat.java:150) at com.google.common.base.CaseFormat.to(CaseFormat.java:128) at com.jd.jdl.sj.acr.utils.JDBCUtils.Populate(JDBCUtils.java:184) at com.jd.jdl.sj.acr.mapper.RecommendedMapper.queryByAssociateData(RecommendedMapper.java:87) at com.jd.jdl.sj.acr.algo.AcrAlgoStrategyA.predict(AcrAlgoStrategyA.java:73) at com.jd.jdl.sj.acr.algo.AcrAlgoStrategyB.predict(AcrAlgoStrategyB.java:56) at com.jd.jdl.sj.predict.service.impl.AlgoServiceImpl.predict(AlgoServiceImpl.java:26) at com.jd.jdl.sj.predict.service.impl.AlgoServiceImpl$$FastClassBySpringCGLIB$$211fefd6.invoke(&lt;generated&gt;) 且jmap中发现jvm内存中存在大量String对象 acr4 最终定位到问题代码123456789101112131415161718192021222324252627282930313233343536public static List Populate(ResultSet rs, Class cc) throws SQLException, InstantiationException, IllegalAccessException &#123; try &#123; //结果集 中列的名称和类型的信息 ResultSetMetaData rsm = rs.getMetaData(); int colNumber = rsm.getColumnCount(); List res = new ArrayList(); Field[] fields = cc.getDeclaredFields(); //遍历每条记录 while (rs.next()) &#123; //实例化对象 Object obj = cc.newInstance(); //取出每一个字段进行赋值 for (int i = 1; i &lt;= colNumber; i++) &#123; Object value = rs.getObject(i); //匹配实体类中对应的属性 for (Field f : fields) &#123; // 驼峰转下划线命名 String name = CaseFormat.LOWER_CAMEL.to(CaseFormat.LOWER_UNDERSCORE, f.getName()); if (name.equals(rsm.getColumnName(i))) &#123; boolean flag = f.isAccessible(); f.setAccessible(true); f.set(obj, value); f.setAccessible(flag); break; &#125; &#125; &#125; res.add(obj); &#125; return res; &#125; catch (Exception e) &#123; throw new BusinessException(); &#125;&#125; 这段代码是通过jdbc查询结果后，需要将ResultSet映射成pojo中的结果。主要问题出在这行驼峰转下划线的代码中：1String name = CaseFormat.LOWER_CAMEL.to(CaseFormat.LOWER_UNDERSCORE, f.getName()); 查询一次数据库大概返回400行数据，每条数据25个字段，一次查询就会执行2.5w次这行代码，创建出2.5w个String。 解决方案将驼峰转下划线前置，这样一次调用只会执行25次这个方法。123456789101112131415161718192021222324252627282930313233343536373839public static List Populate(ResultSet rs, Class cc) throws SQLException, InstantiationException, IllegalAccessException &#123; try &#123; List res = new ArrayList(); Field[] fields = cc.getDeclaredFields(); Map&lt;String, Field&gt; fieldMap = new HashMap&lt;&gt;(fields.length); for (Field field : fields) &#123; String fieldUnderscoreName = CaseFormat.LOWER_CAMEL.to(CaseFormat.LOWER_UNDERSCORE, field.getName()); fieldMap.put(fieldUnderscoreName, field); &#125; //结果集 中列的名称和类型的信息 ResultSetMetaData rsm = rs.getMetaData(); //遍历每条记录 while (rs.next()) &#123; //实例化对象 Object obj = cc.newInstance(); //取出每一个字段进行赋值 for (int i = 1; i &lt;= rsm.getColumnCount(); i++) &#123; Object value = rs.getObject(i); String columnName = rsm.getColumnName(i); Field field = fieldMap.get(columnName); if (field == null) &#123; continue; &#125; // boolean flag = field.isAccessible(); field.setAccessible(true); field.set(obj, value); // field.setAccessible(flag); &#125; res.add(obj); &#125; return res; &#125; catch (Exception e) &#123; throw new BusinessException(); &#125;&#125; 压测结果性能大幅提升，tp99在20ms以下。 acr5]]></content>
      <categories>
        <category>问题排查</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>young-gc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[加载catboost模型导致Java进程异常退出]]></title>
    <url>%2F2023%2F08%2F01%2F%E5%8A%A0%E8%BD%BDcatboost%E6%A8%A1%E5%9E%8B%E5%AF%BC%E8%87%B4Java%E8%BF%9B%E7%A8%8B%E5%BC%82%E5%B8%B8%E9%80%80%E5%87%BA%2F</url>
    <content type="text"><![CDATA[现象在对catboost模型（大小1g）做切换测试的时候，出现Java进程异常退出的情况。 JVM监控：内存稳定，且没有出现FullGC，没有发生oom catboost1 MDC监控：cpu使用率接近70%，内存使用率接近100% catboost2 怀疑使用了堆外内存，导致容器内存打满。排查加载catboost模型代码，发现catboost提供sdk中loadModel方法调用了JNI，推测在native方法中申请了内存。 1234567891011121314151617public static CatBoostModel loadModel(InputStream in) throws CatBoostError, IOException &#123; long[] handles = new long[1]; byte[] copyBuffer = new byte[4096]; ByteArrayOutputStream out = new ByteArrayOutputStream(); int bytesRead; while((bytesRead = in.read(copyBuffer)) != -1) &#123; out.write(copyBuffer, 0, bytesRead); &#125; implLibrary.catBoostLoadModelFromArray(out.toByteArray(), handles); return new CatBoostModel(handles[0]);&#125;final void catBoostLoadModelFromArray(@NotNull byte[] data, @NotNull long[] handle) throws CatBoostError &#123; CatBoostJNIImpl.checkCall(CatBoostJNIImpl.catBoostLoadModelFromArray(data, handle));&#125; 调整堆外内存大小调整机器配置8c12g -&gt; 8c16gJVM堆内存参数配置不变（即堆外内存增大4g）-Xms9632M-Xmx9632M JVM监控： catboost3 MDC监控： catboost4 模型切换次数由原来的1、2次，提升到7次才出现Java进程异常退出的情况，基本可以确定堆外内存搞的鬼了。 主动释放模型资源在CatBoostModel对象被回收的时候，finalize方法中会自己调用dispose方法，释放资源1234567891011121314protected void finalize() throws Throwable &#123; try &#123; this.dispose(); &#125; finally &#123; super.finalize(); &#125;&#125;private synchronized void dispose() throws CatBoostError &#123; if (this.handle != 0L) &#123; implLibrary.catBoostFreeModel(this.handle); this.handle = 0L; &#125;&#125; 不过我们还是在加载新模型后，尝试主动调用释放旧模型，即增加oldModel.close()代码12345678910111213141516171819public void convert(String modelKey, InputStream inputStream) &#123; try &#123; CatBoostModel catBoostModel = CatBoostModel.loadModel(inputStream); CatBoostModel oldModel = modelMap.get(modelKey); modelMap.put(modelKey, catBoostModel); if(Objects.nonNull(oldModel))&#123; log.info("释放catboost资源"); oldModel.close(); &#125; log.info("CatBoost init model ：&#123;&#125; success！", modelKey); &#125; catch (Exception e) &#123; log.error("CatBoost init model ：&#123;&#125; fail！ exception ：", modelKey, e); throw new BusinessException("CatBoost模型加载失败"); &#125;&#125;public void close() throws CatBoostError &#123; this.dispose();&#125; JVM监控 catboost5 MDC监控 catboost6 还是一样存在内存泄漏的问题。 NMT定位内存区域 可以展示堆内内存、Code区域或者使用unsafe.allocateMemory和DirectByteBuffer申请的堆外内存JVM启动参数增加：-XX:NativeMemoryTracking=detail 查看命令：jcmd pid VM.native_memory detail 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849[admin@host-11-68-72-16 ~]$ jcmd 217 VM.native_memory detail217:Native Memory Tracking:Total: reserved=11242880KB, committed=9746476KB- Java Heap (reserved=8839168KB, committed=8839168KB) (mmap: reserved=8839168KB, committed=8839168KB) - Class (reserved=1176337KB, committed=143121KB) (classes #23536) (malloc=2833KB #43400) (mmap: reserved=1173504KB, committed=140288KB) - Thread (reserved=437769KB, committed=437769KB) (thread #425) (stack: reserved=435872KB, committed=435872KB) (malloc=1400KB #2133) (arena=498KB #849)- Code (reserved=548090KB, committed=84902KB) (malloc=15610KB #19166) (mmap: reserved=532480KB, committed=69292KB) - GC (reserved=62053KB, committed=62053KB) (malloc=36149KB #493) (mmap: reserved=25904KB, committed=25904KB) - Compiler (reserved=1664KB, committed=1664KB) (malloc=1533KB #2248) (arena=131KB #3)- Internal (reserved=38055KB, committed=38055KB) (malloc=38023KB #89946) (mmap: reserved=32KB, committed=32KB) - Symbol (reserved=29710KB, committed=29710KB) (malloc=27017KB #264972) (arena=2693KB #1)- Native Memory Tracking (reserved=6936KB, committed=6936KB) (malloc=261KB #3929) (tracking overhead=6675KB)- Arena Chunk (reserved=190KB, committed=190KB) (malloc=190KB) - Unknown (reserved=102908KB, committed=102908KB) (mmap: reserved=102908KB, committed=102908KB) 可以发现Native Memory Tracking中，只分配了6m的空间，我们更加相信是Native Code（C代码）申请的堆外内存导致的问题。 系统层面的工具定位堆外内存pmap 显示进程的地址空间的相关信息 切换前 catboost7 切换后 catboost8 对比切换前后进程分配的内存空间，可以看到每次loadModel会增加700m的内存，而且旧模型申请的空间也没有释放。 strace 我们可以用它来监控用户空间进程和内核的交互。如对应用程序的系统调用、信号传递与进程状态变更等进行跟踪与分析，以达到解决问题的目的。 catboost9 通过strace监控，切换模型过程中申请内存的命令，可以看到申请了差不多700m内存，可以与上面pmap对应上。 /proc/pid/smaps我们通过pmap已经发现了可疑的内存区间，在/proc/pid/smaps可以找到分配内存块的起始地址和结束地址 catboost10 gdb通过gdb对可疑内存区间进行dump catboost11 编码可视化其内容，进行分析，可以看到是模型相关的 catboost12 catboost13 catboost14 github相似issuehttps://github.com/catboost/catboost/issues/1979]]></content>
      <categories>
        <category>问题排查</category>
      </categories>
      <tags>
        <tag>内存泄露</tag>
        <tag>堆外内存</tag>
        <tag>JNI</tag>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git merge与rebase对比]]></title>
    <url>%2F2023%2F01%2F01%2Fgit-merge%E4%B8%8Erebase%E5%AF%B9%E6%AF%94%2F</url>
    <content type="text"><![CDATA[写在开篇对于很多同学来说，对于git工具的使用只是停留在最基础的几条命令或者是几个按钮上，对于普通的开发工作来说可能是够用了，但对于想高效的利用好git这个实战利器来说，显然是需要再精进提升的。 今天我们将从代码合并这个角度，为大家讲解git中merge与rebase的区别，使用场景等。 区别初始场景假设目前我们有两个分支，main和feature，同时两个分支的head指针都指向add ClassB这个提交节点上，如下图所示。 git00 无分叉情况下合并对于第一种情况，main分支新增一个提交，其head指针指向add ClassC提交节点上，而feature分支的仍然停留在add ClassB上。 git01 此时我们希望在feature分支上将main分支上的最新提交合并过来，此时对于两个分支来说，它们是没有分叉的，merge默认会采用的策略是fast-forward，即快速将feature的head指针移动到add ClassC上。 git02 有分叉情况下合并对于下图，main和feature分支中出现了分叉的情况，如果想要将main中的提交合并到feature中，我们应该怎么做呢？ git03 merge对于之前没有了解过rebase的我们来说，我们通过merge来将main中提交的ClassC合并到feature来，我们会在ClassE节点后新增一个merge结点，放到自己的最后面，如下图所示。 git04 而这个merge节点，它是main分支上更改的合并，即不管main分支上多少个提交节点，都会合并成一个节点。 rebase但如果通过rebase合并后，feature分支的提交还是在最后，就好像从节点ClassC中拉出来的一样，此时相对于main分支没有分叉。 git05 优缺点上述两个例子很清晰的提现了merge和rebase的区别和作用，简单来说： merge保留了作品的完整历史记录，包括按时间顺序排列；对于回滚等操作也更有优势 Rebase使提交变得整洁，不会产生嘈杂的提交 使用场景merge 对于多个人开发同一个模块，很可能他的某个改动会导致你的功能出问题，如果出了问题，保留记录能便于后期排查问题 main分支需要将开发完的子分支的内容合并进来，使用merge可以留有提交记录，出现问题方便后面排查问题 rebase个人开发分支同步main最新提交应该使用rebase，该模块的内容更新和你功能无关，合并代码也不会影响你的功能，无需保留该记录 巨人的肩膀：https://www.bilibili.com/video/BV1cv411u7wd/?spm_id_from=333.788.recommend_more_video.2&amp;vd_source=7c8b86fff4f4354960fa30b9be566d0e]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>merge</tag>
        <tag>rebase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在线debug日志]]></title>
    <url>%2F2022%2F12%2F25%2F%E5%9C%A8%E7%BA%BFdebug%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[写在开篇最近工作中涉及实时算法工程框架相关的开发，由于发现实时预测的结果和线下预测结果有偏差，需要向业务提供接口调用过程中的debug日志，供其分析排查问题。 但在茫茫的日志海洋中搂取日志对于业务来说压力比较大，因此我们提出通过对目前预测接口进行包装，提供测试能力，在接口出参返回整个接口调用过程中的debug日志的方案。 这个过程中将利用我们上一篇博客中介绍的log4j2的插件，实现了这个有趣的小功能。如果大家对于log4j2插件功能还不熟悉，可以先阅读我的上一篇文章。 整体思路首先，我们梳理一下思路，这个功能需要处理predict()业务接口输出日志的位置，所以我们可以通过实现appender插件获取到业务日志，再将每次调用的日志收集保存下来，而对于这个场景，大家会不约而同的想到ThreadLocal，整体的流程如下图所示。 debuglog01 我们再回顾一下这个过程，对于简单的同步业务场景，应该是没有什么问题了，但如果业务接口中存在异步逻辑，该怎么处理呢？ debuglog02 结合上面这张图，我给大家介绍一下我的思路。1、生成一个uuid作为一次接口调用tracekey，且存入MDC中。2、每次追加日志时，会先获取MDC中的uuid，将日志放入其对应本地缓存中3、在业务接口调用结束的时候，根据MDC中的uuid，获取本地缓存中的日志4、清除MDC中的uuid 需要注意的是，上述处理流程只能处理异步后在方法调用结束之前会阻塞获取异步调用结果的场景，对于异步处理的流程，个人觉得是没有返回debug日志的必要。 需要注意的点对于测试接口的请求，才需要返回debug日志，否则会影响接口正常调用的性能 需要对接口来源进行打标，而且考虑到子线程的使用，需要通过TransmittableThreadLocal来传递标记，而且对于使用的线程池，需要使用TtlExecutors对线程池包装一下 log4j2的MDC或ThreadContext子线程中取不到父线程的标记，需要在配置文件中加上1isThreadContextMapInheritable=true 具体代码实现Appender12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152@Log4j2@Plugin(name = "LogAppender", category = "Core", elementType = "appender", printObject = true)public class LogAppender extends AbstractAppender &#123; /** * debug日志bean */ private static final String DEBUG_LOG_SERVICE = "debugLogService"; public LogAppender(String name, Filter filter, Layout&lt;? extends Serializable&gt; layout, boolean ignoreExceptions) &#123; super(name, filter, layout, ignoreExceptions); &#125; @Override public void append(LogEvent logEvent) &#123; if (Boolean.FALSE.equals(ThreadLocalLogUtil.getIsLog())) &#123; // 不需要记录调用日志 return; &#125; if (logEvent == null) &#123; return; &#125; String traceKey = ThreadContext.get(OsConstant.THEAD_CONTEXT_TRACE_KEY); if (StringUtils.isBlank(traceKey)) &#123; return; &#125; final byte[] bytes = getLayout().toByteArray(logEvent); String log = new String(bytes); Object serviceObj = SpringBeanUtils.getBean(DEBUG_LOG_SERVICE); if (serviceObj instanceof DebugLogService) &#123; DebugLogService debugLogService = (DebugLogService) serviceObj; debugLogService.appendDebugLog(traceKey, log); &#125; &#125; // 下面这个方法可以接收配置文件中的参数信息 @PluginFactory public static LogAppender createAppender( @PluginAttribute("name") String name, @PluginElement("Filter") final Filter filter, @PluginElement("Layout") Layout&lt;? extends Serializable&gt; layout, @PluginAttribute("ignoreExceptions") boolean ignoreExceptions) &#123; if (StringUtils.isBlank(name)) &#123; log.error("No name provided for LogAppenderImpl"); return null; &#125; if (layout == null) &#123; layout = PatternLayout.createDefaultLayout(); &#125; return new LogAppender(name, filter, layout, ignoreExceptions); &#125;&#125; 这里需要注意一个上下文的问题，log4j2在dao层、service层初始化结束之前就已经初始化了，如果采用@Resource这种依赖注入的方式构建bean是行不通的，获取到的只能是null，但是ApplicationContext已经加载，可以通过ApplicationContext手动获取bean。 Aspect为了降低对业务代码的侵入、以及兼顾代码的可拓展性，对接口调用的打标，接口返回debugLog等过程就通过切面实现了。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869@Aspect@Component@Log4j2public class LogAspect &#123; @Resource private DebugLogService debugLogService; @Around("execution(* com.kyrie.predict.service.AService.predict(..))") public Object doAround(ProceedingJoinPoint pjp) throws Throwable &#123; setIsLogFlag(pjp); Object result = null; try &#123; result = pjp.proceed(); &#125; catch (Exception e) &#123; log.error("LogAspect-doAround-e:", e); throw e; &#125; finally &#123; addDebugLog(result); &#125; return result; &#125; /** * ThreadLocal设置是否返回debug日志标签 * @param pjp */ private void setIsLogFlag(ProceedingJoinPoint pjp) &#123; Boolean isLogFlag = Boolean.FALSE; Object[] args = pjp.getArgs(); if (args != null &amp;&amp; args.length &gt; 0) &#123; Object arg = args[0]; if (arg instanceof OsInputData) &#123; OsInputData osInputData = (OsInputData) arg; String source = osInputData.getSource(); if (StringUtils.isNotBlank(source) &amp;&amp; OsConstant.SOURCE_SJ_DEBUG.equals(source)) &#123; isLogFlag = Boolean.TRUE; &#125; &#125; &#125; log.info("打印debug日志：&#123;&#125;", isLogFlag); ThreadLocalLogUtil.setIsLog(isLogFlag); &#125; /** * 返回结果设置debugLog * @param result */ private void addDebugLog(Object result) &#123; if (!ThreadLocalLogUtil.getIsLog()) &#123; return; &#125; String traceKey = ThreadContext.get(OsConstant.THEAD_CONTEXT_TRACE_KEY); if (StringUtils.isNotBlank(traceKey)) &#123; if (result == null) &#123; result = new OsOutputData(); &#125; if (result instanceof OsOutputData) &#123; OsOutputData osOutputData = (OsOutputData) result; List&lt;String&gt; debugLog = debugLogService.getDebugLog(traceKey); osOutputData.setDebugLogs(debugLog); &#125; debugLogService.removeDebugLog(traceKey); &#125; ThreadLocalLogUtil.remove(); &#125;&#125; 这里有个地方可能会遗漏，对于这个接口的产生的异常，我们也是需要进行捕获，同时追加到返回debug日志中的。 log4j2.xml123456789101112131415161718192021222324252627282930&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;Configuration status="WARN" monitorInterval="3600"&gt; &lt;Appenders&gt; &lt;!-- ... --&gt; &lt;LogAppender name="logAppender"&gt; &lt;ThresholdFilter level="info" onMatch="ACCEPT" onMismatch="DENY"/&gt; &lt;PatternLayout pattern="%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125;[%-5level]%m[%C.%M:%L][%X&#123;traceKey&#125;]- %n" /&gt; &lt;/LogAppender&gt; &lt;/Appenders&gt; &lt;Loggers&gt; &lt;!-- ... --&gt; &lt;!-- 需要返回debug日志 --&gt; &lt;logger name="com.kyrie.predict" level="debug" additivity="true"&gt; &lt;appender-ref ref="logAppender" /&gt; &lt;/logger&gt; &lt;!-- 配置日志的根节点 --&gt; &lt;root level="info"&gt; &lt;appender-ref ref="console"/&gt; &lt;appender-ref ref="file" /&gt; &lt;appender-ref ref="error" /&gt; &lt;/root&gt; &lt;/Loggers&gt;&lt;/Configuration&gt; 这里还有个需要注意的地方是debug日志的logger需要将additivity置为true，不影响根日志的正常输出，关于配置的属性详情，可以参考我的上一篇文章。]]></content>
      <categories>
        <category>Java乐园</category>
      </categories>
      <tags>
        <tag>log</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[日志框架log4j]]></title>
    <url>%2F2022%2F11%2F21%2F%E6%97%A5%E5%BF%97%E6%A1%86%E6%9E%B6log4j%2F</url>
    <content type="text"><![CDATA[写在开篇本文主要介绍了log4j、xml方式的配置以及插件的使用。 sl4j与log4j关系slf4j不是具体的日志解决方案，而是一种适配器的实现方式，为我们提供一个一致的API，开发者只需要关注slf4j的api接口，而不用关心具体日志是由log4j、log4j2还是logback等日志框架实现的。 log4j1 适配过程上面讲到sl4j是适配层，那么它是怎么适配到日志框架的呢？我们一起通过源码来看一下。 12345678910111213package com.demo.log; import org.slf4j.Logger;import org.slf4j.LoggerFactory; public class LogDemo &#123; // 调用slf4j的api，首先我们需要获它的logger private static final Logger LOGGER = LoggerFactory.getLogger(LogDemo.class); public static void main(String[] args) &#123; LOGGER.info("log4j2"); &#125;&#125; LoggerFactory类中获取logger的方法。 1234567891011121314151617181920212223242526272829303132333435363738public static Logger getLogger(Class&lt;?&gt; clazz) &#123; Logger logger = getLogger(clazz.getName()); // ... return logger;&#125;public static Logger getLogger(String name) &#123; ILoggerFactory iLoggerFactory = getILoggerFactory(); return iLoggerFactory.getLogger(name);&#125; // 获取ILoggerFactorypublic static ILoggerFactory getILoggerFactory() &#123; // 双重校验锁创建单例的LoggerFactory if (INITIALIZATION_STATE == UNINITIALIZED) &#123; Class var0 = LoggerFactory.class; synchronized(LoggerFactory.class) &#123; if (INITIALIZATION_STATE == UNINITIALIZED) &#123; INITIALIZATION_STATE = ONGOING_INITIALIZATION; // 初始化ILoggerFactory的核心方法 performInitialization(); &#125; &#125; &#125; switch (INITIALIZATION_STATE) &#123; case ONGOING_INITIALIZATION: return SUBST_FACTORY; case FAILED_INITIALIZATION: throw new IllegalStateException("org.slf4j.LoggerFactory in failed state."); case SUCCESSFUL_INITIALIZATION: return StaticLoggerBinder.getSingleton().getLoggerFactory(); case NOP_FALLBACK_INITIALIZATION: return NOP_FALLBACK_FACTORY; default: throw new IllegalStateException("Unreachable code"); &#125;&#125; 初始化ILoggerFactory。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758private static final void performInitialization() &#123; bind(); if (INITIALIZATION_STATE == SUCCESSFUL_INITIALIZATION) &#123; versionSanityCheck(); &#125;&#125;private static final void bind() &#123; String msg; try &#123; Set&lt;URL&gt; staticLoggerBinderPathSet = null; if (!isAndroid()) &#123; // 找出绑定的日志的path，即StaticLoggerBinder.class文件 staticLoggerBinderPathSet = findPossibleStaticLoggerBinderPathSet(); // 我们只需要一个实现的日志框架，如果有多个要上报 reportMultipleBindingAmbiguity(staticLoggerBinderPathSet); &#125; // 实例化StaticLoggerBinder StaticLoggerBinder.getSingleton(); INITIALIZATION_STATE = SUCCESSFUL_INITIALIZATION; reportActualBinding(staticLoggerBinderPathSet); fixSubstituteLoggers(); replayEvents(); SUBST_FACTORY.clear(); &#125; catch (NoClassDefFoundError var2) &#123; // ... &#125; catch (Exception var4) &#123; // ... &#125;&#125;// 找到所有的StaticLoggerBinderstatic Set&lt;URL&gt; findPossibleStaticLoggerBinderPathSet() &#123; Set&lt;URL&gt; staticLoggerBinderPathSet = new LinkedHashSet(); try &#123; // 获取LoggerFactory，即slf4j-api的类加载器 ClassLoader loggerFactoryClassLoader = LoggerFactory.class.getClassLoader(); Enumeration paths; if (loggerFactoryClassLoader == null) &#123; // 说明是由Bootstrap Classloader加载的，则转为App Classloader去加载 paths = ClassLoader.getSystemResources(STATIC_LOGGER_BINDER_PATH); &#125; else &#123; // 用slf4j的Classloader去加载 paths = loggerFactoryClassLoader.getResources(STATIC_LOGGER_BINDER_PATH); &#125; while(paths.hasMoreElements()) &#123; URL path = (URL)paths.nextElement(); staticLoggerBinderPathSet.add(path); &#125; &#125; catch (IOException var4) &#123; Util.report("Error getting resources from path", var4); &#125; return staticLoggerBinderPathSet;&#125; 看到这我们已经可以知道，各个日志框架是通过实现org/slf4j/impl/StaticLoggerBinder来对sl4j进行适配的。下图是log4j2实现的StaticLoggerBinder。 log4j2 从类加载器的用法可以看出org/slf4j/impl/StaticLoggerBinder.class要和slf4j-api.jar包在同一个类加载器中，一般来说即要求放在同一路径下比较稳妥。 我们来浅窥下log4j2中对于StaticLoggerBinder的具体实现。 123456789101112131415161718192021222324252627package org.slf4j.impl;import org.apache.logging.slf4j.Log4jLoggerFactory;import org.slf4j.ILoggerFactory;import org.slf4j.spi.LoggerFactoryBinder;public final class StaticLoggerBinder implements LoggerFactoryBinder &#123; public static String REQUESTED_API_VERSION = "1.6"; private static final String LOGGER_FACTORY_CLASS_STR = Log4jLoggerFactory.class.getName(); private static final StaticLoggerBinder SINGLETON = new StaticLoggerBinder(); private final ILoggerFactory loggerFactory = new Log4jLoggerFactory(); private StaticLoggerBinder() &#123; &#125; public static StaticLoggerBinder getSingleton() &#123; return SINGLETON; &#125; public ILoggerFactory getLoggerFactory() &#123; return this.loggerFactory; &#125; public String getLoggerFactoryClassStr() &#123; return LOGGER_FACTORY_CLASS_STR; &#125;&#125; 我们只需要关心，log4j2是通过Log4jLoggerFactory继承了ILoggerFactory、以及Log4jLogger继承了Logger，来实现适配到slf4j的即可。 log4j2配置关于日志我们一开始不免会关心两个问题：1、开发时日志是怎么输出到控制台，生产环境的日志是怎么输出的磁盘文件中的？2、日志输出的格式为什么是这样的？ 那我们就需要介绍下log4j2的配置了。 log4j2.xmllog4j2支持xml、json、yaml、properties四种配置方式，不过本文将通过大家常用的xml方式来介绍。 我们通过这个简单的xml配置来介绍。 12345678910111213141516171819202122&lt;Configuration name="ConfigTest" status="ERROR" monitorInterval="5"&gt; &lt;Appenders&gt; &lt;SystemPropertyArbiter propertyName="env" propertyValue="dev"&gt; &lt;Console name="Out"&gt; &lt;PatternLayout pattern="%m%n"/&gt; &lt;/Console&gt; &lt;/SystemPropertyArbiter&gt; &lt;SystemPropertyArbiter propertyName="env" propertyValue="prod"&gt; &lt;List name="Out"&gt; &lt;/List&gt; &lt;/SystemPropertyArbiter&gt; &lt;/Appenders&gt; &lt;Loggers&gt; &lt;Logger name="org.apache.test" level="trace" additivity="false"&gt; &lt;AppenderRef ref="Out"/&gt; &lt;/Logger&gt; &lt;Root level="error"&gt; &lt;AppenderRef ref="Out"/&gt; &lt;/Root&gt; &lt;/Loggers&gt;&lt;/Configuration&gt; 可以看到，同体上来说，主要Configuration构成分为两个部分。 Appender 通过appender指定一个日志的输出方式，目前支持的Appender主要有Console、File、RollingFile、Async、Routing等 Console 将日志打印到控制台 name 指定Appender的名字 target SYSTEM_OUT或SYSTEM_ERR PatternLayout pattern指定输出格式，不设置默认为:%m%n File 将日志打印到文件 name 指定Appender的名字 filename 指定输出日志的目的文件带全路径的文件名 PatternLayout pattern指定输出格式，不设置默认为:%m%n RollingFile 将日志打印到文件，文件可以滚动保存 name 指定Appender的名字 filename 指定输出日志的目的文件带全路径的文件名 filepattern 指定新建日志文件的名称格式 filePermissions 指定日志文件权限 PatternLayout pattern指定输出格式，不设置默认为:%m%n Policies 指定滚动日志的策略（支持基于时间、指定文件大小等滚动策略） Routing 指定日志路由，可以指定规则与Appender进行绑定 name 指定Appender的名字 pattern 根据所有注册的Lookups进行评估并将结果用于选择路由 Logger 指定logger与appeder进行关联，将logger中的日志输出到appender，由appender实现日志的控制台输出或者文件记录。 Root 用来指定项目的根日志 level 日志输出级别 AppenderRef 用来指定该日志输出到哪个Appender Logger 自定义的子日志 level 日志输出级别 name 用来指定该Logger所适用的类或者类所在的包全路径,继承自Root节点 additivity 日志是否在父Logger中输出，如果为false，只在自定义的Appender中进行输出 AppenderRef 用来指定该日志输出到哪个Appender,如果没有指定，就会默认继承自Root log4j2插件在我们的自定义插件上需要使用@Plugin表明此时一个log4j2的插件，定义插件的名称和属性。 1@Plugin(name = "MyAppender", category = "Core", elementType = "layout", printObject = true) log4j为我们提供了Core、Converters、KeyProviders、Lookups、TypeConverters、Developer Notes等几种插件方式，我们下面将选取几个有代表性的为大家详细说明。 Core Core插件是指那些由配置文件中的元素直接表示的插件，例如Appender、Layout、Logger或Filter。 在介绍core插件之前，先需要了解以下三个注解。 @PluginFactory用于提供所有选项作为方法参数的静态工厂方法，即可以将xml中配置属性传递进方法中 @PluginAttribute 插件的属性 @PluginElement 插件的子元素 自定义appender插件支持自定义appender：即指定日志输出目的地。 1、需要用@PluginFactory声明createAppender方法，创建一个Appender，2、继承AbstractAppender，实现append方法，处理日志 在使用场景上，可以应用至将分布式服务的单机上日志输出到统一的机器上。 1234567891011121314151617181920212223242526272829303132333435@Log4j2@Plugin(name = "TestLogAppender", category = Node.CATEGORY, elementType = Appender.ELEMENT_TYPE, printObject = true)public class TestLogAppender extends AbstractAppender &#123; public TestLogAppender(String name, Filter filter, Layout&lt;? extends Serializable&gt; layout, boolean ignoreExceptions) &#123; super(name, filter, layout, ignoreExceptions); &#125; @Override public void append(LogEvent logEvent) &#123; if (logEvent == null) &#123; return; &#125; final byte[] bytes = getLayout().toByteArray(logEvent); String log = new String(bytes); rpcService.doLog(log); &#125; // 下面这个方法可以接收配置文件中的参数信息 @PluginFactory public static TestLogAppender createAppender( @PluginAttribute("name") String name, @PluginElement("Filter") final Filter filter, @PluginElement("Layout") Layout&lt;? extends Serializable&gt; layout, @PluginAttribute("ignoreExceptions") boolean ignoreExceptions) &#123; if (StringUtils.isBlank(name)) &#123; log.error("No name provided for TestLogAppender"); return null; &#125; if (layout == null) &#123; layout = PatternLayout.createDefaultLayout(); &#125; return new TestLogAppender(name, filter, layout, ignoreExceptions); &#125;&#125; 12345678910111213141516171819202122232425&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;Configuration status="WARN" monitorInterval="3600"&gt; &lt;Appenders&gt; &lt;!-- 控制台输出 --&gt; &lt;Console name="console" target="SYSTEM_OUT"&gt; &lt;ThresholdFilter level="debug" onMatch="ACCEPT" onMismatch="DENY"/&gt; &lt;!-- 输出日志的格式 --&gt; &lt;PatternLayout pattern="%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread]] %-5level %logger&#123;36&#125; %F:%L - %msg %ex%n"/&gt; &lt;/Console&gt;&gt; &lt;TestLogAppender name="testLogAppender" append="true" &gt; &lt;ThresholdFilter level="info" onMatch="ACCEPT" onMismatch="DENY"/&gt; &lt;PatternLayout pattern="%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125;[%-5level]%m[%C.%M:%L]" /&gt; &lt;/TestLogAppender&gt; &lt;/Appenders&gt; &lt;Loggers&gt; &lt;!-- 配置日志的根节点 --&gt; &lt;root level="info"&gt; &lt;appender-ref ref="console"/&gt; &lt;appender-ref ref="testLogAppender" /&gt; &lt;/root&gt; &lt;/Loggers&gt;&lt;/Configuration&gt; 自定义layout插件支持自定义layout：即负责对输出日志格式化。 1、需要用@PluginFactory声明createAppender方法，创建一个Appender2、继承AbstractAppender，实现toSerializable方法，处理日志 在使用场景上，可以替换日志中的敏感信息。123456789101112131415161718192021222324252627282930313233343536373839404142@Plugin(name = "Log4jEncodeLayout", category = Node.CATEGORY, elementType = Layout.ELEMENT_TYPE, printObject = true)public class Log4jEncodeLayout extends AbstractStringLayout &#123; /** * 手机号正则匹配式 */ private final static Pattern PHONE_PATTERN = Pattern.compile("(?&lt;![0-9a-zA-Z])1[345789]\d&#123;9&#125;(?![0-9a-zA-Z])"); private PatternLayout patternLayout; protected Log4jEncodeLayout(Charset charset, String pattern) &#123; //调用父类设置基本参数 super(charset); //PatternLayout 是原本的输出对象，用来获取到原本要输出的日志字符串 patternLayout = PatternLayout.newBuilder().withPattern(pattern).build(); &#125; @Override public String toSerializable(LogEvent event) &#123; // 调用原本的 toSerializable 方法，获取到原本要输出的日志 String message = patternLayout.toSerializable(event); // 在原本输出的字符串上做正则匹配过滤 Matcher match = PHONE_PATTERN.matcher(message); StringBuffer sb = new StringBuffer(); while (match.find()) &#123; match.appendReplacement(sb, "***"); &#125; match.appendTail(sb);// 增加 // 将脱敏后的日志输出 return sb.toString(); &#125; //定义插件传入的参数 @PluginFactory public static Layout createLayout( @PluginAttribute(value = "pattern") final String pattern, @PluginAttribute(value = "charset") final Charset charset) &#123; return new Log4jEncodeLayout(charset, pattern); &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;Configuration status="INFO" name="XMLConfigTest" packages="org.apache.logging.log4j.test,com.zyx.demo"&gt; &lt;Properties&gt; &lt;Property name="PATTERN"&gt; %d&#123;yyyy-MM-dd HH:mm:ss SSS&#125; [%p] [c=%c&#123;1&#125;] [%thread] %m%n &lt;/Property&gt; &lt;property name="MODULE_NAME"&gt;log4j2-demo&lt;/property&gt; &lt;property name="LOG_HOME"&gt;/data&lt;/property&gt; &lt;/Properties&gt; &lt;Appenders&gt; &lt;Console name="STDOUT"&gt; &lt;!--&lt;PatternLayout&gt;--&gt; &lt;!-- &lt;pattern&gt;$&#123;PATTERN&#125;&lt;/pattern&gt;--&gt; &lt;!--&lt;/PatternLayout&gt;--&gt; &lt;!--将原先的日志输出替换为自定义的日志输出appender插件--&gt; &lt;Log4jEncodeLayout pattern="$&#123;PATTERN&#125;" charset="UTF-8"/&gt; &lt;/Console&gt; &lt;RollingFile name="ROLLINGFILE" fileName="$&#123;LOG_HOME&#125;/$&#123;MODULE_NAME&#125;.log" filePattern="$&#123;LOG_HOME&#125;/log/$&#123;MODULE_NAME&#125;-%d&#123;yyyy-MM-dd&#125;-%i.log.gz"&gt; &lt;!--&lt;PatternLayout--&gt; &lt;!--pattern="[$&#123;MODULE_NAME&#125;] %d&#123;yyyy-MM-dd HH:mm:ss SSS&#125; [%p] [c=%c&#123;1&#125;] [%thread] %m%n"/&gt;--&gt; &lt;!--将原先的日志输出替换为自定义的日志输出appender插件--&gt; &lt;Log4jEncodeLayout pattern="[$&#123;MODULE_NAME&#125;] %d&#123;yyyy-MM-dd HH:mm:ss SSS&#125; [%p] [c=%c&#123;1&#125;] [%thread] %m%n" charset="UTF-8"/&gt; &lt;Policies&gt; &lt;TimeBasedTriggeringPolicy modulate="true" interval="1" /&gt; &lt;SizeBasedTriggeringPolicy size="100MB"/&gt; &lt;CronTriggeringPolicy schedule="0 0 * * * ?"/&gt; &lt;/Policies&gt; &lt;DefaultRolloverStrategy max="100"&gt; &lt;Delete basePath="$&#123;LOG_HOME&#125;" maxDepth="3"&gt; &lt;IfFileName glob="*/$&#123;MODULE_NAME&#125;-*.log.gz"/&gt; &lt;IfLastModified age="30d"/&gt; &lt;/Delete&gt; &lt;/DefaultRolloverStrategy&gt; &lt;/RollingFile&gt; &lt;/Appenders&gt; &lt;Loggers&gt; &lt;Root level="INFO"&gt; &lt;AppenderRef ref="STDOUT"/&gt; &lt;AppenderRef ref="ROLLINGFILE"/&gt; &lt;/Root&gt; &lt;/Loggers&gt;&lt;/Configuration&gt; LookupsLookups自定义插件支持对属性的key进行查找功能。而且自定义操作过程也很简单，只需要实现StrLookup，实现lookup方法。 在下面这个不同线程打印日志例子中我们看到Lookups的简单应用。 1234567891011121314@Plugin(name = "threadName", category = StrLookup.CATEGORY)public class ThreadName implements StrLookup &#123; // 插件的功能即根据key值获取相应结果，这里我们直接返回线程名字 @Override public String lookup(String key) &#123; return Thread.currentThread().getName(); &#125; @Override public String lookup(LogEvent event, String key) &#123; return event.getThreadName() == null ? Thread.currentThread().getName() : event.getThreadName(); &#125;&#125; 1234567891011121314151617181920212223242526272829&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;Configuration name="log-demo-config" status="error" monitorInterval="10"&gt; &lt;Appenders&gt; &lt;!-- 默认保留Console,用于控制台日志输出 --&gt; &lt;Console name="Console" target="SYSTEM_OUT"&gt; &lt;PatternLayout pattern="[%d&#123;yyyy-MM-dd;HH:mm:ss.SSS Z&#125;] [%-5p] [%t] [%c] %m%n"&gt;&lt;/PatternLayout&gt; &lt;/Console&gt; &lt;Routing name="Routing"&gt; &lt;Routes pattern="$$&#123;threadName:threadName&#125;"&gt; &lt;Route&gt; &lt;RollingFile name="RollingFile-$&#123;threadName:threadName&#125;" fileName="export\log\thread-$&#123;threadName:threadName&#125;.log" filePattern="export\log\thread-$&#123;threadName:threadName&#125;-%i.log"&gt; &lt;PatternLayout pattern="[%d&#123;yyyy-MM-dd HH:mm:ss,SSS Z&#125;] [%-5p] [%t] [%c %L] %m%n"/&gt; &lt;Policies&gt; &lt;SizeBasedTriggeringPolicy size="10 MB" /&gt; &lt;/Policies&gt; &lt;DefaultRolloverStrategy max="10"/&gt; &lt;/RollingFile&gt; &lt;/Route&gt; &lt;/Routes&gt; &lt;/Routing&gt; &lt;/Appenders&gt; &lt;Loggers&gt; &lt;Logger name="com.demo.log" level="INFO" additivity="false"&gt; &lt;AppenderRef ref="Routing"&gt;&lt;/AppenderRef&gt; &lt;/Logger&gt; &lt;/Loggers&gt;&lt;/Configuration&gt; 巨人的肩膀：https://logging.apache.org/log4j/2.x/https://blog.csdn.net/numb_zl/category_11244831.htmlhttps://blog.csdn.net/huangjinjin520/article/details/120600251https://blog.csdn.net/zyx1260168395/article/details/126539475]]></content>
      <categories>
        <category>Java乐园</category>
      </categories>
      <tags>
        <tag>log</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二分查找算法]]></title>
    <url>%2F2020%2F12%2F07%2F%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[写在开篇二分模板一共有两个，分别适用于不同情况。 满足某个条件的第一个数当我们将区间[l, r]划分成[l, mid]和[mid + 1, r]时，其更新操作是r = mid或者l = mid + 1;，计算mid时不需要加1。12345678910int bsearch_1(int l, int r)&#123; while (l &lt; r) &#123; int mid = l + r &gt;&gt; 1; if (check(mid)) r = mid; else l = mid + 1; &#125; return l;&#125; 满足某个条件的最后一个数当我们将区间[l, r]划分成[l, mid - 1]和[mid, r]时，其更新操作是r = mid - 1或者l = mid;，此时为了防止死循环，计算mid时需要加1。12345678910int bsearch_2(int l, int r)&#123; while (l &lt; r) &#123; int mid = l + r + 1 &gt;&gt; 1; if (check(mid)) l = mid; else r = mid - 1; &#125; return l;&#125; 当我们将区间[l, r]划分成[r, mid - 1]和[mid, r]时，其更新操作是r = mid - 1或l = mid，此时为防止死循环，计算mid时需要+1，即： 二分查找01 选择二分只有上述两种情况： 找大于等于给定数的第一个数 找小于等于给定数的最后一个数 二分查找02 下面给一个对比的例子（leetcode34）：Given an array of integers nums sorted in ascending order, find the starting and ending position of a given target value.If target is not found in the array, return [-1, -1].Follow up: Could you write an algorithm with O(log n) runtime complexity? 123Example 1:Input: nums = [5,7,7,8,8,10], target = 8Output: [3,4] 思路：分别找出第一次出现的位置和最后一次出现的位置，即分别对应模板1和模板2。123456789101112131415161718192021222324252627282930class Solution &#123; public int[] searchRange(int[] nums, int target) &#123; if (nums == null || nums.length == 0) return new int[] &#123;-1, -1&#125;; int l = 0, r = nums.length - 1; while (l &lt; r) &#123; int mid = l + r &gt;&gt; 1; if (nums[mid] &gt;= target) r = mid; else l = mid + 1; &#125; if (nums[l] != target) return new int[] &#123;-1, -1&#125;; int start = l; l = 0; r = nums.length - 1; while (l &lt; r) &#123; int mid = l + r + 1 &gt;&gt; 1; if (nums[mid] &lt;= target) l = mid; else r = mid - 1; &#125; int end = r; return new int[] &#123;start, end&#125;; &#125;&#125; 巨人的肩膀： acwing.com]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>二分</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[心跳包设计]]></title>
    <url>%2F2020%2F11%2F29%2F%E5%BF%83%E8%B7%B3%E5%8C%85%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[一个socket长连接长连接会存在以下两种情况： 一个客户端连接服务器以后，如果长期没有和服务器有数据来往，可能会被防火墙程序关闭连接，有时候我们并不想要被关闭连接。要求必须保持客户端与服务器之间的连接正常，就是我们通常所说的保活 通常情况下，服务器与某个客户端一般不是位于同一个网络，其之间可能经过数个路由器和交换机，如果其中某个必经路由器或者交换器出现了故障，并且一段时间内没有恢复，导致这之间的链路不再畅通，而此时服务器与客户端之间也没有数据进行交换，由于TCP连接是状态机，对于这种情况，无论是客户端或者服务器都无法感知与对方的连接是否正常，这类连接我们一般称之为死链 根据上面的分析，可以看到，心跳检测一般有两个作用： 保活 检测死链 TCP keepalive选项熟悉socket编程的读者可能会熟悉下面的这个方法：12345public void setKeepAlive(boolean on) throws SocketException &#123; if (isClosed()) throw new SocketException("Socket is closed"); getImpl().setOption(SocketOptions.SO_KEEPALIVE, Boolean.valueOf(on));&#125; setKeepAlive字面意思是保持活着，这个方法也确实是提供用来保持一个TCP连接的，但是为什么我们在设计一个通信系统的时候往往不会直接使用这个方法呢，而是自己实现一个保活机制，不推荐使用SO_KEEPALIVE为什么呢？ 我们通过了解TCPKeepAlive的原理，来找到这个问题的答案。 TCP内嵌有心跳包，以服务端为例,当server检测到超过一定时间(2小时)没有数据传输，那么会向client端发送一个keepalive packet，此时client端有三种反应: client端连接正常,返回一个ACK。server端收到ACK后重置计时器，在2小时后在发送探测。如果2小时内连接上有数据传输，那么在该时间的基础上向后推延2小时发送探测包 客户端异常关闭，或网络断开。client无响应，server收不到ACK，在一定时间(75秒)后重发keepalive packet, 并且重发一定次数(9次) 客户端曾经崩溃，但已经重启。server收到的探测响应是一个复位(reset)，server端终止连接 注意：两个小时才会发一次。也就是说，在没有实际数据通信的时候，我把网线拔了，你的应用程序要经过两个小时才会知道。 应用层的心跳包机制设计由于keepalive选项需要为每个连接中的socket开启，这不一定是必须的，可能会产生大量无意义的带宽浪费，且keepalive选项不能与应用层很好地交互，因此一般实际的服务开发中，还是建议读者在应用层设计自己的心跳包机制。那么如何设计呢？ 假定现在有一对已经连接的socket，在以下情况发生时候，socket将不再可用： 某一端关闭是socket：主动关闭的一方会发送FIN，通知对方要关闭TCP连接。在这种情况下，另一端如果去读socket，将会读到EoF（End of File），于是我们知道对方关闭了socket 应用程序奔溃：此时socket会由内核关闭，结果跟情况1一样 系统奔溃：这时候系统是来不及发送FIN的，因为它已经跪了。此时对方无法得知这一情况。对方在尝试读取数据时，最后会返回read time out；如果写数据，则是host unreachable之类的错误（如果没有对socket进行读写，两边都不知道发生了事故） 电缆被挖断、网线被拔：跟情况3差不多，如果没有对socket进行读写，两边都不知道发生了事故。跟情况3不同的是，如果我们把网线接回去，socket依旧可以正常使用 在上面的几种情形中，有一个共同点就是，只要去读、写socket，只要socket连接不正常，我们就能够知道。基于这一点，要实现一个socket长连接，我们需要做的就是不断地给对方写数据，然后读取对方的数据，也就是所谓的心跳。只要心还在跳，socket就是活的。写数据的间隔，需要根据实际的应用需求来决定。 心跳包不是实际的业务数据，根据通信协议的不同，需要做不同的处理。比方说，我们使用JSON进行通信，那么，可以为协议包加一个type字段，表面这个JSON是心跳还是业务数据：1234&#123; "msgType": 0, // 0 表示心跳 // 1 表示真实的通信数据 // ...&#125; 需要注意的是：一般是客户端主动给服务器端发送心跳包，服务器端做心跳检测决定是否断开连接。而不是反过来，从客户端的角度来说，客户端为了让自己得到服务器端的正常服务有必要主动和服务器保持连接状态正常，而服务器端不会局限于某个特定的客户端，如果客户端不能主动和其保持连接，那么就会主动回收与该客户端的连接。当然，服务器端在收到客户端的心跳包时应该给客户端一个心跳应答。 例子我们看一个LongLiveSocket类，这个类就是长连接保活的类。也是实现长连接的一个核心类。我们就来看看这个类的实现：1234567891011121314151617181920212223242526272829303132333435private final Runnable mHeartBeatTask = new Runnable() &#123; private byte[] mHeartBeat = new byte[0]; @Override public void run() &#123; ++mSeqNumHeartBeatSent; // 我们使用长度为 0 的数据作为 heart beat write(mHeartBeat, new WritingCallback() &#123; @Override public void onSuccess() &#123; // 每隔 HEART_BEAT_INTERVAL_MILLIS 发送一次 mWriterHandler.postDelayed(mHeartBeatTask, HEART_BEAT_INTERVAL_MILLIS); // At this point, the heart-beat might be received and handled if (mSeqNumHeartBeatRecv &lt; mSeqNumHeartBeatSent) &#123; mUIHandler.postDelayed(mHeartBeatTimeoutTask, HEART_BEAT_TIMEOUT_MILLIS); // double check if (mSeqNumHeartBeatRecv == mSeqNumHeartBeatSent) &#123; mUIHandler.removeCallbacks(mHeartBeatTimeoutTask); &#125; &#125; &#125; @Override public void onFail(byte[] data, int offset, int len) &#123; // nop // write() 方法会处理失败 &#125; &#125;); &#125;&#125;;private final Runnable mHeartBeatTimeoutTask = () -&gt; &#123; Log.e(TAG, "mHeartBeatTimeoutTask#run: heart beat timeout"); closeSocket();&#125;; 可以看出来这个发送心跳频率包的核心方法的实现是： 有两个心跳包计数器，mSeqNumHeartBeatSent发送心跳包计数器，每次发送一个心跳包，mSeqNumHeartBeatSent+1 。mSeqNumHeartBeatRecv接收的心跳包计数器，每次接收客户端发来的心跳包mSeqNumHeartBeatRecv+1 这个心跳包的大小是0个字节，rivate byte[] mHeartBeat = new byte[0] 如果mSeqNumHeartBeatRecv &lt; mSeqNumHeartBeatSent则认为对端断开连接，关闭socket 客户端client代码如下：12345678910111213141516171819202122232425262728293031public class EchoClient &#123; private static final String TAG = "EchoClient"; private final LongLiveSocket mLongLiveSocket; public EchoClient(String host, int port) &#123; mLongLiveSocket = new LongLiveSocket( host, port, // 回调函数 (data, offset, len) -&gt; Log.i(TAG, "EchoClient: received: " + new String(data, offset, len)), // 发生错误的回调函数，返回 true，所以只要出错，就会一直重连 () -&gt; true); &#125; public void send(String msg) &#123; mLongLiveSocket.write(msg.getBytes(), new LongLiveSocket.WritingCallback() &#123; @Override public void onSuccess() &#123; Log.d(TAG, "onSuccess: "); &#125; @Override public void onFail(byte[] data, int offset, int len) &#123; Log.w(TAG, "onFail: fail to write: " + new String(data, offset, len)); // 连接成功后，还会发送这个消息 mLongLiveSocket.write(data, offset, len, this); &#125; &#125;); &#125;&#125; 就这样，一个带 socket 长连接的客户端就完成了。剩余代码跟我们这里的主题没有太大关系。 输出如下：123456789101103:54:55.583 12691-12713/com.example.echo I/LongLiveSocket: readResponse: heart beat received03:55:00.588 12691-12713/com.example.echo I/LongLiveSocket: readResponse: heart beat received03:55:05.594 12691-12713/com.example.echo I/LongLiveSocket: readResponse: heart beat received03:55:09.638 12691-12710/com.example.echo D/EchoClient: onSuccess:03:55:09.639 12691-12713/com.example.echo I/EchoClient: EchoClient: received: hello03:55:10.595 12691-12713/com.example.echo I/LongLiveSocket: readResponse: heart beat received03:55:14.652 12691-12710/com.example.echo D/EchoClient: onSuccess:03:55:14.654 12691-12713/com.example.echo I/EchoClient: EchoClient: received: echo03:55:15.596 12691-12713/com.example.echo I/LongLiveSocket: readResponse: heart beat received03:55:20.597 12691-12713/com.example.echo I/LongLiveSocket: readResponse: heart beat received03:55:25.602 12691-12713/com.example.echo I/LongLiveSocket: readResponse: heart beat received 巨人的肩膀： https://mp.weixin.qq.com/s/dFn-4Gkm6NNeJkDlupqDvw]]></content>
      <categories>
        <category>I/O</category>
      </categories>
      <tags>
        <tag>socket</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM内存管理]]></title>
    <url>%2F2020%2F11%2F17%2FJVM%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[写在开篇本文主要介绍了JVM内存管理和垃圾收集器。 垃圾收集概念我们把还被GC Roots引用的对象称为活的，把不再被引用的对象认为是死的，也就是我们说的垃圾，GC的工作就是找到死的对象，回收它们占用的空间。 我们把GC管理的内存称为堆（heap），垃圾收集启动的时机取决于各个垃圾收集器，通常，垃圾收集发生于整个堆或堆的部分已经被使用光了，或者使用的空间达到了某个百分比阈值。 对于内存分配请求，实现的难点在于在堆中找到一块没有被使用的确定大小的内存空间。所以，对于大部分垃圾回收算法来说避免内存碎片化是非常重要的，它将使得空间分配更加高效。 垃圾收集器的理想特征 安全和全面：活的对象一定不能被清理掉，死的对象一定不能在几个回收周期结束后还在内存中。 高效：不能将我们的应用程序挂起太长时间。我们需要在时间、空间、频次上作出权衡。比如，如果堆内存很小，每次垃圾收集就会很快，但是频次会增加。如果堆内存很大，很久才会被填满，但是每一次回收需要的时间很长。 尽量少的内存碎片：每次将垃圾对象释放以后，这些空间可能分布在各个地方，最糟糕的情况就是，内存中到处都是碎片，在给一个大对象分配空间的时候没有内存可用，实际上内存是够的。消除碎片的方式就是压缩。 可扩展性：在多核多线程应用中，内存分配和垃圾回收都不应该成为可扩展性的瓶颈。原文提到的这一点，我的理解是：单线程垃圾回收在多核系统中会浪费CPU资源，如果我理解错误，请指正我。 设计上的权衡往下看之前，我们需要先分清楚这里的两个概念：并发和并行 并行：多个垃圾回收线程同时工作，而不是只有一个垃圾回收线程在工作 并发：垃圾回收线程和应用程序线程同时工作，应用程序不需要挂起 在设计或选择垃圾回收算法的时候，我们需要作出以下几个权衡： 串行 vs 并行串行收集的情况，即使是多核 CPU，也只有一个核心参与收集。使用并行收集器的话，垃圾收集的工作将分配给多个线程在不同的 CPU 上同时进行。并行可以让收集工作更快，缺点是带来的复杂性和内存碎片问题。 并发 vs Stop-the-world当 stop-the-world 垃圾收集器工作的时候，应用将完全被挂起。与之相对的，并发收集器在大部分工作中都是并发进行的，也许会有少量的 stop-the-world。stop-the-world 垃圾收集器比并发收集器简单很多，因为应用挂起后堆空间不再发生变化，它的缺点是在某些场景下挂起的时间我们是不能接受的（如 web 应用）。相应的，并发收集器能够降低挂起时间，但是也更加复杂，因为在收集的过程中，也会有新的垃圾产生，同时，需要有额外的空间用于在垃圾收集过程中应用程序的继续使用。 压缩 vs 不压缩 vs 复制当垃圾收集器标记出内存中哪些是活的，哪些是垃圾对象后，收集器可以进行压缩，将所有活的对象移到一起，这样新的内存分配就可以在剩余的空间中进行了。经过压缩后，分配新对象的内存空间是非常简单快速的。相对的，不压缩的收集器只会就地释放空间，不会移动存活对象。优点就是快速完成垃圾收集，缺点就是潜在的碎片问题。通常，这种情况下，分配对象空间会比较慢比较复杂，比如为新的一个大对象找到合适的空间。还有一个选择就是复制收集器，将活的对象复制到另一块空间中，优点就是原空间被清空了，这样后续分配对象空间非常迅速，缺点就是需要进行复制操作和占用额外的空间。 性能指标以下几个是评估垃圾收集器性能的一些指标： 吞吐量：应用程序的执行时间占总时间的百分比，当然是越高越好 垃圾收集开销：垃圾收集时间占总时间的百分比（1 - 吞吐量） 停顿时间：垃圾收集过程中导致的应用程序挂起时间 频次：相对于应用程序来说，垃圾收集的频次 空间：垃圾收集占用的内存 及时性：一个对象从成为垃圾到该对象空间再次可用的时间 在交互式程序中，通常希望是低延时的，而对于非交互式程序，总运行时间比较重要。实时应用程序既要求每次停顿时间足够短，也要求总的花费在收集的时间足够短。在小型个人计算机和嵌入式系统中，则希望占用更小的空间。 分代收集介绍当我们使用分代垃圾收集器时，内存将被分为不同的代(generation)，最常见的就是分为年轻代和老年代。 在不同的分代中，可以根据不同的特点使用不同的算法。分代垃圾收集基于 weak generational hypothesis 假设（通常国人会翻译成 弱分代假设）： 大部分对象都是短命的，它们在年轻的时候就会死去 极少老年对象对年轻对象的引用 年轻代中的收集是非常频繁的、高效的、快速的，因为年轻代空间中，通常都是小对象，同时有非常多的不再被引用的对象。 那些经历过多次年轻代垃圾收集还存活的对象会晋升到老年代中，老年代的空间更大，而且占用空间增长比较慢。这样，老年代的垃圾收集是不频繁的，但是进行一次垃圾收集需要的时间更长。 对于新生代，需要选择速度比较快的垃圾回收算法，因为新生代的垃圾回收是频繁的。 对于老年代，需要考虑的是空间，因为老年代占用了大部分堆内存，而且针对该部分的垃圾回收算法，需要考虑到这个区域的垃圾密度比较低。 JVM中的垃圾收集器HotSpot分代在 HotSpot 虚拟机中，内存被组织成三个分代：年轻代、老年代、永久代。 大部分对象初始化的时候都是在年轻代中的 老年代存放经过了几次年轻代垃圾收集依然还活着的对象，还有部分大对象因为比较大所以分配的时候直接在老年代分配 永久代，通常也叫 方法区，用于存储已加载类的元数据，以及存储运行时常量池等 垃圾回收类型当年轻代被填满后，会进行一次年轻代垃圾收集（也叫做minor GC）。 当老年代或永久代被填满了，会触发full GC（也叫做 major GC），full GC 会收集所有区域，先进行年轻代的收集，使用年轻代专用的垃圾回收算法，然后使用老年代的垃圾回收算法回收老年代和永久代。如果算法带有压缩，每个代分别独立地进行压缩。 如果先进行年轻代垃圾收集，会使得老年代不能容纳要晋升上来的对象，这种情况下，不会先进行young gc，所有的收集器都会（除了CMS）直接采用老年代收集算法对整个堆进行收集（CMS收集器比较特殊，因为它不能收集年轻代的垃圾）。 内存分配指针碰撞如果垃圾收集完成后，存在大片连续的内存可用于分配给新对象，这种情况下分配空间是非常简单快速的，只要一个简单的指针碰撞就可以了（bump-the-pointer），每次分配对象空间只要检测一下是否有足够的空间，如果有，指针往前移动N位就分配好空间了，然后就可以初始化这个对象了。 TLABs对于多线程应用，对象分配必须要保证线程安全性，如果使用全局锁，那么分配空间将成为瓶颈并降低程序性能。HotSpot使用了称之为Thread-Local Allocation Buffers(TLABs) 的技术，该技术能改善多线程空间分配的吞吐量。首先，给予每个线程一部分内存作为缓存区，每个线程都在自己的缓存区中进行指针碰撞，这样就不用获取全局锁了。只有当一个线程使用完了它的TLAB，它才需要使用同步来获取一个新的缓冲区。HotSpot使用了多项技术来降低TLAB对于内存的浪费。比如，TLAB的平均大小被限制在Eden区大小的1%之内。TLABs和使用指针碰撞的线性分配结合，使得内存分配非常简单高效，只需要大概10条机器指令就可以完成。 串行收集器使用串行收集器，年轻代和老年代都使用单线程进行收集（使用一个CPU），收集过程中会stop-the-world。所以当在垃圾收集的时候，应用程序是完全停止的。 在年轻代中使用串行收集器下图展示了年轻代中使用串行收集器的流程。 jvm内存管理01 年轻代分为一个Eden区和两个Survivor区（From区和To区）。年轻代垃圾收集时，将Eden中活着的对象复制到空的Survivor-To区，Survivor-From区的对象分两类，一类是年轻的，也是复制到Survivor-To区，还有一类是老家伙，晋升到老年代中。 如果复制的过程中，发现Survivor-To空间满了，将剩下还没复制到Survivor-To的来自于Eden和Survivor-From区的对象直接晋升到老年代。 年轻代垃圾收集完成后，Eden区和Survivor-From就干净了，此时，将Survivor-From和 Survivor-To交换一下角色。得到下面这个样子： jvm内存管理02 在老年代中使用串行收集器如果使用串行收集器，在老年代和永久代将通过使用 标记 -&gt; 清除 -&gt; 压缩算法。标记阶段，收集器识别出哪些对象是活的；清除阶段将遍历一下老年代和永久代，识别出哪些是垃圾；然后执行压缩，将活的对象左移到老年代的起始端（永久代类似），这样就留下了右边一片连续可用的空间，后续就可以通过指针碰撞的方式快速分配对象空间。 jvm内存管理03 何时应该使用串行收集器串行收集器适用于运行在client模式下的大部分程序，它们不要求低延时。在现代硬件条件下，串行收集器可以高效管理64M堆内存，并且能将full GC控制在半秒内完成。 并行收集器现在大多数Java应用都运行在大内存、多核环境中，并行收集器，也就是大家熟知的吞吐量收集器，利用多核的优势来进行垃圾收集，而不是像串行收集器一样将程序挂起后只使用单线程来收集垃圾。 在年轻代中使用并行收集器并行收集器在年轻代中其实就是串行收集器收集算法的并行版本。它仍然使用 stop-the-world 和复制算法，只不过使用了多核的优势并行执行，降低垃圾收集的时间，从而提高吞吐量。下图示意了在年轻代中，串行收集器和并行收集器的区别： jvm内存管理04 在老年代中使用并行收集器在老年代中，并行收集器使用的是和串行收集器一样的算法：单线程，标记 -&gt; 清除 -&gt; 压缩。 ps：是的，并行收集器只能在年轻代中并行。 何时使用并行收集器其适用于多核、不要求低停顿的应用，因为老年代的收集虽然不频繁，但是每次老年代的单线程垃圾收集依然可能会需要很长时间。比如说，它可以应用在批处理、账单计算、科学计算等。 你应该不会想要这个收集器，而是要一个可以对每个代都采用并行收集的并行压缩收集器，下一节将介绍这个。 并行压缩收集器并行压缩收集器于J2SE 5.0 update 6引入，和并行收集器的区别在于它在老年代也使用并行收集算法。注意：并行压缩收集器终将会取代并行收集器。 在年轻代中使用并行压缩收集器并行压缩收集器在年轻代中使用了和并行收集器一样的算法。即使用 并行、stop-the-world、复制 算法。 在老年代中使用并行压缩收集器在老年代和永久代中，其使用 并行、stop-the-world、滑动压缩 算法。 一次收集分三个阶段，首先，将老年代或永久代逻辑上分为固定大小的区块。 标记阶段，将GC Roots分给多个垃圾收集线程，每个线程并行地去标记存活的对象，一旦标记一个存活对象，在该对象所在的区块记录这个对象的大小和对象所在的位置 汇总阶段，此阶段针对区块进行。由于之前的垃圾回收影响，老年代和永久代的左侧是 存活对象密集区，对这部分区域直接进行压缩的代价是不值得的，能清理出来的空间有限。所以第一件事就是，检查每个区块的密度，从左边第一个开始，直到找到一个区块满足：对右侧的所有区块进行压缩获得的空间抵得上压缩它们的成本。这个区块左边的区域过于密集，不会有对象移动到这个区域中。然后，计算并保存右侧区域中每个区块被压缩后的新位置首字节地址右侧的区域将被压缩，对于右侧的每个区块，由于每个区块中保存了该区块的存活对象信息，所以很容易计算每个区块的新位置。注意：汇总阶段目前被实现为串行进行，这个阶段修改为并行也是可行的，不过没有在标记阶段和下面的压缩阶段并行那么重要 压缩阶段，在汇总阶段已经完成了每个区块新位置的计算，所以压缩阶段每个回收线程并行将每个区块复制到新位置即可。压缩结束后，就清出来了右侧一大片连续可用的空间 何时使用并行压缩收集器首先是多核上的并行优势，这个就不重复了。其次，前面的并行收集器对于老年代和永久代使用串行，而并行压缩收集器在这些区域使用并行，能降低停顿时间。 并行压缩收集器不适合运行在大型共享主机上（如SunRays），因为它在收集的时候会独占几个CPU，在这种机器上，可以考虑减少垃圾收集的线程数（通过 –XX:ParallelGCThreads=n），或者就选择其他收集器。 Concurrent Mark-Sweep（CMS）收集器重头戏CMS登场了，至少对于我这个web开发者来说，目前CMS最常用（使用JDK8的应用一般都切换到G1收集器了）。前面介绍的都是并行收集，这里要介绍并发收集了，也就是垃圾回收线程和应用程序线程同时运行。 对于许多程序来说，吞吐量不如响应时间来得重要。通常年轻代的垃圾收集不会停顿多长时间，但是，老年代垃圾回收，虽然不频繁，但是可能导致长时间的停顿，尤其当堆内存比较大的时候。为了解决这个问题，HotSpot虚拟机提供了CMS收集器，也叫做低延时收集器。 在年轻代中使用CMS收集器在年轻代中，CMS和并行收集器一样，即：并行、stop-the-world、复制。 在老年代中使用 CMS 收集器在老年代的垃圾收集过程中，大部分收集任务是和应用程序并发执行的。 CMS收集过程首先是一段小停顿stop-the-world，叫做初始标记阶段（initial mark），用于确定GC Roots。然后是并发标记阶段（concurrent mark），标记GC Roots可达的所有存活对象，由于这个阶段应用程序同时也在运行，所以并发标记阶段结束后，并不能标记出所有的存活对象。为了解决这个问题，需要再次停顿应用程序，称为再次标记阶段（remark），遍历在并发标记阶段应用程序修改的对象（标记出应用程序在这个期间的活对象），由于这次停顿比初始标记要长得多，所以会使用多线程并行执行来增加效率。 再次标记阶段结束后，能保证所有存活对象都被标记完成，所以接下来的并发清理阶段（concurrent sweep） 将就地回收垃圾对象所占空间。下图示意了老年代中串行、标记 -&gt; 清理 -&gt; 压缩收集器和CMS收集器的区别： jvm内存管理05 由于部分任务增加了收集器的工作，如遍历并发阶段应用程序修改的对象，所以增加了CMS收集器的负载。对于大部分试图降低停顿时间的收集器来说，这是一种权衡方案。 CMS收集器是唯一不进行压缩的收集器，在它释放了垃圾对象占用的空间后，它不会移动存活对象到一边去。 jvm内存管理06 这将节省垃圾回收的时间，但是由于之后空闲空间不是连续的，所以也就不能使用简单的指针碰撞进行对象空间分配了。它需要维护一个空闲列表，将所有的空闲区域连接起来，当分配空间时，需要寻找到一个可以容纳该对象的区域。显然，它比使用简单的指针碰撞成本要高。同时它也会加大年轻代垃圾收集的负载，因为年轻代中的对象如果要晋升到老年代中，需要老年代进行空间分配。 另外一个缺点就是，CMS收集器相比其他收集器需要使用更大的堆内存。因为在并发标记阶段，程序还需要执行，所以需要留足够的空间给应用程序。另外，虽然收集器能保证在标记阶段识别出所有的存活对象，但是由于应用程序并发运行，所以刚刚标记的存活对象很可能立马成为垃圾，而且这部分由于已经被标记为存活对象，所以只能到下次老年代收集才会被清理，这部分垃圾称为浮动垃圾。 最后，由于缺少压缩环节，堆将会出现碎片化问题。为了解决这个问题，CMS 收集器需要追踪统计最常用的对象大小，评估将来的分配需求，可能还需要分割或合并空闲区域。 不像其他垃圾收集器，CMS收集器不能等到老年代满了才开始收集。否则的话，CMS收集器将退化到使用更加耗时的stop-the-world、标记-清除-压缩算法。为了避免这个，CMS收集器需要统计之前每次垃圾收集的时间和老年代空间被消耗的速度。另外，如果老年代空间被消耗了预设占用率（initiating occupancy），也将会触发一次垃圾收集，这个占用率通过 –XX:CMSInitiatingOccupancyFraction=n 进行设置，n为老年代空间的占用百分比，默认值是68。 总结下来，和并行收集器相比，CMS收集器降低了老年代收集时的停顿时间（有时是显著降低），稍微增加了一些年轻代收集的时间、降低了吞吐量以及需要更多的堆内存。 何时使用CMS收集器适用于应用程序要求低停顿，同时能接受在垃圾收集阶段和垃圾收集线程一起共享CPU资源的场景，典型的就是web应用了。 在web应用中，低延时非常重要，所以CMS几乎就是唯一选择，直到后来G1的出现。 G1G1的主要关注点在于达到可控的停顿时间，在这个基础上尽可能提高吞吐量，这一点非常重要。 G1被设计用来长期取代CMS收集器，和CMS相同的地方在于，它们都属于并发收集器，在大部分的收集阶段都不需要挂起应用程序。区别在于，G1没有CMS的碎片化问题（或者说不那么严重），同时提供了更加可控的停顿时间。 如果你的应用使用了较大的堆（如6GB及以上）而且还要求有较低的垃圾收集停顿时间（如0.5秒），那么G1是你绝佳的选择，是时候放弃CMS了。 G1总览首先是内存划分上，之前介绍的分代收集器将整个堆分为年轻代、老年代和永久代，每个代的空间是确定的。 而G1将整个堆划分为一个个大小相等的小块（每一块称为一个region），每一块的内存是连续的。和分代算法一样，G1中每个块也会充当Eden、Survivor、Old三种角色，但是它们不是固定的，这使得内存使用更加地灵活。 JVM内存管理07 执行垃圾收集时，和CMS一样，G1收集线程在标记阶段和应用程序线程并发执行，标记结束后，G1也就知道哪些区块基本上是垃圾，存活对象极少，G1会先从这些区块下手，因为从这些区块能很快释放得到很大的可用空间，这也是为什么G1被取名为Garbage-First的原因。 在G1中，目标停顿时间非常非常重要，用-XX:MaxGCPauseMillis=200指定期望的停顿时间。 G1使用了停顿预测模型来满足用户指定的停顿时间目标，并基于目标来选择进行垃圾回收的区块数量。G1采用增量回收的方式，每次回收一些区块，而不是整堆回收。 我们要知道G1不是一个实时收集器，它会尽力满足我们的停顿时间要求，但也不是绝对的，它基于之前垃圾收集的数据统计，估计出在用户指定的停顿时间内能收集多少个区块。 注意：G1有和应用程序一起运行的并发阶段，也有stop-the-world的并行阶段。但是，Full GC的时候还是单线程运行的，所以我们应该尽量避免发生Full GC，后面我们也会介绍什么时候会触发Full GC。 G1内存占用G1比ParallelOld和CMS会需要更多的内存消耗，那是因为有部分内存消耗于簿记（accounting）上，如以下两个数据结构： Remembered Sets：每个区块都有一个RSet，用于记录进入该区块的对象引用（如区块 A 中的对象引用了区块B，区块B的Rset需要记录这个信息），它用于实现收集过程的并行化以及使得区块能进行独立收集。总体上Remembered Sets消耗的内存小于5% Collection Sets：将要被回收的区块集合。GC时，在这些区块中的对象会被复制到其他区块中，总体上Collection Sets消耗的内存小于1% G1工作流程G1收集器主要包括了以下4种操作： 年轻代收集 并发收集，和应用线程同时执行 混合式垃圾收集 必要时的 Full GC 年轻代收集首先，我们来看下 G1 的堆结构： jvm内存管理08 年轻代中的垃圾收集流程（Young GC）： jvm内存管理09 我们可以看到，年轻代收集概念上和之前介绍的其他分代收集器大差不差的，但是它的年轻代会动态调整。 Old GC / 并发标记周期接下来是Old GC的流程（含Young GC阶段），其实把Old GC理解为并发周期是比较合理的，不要单纯地认为是清理老年代的区块，因为这一步和年轻代收集也是相关的。下面我们介绍主要流程： 初始标记：stop-the-world，它伴随着一次普通的Young GC发生，然后对Survivor区（root region）进行标记，因为该区可能存在对老年代的引用因为Young GC是需要stop-the-world的，所以并发周期直接重用这个阶段，虽然会增加CPU开销，但是停顿时间只是增加了一小部分 扫描根引用区：因为先进行了一次YGC，所以当前年轻代只有Survivor区有存活对象，它被称为根引用区。扫描Survivor到老年代的引用，该阶段必须在下一次Young GC发生前结束这个阶段不能发生年轻代收集，如果中途Eden区真的满了，也要等待这个阶段结束才能进行Young GC 并发标记：寻找整个堆的存活对象，该阶段可以被Young GC中断这个阶段是并发执行的，中间可以发生多次Young GC，Young GC会中断标记过程 重新标记：stop-the-world，完成最后的存活对象标记。使用了比CMS收集器更加高效的snapshot-at-the-beginning(SATB)算法Oracle的资料显示，这个阶段会回收完全空闲的区块 清理：清理阶段真正回收的内存很少 到这里，G1的一个并发周期就算结束了，其实就是主要完成了垃圾定位的工作，定位出了哪些分区是垃圾最多的。因为整堆一般比较大，所以这个周期应该会比较长，中间可能会被多次stop-the-world的Young GC打断。 混合垃圾回收周期并发周期结束后是混合垃圾回收周期，不仅进行年轻代垃圾收集，而且回收之前标记出来的老年代的垃圾最多的部分区块。 混合垃圾回收周期会持续进行，直到几乎所有的被标记出来的分区（垃圾占比大的分区）都得到回收，然后恢复到常规的年轻代垃圾收集，最终再次启动并发周期。 Full GC到这里我们已经说了年轻代收集、并发周期、混合回收周期了，大家要熟悉这几个阶段的工作。 下面我们来介绍特殊情况，那就是会导致Full GC的情况，也是我们需要极力避免的： concurrent mode failure：并发模式失败，CMS 收集器也有同样的概念。G1并发标记期间，如果在标记结束前，老年代被填满，G1会放弃标记这个时候说明堆需要增加了，或者需要调整并发周期，如增加并发标记的线程数量，让并发标记尽快结束，或者就是更早地进行并发周期，默认是整堆内存的45% 被占用就开始进行并发周期 晋升失败：并发周期结束后，是混合垃圾回收周期，伴随着年轻代垃圾收集，进行清理老年代空间，如果这个时候清理的速度小于消耗的速度，导致老年代不够用，那么会发生晋升失败说明混合垃圾回收需要更迅速完成垃圾收集，也就是说在混合回收阶段，每次年轻代的收集应该处理更多的老年代已标记区块 疏散失败：年轻代垃圾收集的时候，如果 Survivor 和 Old 区没有足够的空间容纳所有的存活对象。这种情况肯定是非常致命的，因为基本上已经没有多少空间可以用了，这个时候会触发 Full GC 也是很合理的最简单的就是增加堆大小 大对象分配失败，我们应该尽可能地不创建大对象，尤其是大于一个区块大小的那种对象 小结首先，最好不要把上面的Old GC当做是一次GC来看，而应该当做并发标记周期来理解，虽然它确实会释放出一些内存。 并发标记结束后，G1也就知道了哪些区块是最适合被回收的，那些完全空闲的区块会在这这个阶段被回收。如果这个阶段释放了足够的内存出来，其实也就可以认为结束了一次GC。 我们假设并发标记结束了，那么下次GC的时候，还是会先回收年轻代，如果从年轻代中得到了足够的内存，那么结束；过了几次后，年轻代垃圾收集不能满足需要了，那么就需要利用之前并发标记的结果，选择一些活跃度最低的老年代区块进行回收。直到最后，老年代会进入下一个并发周期。 那么什么时候会启动并发标记周期呢？这个是通过参数控制的，下面马上要介绍这个参数了，此参数默认值是45，也就是说当堆空间使用了45%后，G1就会进入并发标记周期。 G1调优的目标是尽量避免出现Full GC，其实就是给老年代足够的空间，或相对更多的空间。 有以下几点我们可以进行调整的方向： 增加堆大小，或调整老年代和年轻代的比例，这个很好理解 增加并发周期的线程数量，其实就是为了加快并发周期快点结束 让并发周期尽早开始，这个是通过设置堆使用占比来调整的（默认45%） 在混合垃圾回收周期中回收更多的老年代区块 G1的很重要的目标是达到可控的停顿时间，所以很多的行为都以这个目标为出发点开展的。 我们通过设置-XX:MaxGCPauseMillis=N来指定停顿时间（单位ms，默认200ms），如果没有达到这个目标，G1会通过各种方式来补救：调整年轻代和老年代的比例，调整堆大小，调整晋升的年龄阈值，调整混合垃圾回收周期中处理的老年代的区块数量等等。 当然了，调整每个参数满足了一个条件的同时往往也会引入另一个问题，比如为了降低停顿时间，我们可以减小年轻代的大小，可是这样的话就会增加年轻代垃圾收集的频率。如果我们减少混合垃圾回收周期处理的老年代区块数量，虽然可以更容易满足停顿时间要求，可是这样就会增加Full GC的风险等等。 文章大篇幅整理自： https://www.javadoop.com/ 垃圾收集器相关文章。]]></content>
      <categories>
        <category>Java乐园</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java类是如何被加载的]]></title>
    <url>%2F2020%2F11%2F16%2FJava%E7%B1%BB%E6%98%AF%E5%A6%82%E4%BD%95%E8%A2%AB%E5%8A%A0%E8%BD%BD%E7%9A%84%2F</url>
    <content type="text"><![CDATA[何时加载类 遇到new、getstatic、putstatic等指令时 对类进行反射调用的时候 初始化某个类的子类的时候 虚拟机启动时会先加载设置的程序主类 使用JDK1.7 的动态语言支持的时候 其实就是，当运行过程中需要这个类的时候。 怎么加载类利用ClassLoader加载类很简单，直接调用ClassLoder的loadClass()方法即可12345public class Test &#123; public static void main(String[] args) throws ClassNotFoundException &#123; Test.class.getClassLoader().loadClass("com.wangxiandeng.test.Dog"); &#125;&#125; JVM 是怎么加载类的JVM默认用于加载用户程序的ClassLoader为AppClassLoader，不过无论是什么ClassLoader，它的根父类都是java.lang.ClassLoader。最终会调用到ClassLoader.definClass1()，这是一个native方法。 Java_java_lang_ClassLoader_defineClass1()-&gt; JVM_DefineClassWithSource()-&gt; jvm_define_class_common() // 利用ClassFileStream将要加载的class文件转成文件流-&gt; SystemDictionary::resolve_from_stream() // 将Class文件加载成内存中的Klass resolve_from_stream()便是重中之重！主要逻辑有下面几步： 判断是否允许并行加载类，并根据判断结果进行加锁12345678bool DoObjectLock = true;if (is_parallelCapable(class_loader)) &#123; DoObjectLock = false;&#125;ClassLoaderData* loader_data = register_loader(class_loader, CHECK_NULL);Handle lockObject = compute_loader_lock_object(class_loader, THREAD);check_loader_lock_contention(lockObject, THREAD);ObjectLocker ol(lockObject, THREAD, DoObjectLock); 如果允许并行加载，则不会对ClassLoader进行加锁，只对SystemDictionary加锁。否则，便会利用ObjectLocker对ClassLoader加锁，保证同一个ClassLoader在同一时刻只能加载一个类。ObjectLocker会在其构造函数中获取锁，并在析构函数中释放锁。允许并行加载的好处便是精细化了锁粒度，这样可以在同一时刻加载多个Class文件。 解析文件流，生成InstanceKlass12345678InstanceKlass* k = NULL;k = KlassFactory::create_from_stream(st, class_name, loader_data, protection_domain, NULL, // host_klass NULL, // cp_patches CHECK_NULL); Klass就是JVM用来定义一个Java Class的数据结构。不过Klass只是一个基类，Java Class真正的数据结构定义在InstanceKlass中。InstanceKlass中记录了一个Java类的所有属性，包括注解、方法、字段、内部类、常量池等信息。这些信息本来被记录在Class文件中，所以说，InstanceKlass就是一个Java Class文件被加载到内存后的形式。 生成InstanceKlass调用的是KlassFactory::create_from_stream()，它的主要逻辑如下：12345678910ClassFileParser parser(stream, name, loader_data, protection_domain, host_klass, cp_patches, ClassFileParser::BROADCAST, // publicity level CHECK_NULL);InstanceKlass* result = parser.create_instance_klass(old_stream != stream, CHECK_NULL); 可以看到，ClassFileParser才是真正的主角啊！它才是将Class文件升华成InstanceKlass的幕后大佬！ create_instance_klass()主要就干了两件事： 为 InstanceKlass分配内存内存分配代码如下：123456789const int size = InstanceKlass::size(parser.vtable_size(), parser.itable_size(), nonstatic_oop_map_size(parser.total_oop_map_count()), parser.is_interface(), parser.is_anonymous(), should_store_fingerprint(parser.is_anonymous()));ClassLoaderData* loader_data = parser.loader_data();InstanceKlass* ik;ik = new (loader_data, size, THREAD) InstanceKlass(parser, InstanceKlass::_misc_kind_other); 这里首先计算了InstanceKlass在内存中的大小，要知道，这个大小在Class文件编译后就被确定了。 然后便new了一个新的InstanceKlass对象。这里并不是简单的在堆上分配内存，要注意的是Klass对new操作符进行了重载：123void* Klass::operator new(size_t size, ClassLoaderData* loader_data, size_t word_size, TRAPS) throw() &#123; return Metaspace::allocate(loader_data, word_size, MetaspaceObj::ClassType, THREAD);&#125; 分配InstanceKlass的时候调用了Metaspace::allocate()：123456789MetaWord* Metaspace::allocate(ClassLoaderData* loader_data, size_t word_size, MetaspaceObj::Type type, TRAPS) &#123; ...... MetadataType mdtype = (type == MetaspaceObj::ClassType) ? ClassType : NonClassType; ...... MetaWord* result = loader_data-&gt;metaspace_non_null()-&gt;allocate(word_size, mdtype); ...... return result;&#125; 由此可见，InstanceKlass 是分配在 ClassLoader的 Metaspace（元空间） 的方法区中。从 JDK8 开始，HotSpot 就没有了永久代，类都分配在 Metaspace 中。Metaspace 和永久代不一样，采用的是 Native Memory，永久代由于受限于 MaxPermSize，所以当内存不够时会内存溢出。 分析Class文件，填充InstanceKlass内存区域ClassFileParser在构造的时候就会开始分析Class文件，所以fill_instance_klass()中只需要填充即可。填充结束后，还会调用 java_lang_Class::create_mirror()创建InstanceKlass在Java层的 Class对象。123456789101112131415void ClassFileParser::fill_instance_klass(InstanceKlass* ik, bool changed_by_loadhook, TRAPS) &#123; ..... ik-&gt;set_class_loader_data(_loader_data); ik-&gt;set_nonstatic_field_size(_field_info-&gt;nonstatic_field_size); ik-&gt;set_has_nonstatic_fields(_field_info-&gt;has_nonstatic_fields); ik-&gt;set_static_oop_field_count(_fac-&gt;count[STATIC_OOP]); ik-&gt;set_name(_class_name); ...... java_lang_Class::create_mirror(ik, Handle(THREAD, _loader_data-&gt;class_loader()), module_handle, _protection_domain, CHECK);&#125; 到这儿，Class文件已经完成了华丽的转身，由冷冰冰的二进制文件，变成了内存中充满生命力的InstanceKlass。 利用SystemDictionary注册生成的Klass先看一下注册的代码：123456789101112131415// 允许并行加载，那么前面就不会对ClassLoader加锁// 所以在同一时刻，可能对同一Class文件加载了多次// 但是同一Class在同一ClassLoader中必须保持唯一性，所以这里会先利用SystemDictionary查询ClassLoader是否已经加载过相同Classif (is_parallelCapable(class_loader)) &#123; // 如果没有查询到，那么就将刚刚加载的InstanceKlass注册到ClassLoader的Dictionary中 InstanceKlass* defined_k = find_or_define_instance_class(h_name, class_loader, k, THREAD); if (!HAS_PENDING_EXCEPTION &amp;&amp; defined_k != k) &#123; // 如果已经加载过，那么就将当前线程刚刚加载的InstanceKlass加入待回收列表，并将InstanceKlass* k重新指向利用SystemDictionary查询到的InstanceKlass loader_data-&gt;add_to_deallocate_list(k); k = defined_k; &#125;&#125; else &#123; // 如果禁止了并行加载，那么直接利用SystemDictionary将 nstanceKlass注册到ClassLoader的Dictionary中即可 define_instance_class(k, THREAD);&#125; SystemDictionary是用来帮助保存ClassLoader加载过的类信息的。准确点说，SystemDictionary并不是一个容器，真正用来保存类信息的容器是Dictionary，每个ClassLoaderData中都保存着一个私有的Dictionary，而SystemDictionary只是一个拥有很多静态方法的工具类而已。 双亲委派模型我们知道， 双亲委派模型中，ClassLoader在加载类的时候，会先交由它的父ClassLoader加载，只有当父ClassLoader加载失败的情况下，才会尝试自己去加载。这样可以实现部分类的复用，又可以实现部分类的隔离，因为不同ClassLoader加载的类是互相隔离的。 但是在看完上面的分析后，你一定对 “不同ClassLoader加载的类是互相隔离的” 这句话的理解又上了一个台阶。 可以总结一下，即每个ClassLoader都有一个Dictionary用来保存它所加载的InstanceKlass信息。并且，每个ClassLoader通过锁，保证了对于同一个Class，它只会注册一份InstanceKlass到自己的 ictionary。 由于上面这些原因，如果所有的ClassLoader都由自己去加载Class文件，就会导致对于同一个Class文件，存在多份InstanceKlass，所以即使是同一个Class文件，不同InstanceKlasss衍生出来的实例类型也是不一样的。 文章大篇幅摘抄自： https://zhuanlan.zhihu.com/p/60328095]]></content>
      <categories>
        <category>Java乐园</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统]]></title>
    <url>%2F2020%2F11%2F13%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[写在开篇随着被字节和腾讯血虐，秋招告一段落了，接下来会好好总结，恢复更新博客。 概述基本特征 并发 并发是指宏观上在一段时间内能同时运行多个程序，操作系统通过引入进程和线程，使得程序能够并发运行 而并行则指同一时刻能运行多个指令，并行需要硬件支持，如多流水线、多核处理器或者分布式计算系统 共享 互斥共享 互斥共享的资源称为临界资源，例如打印机等，在同一时刻只允许一个进程访问，需要用同步机制来实现互斥访问 同时共享 虚拟 时（时间）分复用技术 多个进程能在同一个处理器上并发执行使用了时分复用技术，让每个进程轮流占用处理器，每次只执行一小个时间片并快速切换 空（空间）分复用技术 虚拟内存 异步 异步指进程不是一次性执行完毕，而是走走停停，以不可知的速度向前推进 基本功能 进程管理 内存管理 文件管理 设备管理 系统调用 内核态 用户态 Linux 的系统调用主要有以下这些： Task Commands 进程控制 fork()、exit()、wait() 进程通信 pipe()、shmget()、mmap() 文件操作 open()、read()、write() 设备操作 ioctl()、read()、write() 信息维护 getpid()、alarm()、sleep() 安全 chmod()、umask()、chown() 中断 外中断 由 CPU 执行指令以外的事件引起，如 I/O 完成中断，表示设备输入/输出处理已经完成，处理器能够发送下一个输入/输出请求。此外还有时钟中断、控制台中断等。 异常 由 CPU 执行指令的内部事件引起，如非法操作码、地址越界、算术溢出等。 陷入 在用户程序中使用系统调用。 进程管理进程和线程 概念 QQ 和浏览器是两个进程，浏览器进程里面有很多线程，例如 HTTP 请求线程、事件响应线程、渲染线程等等，线程的并发执行使得在浏览器中点击一个新链接从而发起 HTTP 请求时，浏览器还可以响应用户的其它事件。 区别 拥有的资源 进程是资源分配的基本单位，但线程不拥有资源 系统开销 创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备，所付出的开销远大于创建或撤销线程时的开销 在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小。 通信线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助 IPC 进程状态的切换 就绪状态（ready）：等待被调度 运行状态（running） 阻塞状态（waiting）：等待资源 有就绪态和运行态可以相互转换，其它的都是单向转换。就绪状态的进程通过调度算法从而获得 CPU 时间，转为运行状态；而运行状态的进程，在分配给它的 CPU 时间片用完之后就会转为就绪状态，等待下一次调度。 阻塞状态是缺少需要的资源从而由运行状态转换而来，但是该资源不包括 CPU 时间，缺少 CPU 时间会从运行态转换为就绪态。 进程同步临界区对临界资源进行访问的那段代码称为临界区。 为了互斥访问临界资源，每个进程在进入临界区之前，需要先进行检查。123// entry section// critical section;// exit section 同步与互斥 同步：多个进程因为合作产生的直接制约关系，使得进程有一定的先后执行关系 互斥：多个进程在同一时刻只有一个进程能进入临界区 信号量 特点信号量（Semaphore）是一个整型变量，可以对其执行 down 和 up 操作，也就是常见的 P 和 V 操作 down : 如果信号量大于 0 ，执行 -1 操作；如果信号量等于 0，进程睡眠，等待信号量大于 0 up ：对信号量执行 +1 操作，唤醒睡眠的进程让其完成 down 操作 原型如果信号量的取值只能为 0 或者 1，那么就成为了 互斥量（Mutex） ，0 表示临界区已经加锁，1 表示临界区解锁。 12345678910111213typedef int semaphore;semaphore mutex = 1;void P1() &#123; down(&amp;mutex); // 临界区 up(&amp;mutex);&#125;void P2() &#123; down(&amp;mutex); // 临界区 up(&amp;mutex);&#125; 例子 123456789101112131415161718192021222324252627#define N 100typedef int semaphore;semaphore mutex = 1;semaphore empty = N;semaphore full = 0;void producer() &#123; while(TRUE) &#123; int item = produce_item(); down(&amp;empty); down(&amp;mutex); insert_item(item); up(&amp;mutex); up(&amp;full); &#125;&#125;void consumer() &#123; while(TRUE) &#123; down(&amp;full); down(&amp;mutex); int item = remove_item(); consume_item(item); up(&amp;mutex); up(&amp;empty); &#125;&#125; 管程使用信号量机制实现的生产者消费者问题需要客户端代码做很多控制，而管程把控制的代码独立出来，不仅不容易出错，也使得客户端代码调用更容易。 进程调度不同环境的调度算法目标不同，因此需要针对不同环境来讨论调度算法。 批处理系统批处理系统没有太多的用户操作，在该系统中，调度算法目标是保证吞吐量和周转时间（从提交到终止的时间）。 先来先服务（fcfs） 短作业优先 最短剩余时间优先 交互式系统交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。 时间片轮转 将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。 优先级调度 为每个进程分配一个优先级，按优先级进行调度。为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。 多级反馈队列 一个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，那么需要交换 100 次。多级队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列时间片大小都不同，例如 1,2,4,8,..。进程在第一个队列没执行完，就会被移到下一个队列。这种方式下，之前的进程只需要交换 7 次。每个队列优先权也不同，最上面的优先权最高。因此只有上一个队列没有进程在排队，才能调度当前队列上的进程。可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合。 caozuoxitong03 实时系统实时系统要求一个请求在一个确定时间内得到响应。 分为硬实时和软实时，前者必须满足绝对的截止时间，后者可以容忍一定的超时。 进程间通信管道 特点 它是半双工的（即数据只能在一个方向上流动），具有固定的读端和写端。 只能在父子进程或者兄弟进程中使用 它可以看成是一种特殊的文件，对于它的读写也可以使用普通的read、write 等函数。但是它不是普通的文件，并不属于其他任何文件系统，并且只存在于内存中。 原型12#include &lt;unistd.h&gt;int pipe(int fd[2]); 管道是通过调用 pipe 函数创建的，当一个管道建立时，它会创建两个文件描述符：fd[0] 用于读，fd[1] 用于写。 例子单个进程中的管道几乎没有任何用处。所以，通常调用 pipe 的进程接着调用 fork，这样就创建了父进程与子进程之间的 IPC 通道。 caozuoxitong01 若要数据流从父进程流向子进程，则关闭父进程的读端（fd[0]）与子进程的写端（fd[1]）；反之，则可以使数据流从子进程流向父进程。12345678910111213141516171819202122232425262728#include&lt;stdio.h&gt;#include&lt;unistd.h&gt;int main()&#123; int fd[2]; // 两个文件描述符 pid_t pid; char buff[20]; if(pipe(fd) &lt; 0) // 创建管道 printf("Create Pipe Error!\n"); if((pid = fork()) &lt; 0) // 创建子进程 printf("Fork Error!\n"); else if(pid &gt; 0) // 父进程 &#123; close(fd[0]); // 关闭读端 write(fd[1], "hello world\n", 12); &#125; else &#123; close(fd[1]); // 关闭写端 read(fd[0], buff, 20); printf("%s", buff); &#125; return 0;&#125; FIFO也称为命名管道，去除了管道只能在父子进程中使用的限制。 特点 FIFO可以在无关的进程之间交换数据，与无名管道不同 FIFO有路径名与之相关联，它以一种特殊设备文件形式存在于文件系统中 原型123#include &lt;sys/stat.h&gt;// 返回值：成功返回0，出错返回-1int mkfifo(const char *pathname, mode_t mode); 其中的 mode 参数与open函数中的 mode 相同。一旦创建了一个 FIFO，就可以用一般的文件I/O函数操作它。 例子FIFO的通信方式类似于在进程中使用文件来传输数据，只不过FIFO类型文件同时具有管道的特性。在数据读出时，FIFO管道中同时清除数据，并且“先进先出”。 write_fifo.c1234567891011121314151617181920212223242526272829303132333435363738#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt; // exit#include&lt;fcntl.h&gt; // O_WRONLY#include&lt;sys/stat.h&gt;#include&lt;time.h&gt; // timeint main()&#123; int fd; int n, i; char buf[1024]; time_t tp; printf("I am %d process.\n", getpid()); // 说明进程ID if((fd = open("fifo1", O_WRONLY)) &lt; 0) // 以写打开一个FIFO &#123; perror("Open FIFO Failed"); exit(1); &#125; for(i=0; i&lt;10; ++i) &#123; time(&amp;tp); // 取系统当前时间 n=sprintf(buf,"Process %d's time is %s",getpid(),ctime(&amp;tp)); printf("Send message: %s", buf); // 打印 if(write(fd, buf, n+1) &lt; 0) // 写入到FIFO中 &#123; perror("Write FIFO Failed"); close(fd); exit(1); &#125; sleep(1); // 休眠1秒 &#125; close(fd); // 关闭FIFO文件 return 0;&#125; read_fifo.c123456789101112131415161718192021222324252627#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#include&lt;errno.h&gt;#include&lt;fcntl.h&gt;#include&lt;sys/stat.h&gt;int main()&#123; int fd; int len; char buf[1024]; if(mkfifo("fifo1", 0666) &lt; 0 &amp;&amp; errno!=EEXIST) // 创建FIFO管道 perror("Create FIFO Failed"); if((fd = open("fifo1", O_RDONLY)) &lt; 0) // 以读打开FIFO &#123; perror("Open FIFO Failed"); exit(1); &#125; while((len = read(fd, buf, 1024)) &gt; 0) // 读取FIFO管道 printf("Read message: %s", buf); close(fd); // 关闭FIFO文件 return 0;&#125; 在两个终端里用 gcc 分别编译运行上面两个文件，可以看到输出结果如下：123456789101112[cheesezh@localhost]$ ./write_fifoI am 5954 process.Send message: Process 5954&apos;s time is Mon Apr 20 12:37:28 2015Send message: Process 5954&apos;s time is Mon Apr 20 12:37:29 2015Send message: Process 5954&apos;s time is Mon Apr 20 12:37:30 2015Send message: Process 5954&apos;s time is Mon Apr 20 12:37:31 2015Send message: Process 5954&apos;s time is Mon Apr 20 12:37:32 2015Send message: Process 5954&apos;s time is Mon Apr 20 12:37:33 2015Send message: Process 5954&apos;s time is Mon Apr 20 12:37:34 2015Send message: Process 5954&apos;s time is Mon Apr 20 12:37:35 2015Send message: Process 5954&apos;s time is Mon Apr 20 12:37:36 2015Send message: Process 5954&apos;s time is Mon Apr 20 12:37:37 2015 1234567891011[cheesezh@localhost]$ ./read_fifoRead message: Process 5954&apos;s time is Mon Apr 20 12:37:28 2015Read message: Process 5954&apos;s time is Mon Apr 20 12:37:29 2015Read message: Process 5954&apos;s time is Mon Apr 20 12:37:30 2015Read message: Process 5954&apos;s time is Mon Apr 20 12:37:31 2015Read message: Process 5954&apos;s time is Mon Apr 20 12:37:32 2015Read message: Process 5954&apos;s time is Mon Apr 20 12:37:33 2015Read message: Process 5954&apos;s time is Mon Apr 20 12:37:34 2015Read message: Process 5954&apos;s time is Mon Apr 20 12:37:35 2015Read message: Process 5954&apos;s time is Mon Apr 20 12:37:36 2015Read message: Process 5954&apos;s time is Mon Apr 20 12:37:37 2015 上述例子可以扩展成 客户进程—服务器进程 通信的实例，write_fifo的作用类似于客户端，可以打开多个客户端向一个服务器发送请求信息，read_fifo类似于服务器，它适时监控着FIFO的读端，当有数据时，读出并进行处理，但是有一个关键的问题是，每一个客户端必须预先知道服务器提供的FIFO接口，下图显示了这种安排： caozuoxitong02 消息队列消息队列，是消息的链接表，存放在内核中。一个消息队列由一个标识符（即队列ID）来标识。 特点 消息队列是面向记录的，其中的消息具有特定的格式以及特定的优先级 消息队列独立于发送与接收进程，进程终止时，消息队列及其内容并不会被删除 消息队列可以实现消息的随机查询，消息不一定要以先进先出的次序读取,也可以按消息的类型读取 原型123456789#include &lt;sys/msg.h&gt;// 创建或打开消息队列：成功返回队列ID，失败返回-1int msgget(key_t key, int flag);// 添加消息：成功返回0，失败返回-1int msgsnd(int msqid, const void *ptr, size_t size, int flag);// 读取消息：成功返回消息数据的长度，失败返回-1int msgrcv(int msqid, void *ptr, size_t size, long type,int flag);// 控制消息队列：成功返回0，失败返回-1int msgctl(int msqid, int cmd, struct msqid_ds *buf); 函数msgrcv在读取消息队列时，type参数有下面几种情况： type == 0，返回队列中的第一个消息 type &gt; 0，返回队列中消息类型为 type 的第一个消息 type &lt; 0，返回队列中消息类型值小于或等于 type 绝对值的消息，如果有多个，则取类型值最小的消息 可以看出，type值非 0 时用于以非先进先出次序读消息。也可以把 type 看做优先级的权值。 例子下面写了一个简单的使用消息队列进行IPC的例子，服务端程序一直在等待特定类型的消息，当收到该类型的消息以后，发送另一种特定类型的消息作为反馈，客户端读取该反馈并打印出来。 msg_server.c1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/msg.h&gt;// 用于创建一个唯一的key#define MSG_FILE "/etc/passwd"// 消息结构struct msg_form &#123; long mtype; char mtext[256];&#125;;int main()&#123; int msqid; key_t key; struct msg_form msg; // 获取key值 if((key = ftok(MSG_FILE,'z')) &lt; 0) &#123; perror("ftok error"); exit(1); &#125; // 打印key值 printf("Message Queue - Server key is: %d.\n", key); // 创建消息队列 if ((msqid = msgget(key, IPC_CREAT|0777)) == -1) &#123; perror("msgget error"); exit(1); &#125; // 打印消息队列ID及进程ID printf("My msqid is: %d.\n", msqid); printf("My pid is: %d.\n", getpid()); // 循环读取消息 for(;;) &#123; msgrcv(msqid, &amp;msg, 256, 888, 0);// 返回类型为888的第一个消息 printf("Server: receive msg.mtext is: %s.\n", msg.mtext); printf("Server: receive msg.mtype is: %d.\n", msg.mtype); msg.mtype = 999; // 客户端接收的消息类型 sprintf(msg.mtext, "hello, I'm server %d", getpid()); msgsnd(msqid, &amp;msg, sizeof(msg.mtext), 0); &#125; return 0;&#125; msg_client.c123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/msg.h&gt;// 用于创建一个唯一的key#define MSG_FILE "/etc/passwd"// 消息结构struct msg_form &#123; long mtype; char mtext[256];&#125;;int main()&#123; int msqid; key_t key; struct msg_form msg; // 获取key值 if ((key = ftok(MSG_FILE, 'z')) &lt; 0) &#123; perror("ftok error"); exit(1); &#125; // 打印key值 printf("Message Queue - Client key is: %d.\n", key); // 打开消息队列 if ((msqid = msgget(key, IPC_CREAT|0777)) == -1) &#123; perror("msgget error"); exit(1); &#125; // 打印消息队列ID及进程ID printf("My msqid is: %d.\n", msqid); printf("My pid is: %d.\n", getpid()); // 添加消息，类型为888 msg.mtype = 888; sprintf(msg.mtext, "hello, I'm client %d", getpid()); msgsnd(msqid, &amp;msg, sizeof(msg.mtext), 0); // 读取类型为777的消息 msgrcv(msqid, &amp;msg, 256, 999, 0); printf("Client: receive msg.mtext is: %s.\n", msg.mtext); printf("Client: receive msg.mtype is: %d.\n", msg.mtype); return 0;&#125; 信号量信号量（semaphore）与已经介绍过的 IPC 结构不同，它是一个计数器。信号量用于实现进程间的互斥与同步，而不是用于存储进程间通信数据。 特点 信号量用于进程间同步，若要在进程间传递数据需要结合共享内存 信号量基于操作系统的 PV 操作，程序对信号量的操作都是原子操作 每次对信号量的 PV 操作不仅限于对信号量值加 1 或减 1，而且可以加减任意正整数 支持信号量组 原型1234567#include &lt;sys/sem.h&gt;// 创建或获取一个信号量组：若成功返回信号量集ID，失败返回-1int semget(key_t key, int num_sems, int sem_flags);// 对信号量组进行操作，改变信号量的值：成功返回0，失败返回-1int semop(int semid, struct sembuf semoparray[], size_t numops);// 控制信号量的相关信息int semctl(int semid, int sem_num, int cmd, ...); 当semget创建新的信号量集合时，必须指定集合中信号量的个数（即num_sems），通常为1； 如果是引用一个现有的集合，则将num_sems指定为 0 。 在semop函数中，sembuf结构的定义如下：123456struct sembuf&#123; short sem_num; // 信号量组中对应的序号，0～sem_nums-1 short sem_op; // 信号量值在一次操作中的改变量 short sem_flg; // IPC_NOWAIT, SEM_UNDO&#125; 其中 sem_op 是一次操作中的信号量的改变量： 若sem_op &gt; 0，表示进程释放相应的资源数，将 sem_op 的值加到信号量的值上。如果有进程正在休眠等待此信号量，则换行它们 若sem_op &lt; 0，请求 sem_op 的绝对值的资源 若sem_op == 0，进程阻塞直到信号量的相应值为0 例子123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#include&lt;sys/sem.h&gt;// 联合体，用于semctl初始化union semun&#123; int val; /*for SETVAL*/ struct semid_ds *buf; unsigned short *array;&#125;;// 初始化信号量int init_sem(int sem_id, int value)&#123; union semun tmp; tmp.val = value; if(semctl(sem_id, 0, SETVAL, tmp) == -1) &#123; perror("Init Semaphore Error"); return -1; &#125; return 0;&#125;// P操作:// 若信号量值为1，获取资源并将信号量值-1// 若信号量值为0，进程挂起等待int sem_p(int sem_id)&#123; struct sembuf sbuf; sbuf.sem_num = 0; /*序号*/ sbuf.sem_op = -1; /*P操作*/ sbuf.sem_flg = SEM_UNDO; if(semop(sem_id, &amp;sbuf, 1) == -1) &#123; perror("P operation Error"); return -1; &#125; return 0;&#125;// V操作：// 释放资源并将信号量值+1// 如果有进程正在挂起等待，则唤醒它们int sem_v(int sem_id)&#123; struct sembuf sbuf; sbuf.sem_num = 0; /*序号*/ sbuf.sem_op = 1; /*V操作*/ sbuf.sem_flg = SEM_UNDO; if(semop(sem_id, &amp;sbuf, 1) == -1) &#123; perror("V operation Error"); return -1; &#125; return 0;&#125;// 删除信号量集int del_sem(int sem_id)&#123; union semun tmp; if(semctl(sem_id, 0, IPC_RMID, tmp) == -1) &#123; perror("Delete Semaphore Error"); return -1; &#125; return 0;&#125;int main()&#123; int sem_id; // 信号量集ID key_t key; pid_t pid; // 获取key值 if((key = ftok(".", 'z')) &lt; 0) &#123; perror("ftok error"); exit(1); &#125; // 创建信号量集，其中只有一个信号量 if((sem_id = semget(key, 1, IPC_CREAT|0666)) == -1) &#123; perror("semget error"); exit(1); &#125; // 初始化：初值设为0资源被占用 init_sem(sem_id, 0); if((pid = fork()) == -1) perror("Fork Error"); else if(pid == 0) /*子进程*/ &#123; sleep(2); printf("Process child: pid=%d\n", getpid()); sem_v(sem_id); /*释放资源*/ &#125; else /*父进程*/ &#123; sem_p(sem_id); /*等待资源*/ printf("Process father: pid=%d\n", getpid()); sem_v(sem_id); /*释放资源*/ del_sem(sem_id); /*删除信号量集*/ &#125; return 0;&#125; 上面的例子如果不加信号量，则父进程会先执行完毕。这里加了信号量让父进程等待子进程执行完以后再执行。 共享存储共享内存（Shared Memory），指两个或多个进程共享一个给定的存储区。 特点 共享内存是最快的一种 IPC，因为进程是直接对内存进行存取 因为多个进程可以同时操作，所以需要进行同步 信号量+共享内存通常结合在一起使用，信号量用来同步对共享内存的访问 原型123456789#include &lt;sys/shm.h&gt;// 创建或获取一个共享内存：成功返回共享内存ID，失败返回-1int shmget(key_t key, size_t size, int flag);// 连接共享内存到当前进程的地址空间：成功返回指向共享内存的指针，失败返回-1void *shmat(int shm_id, const void *addr, int flag);// 断开与共享内存的连接：成功返回0，失败返回-1int shmdt(void *addr);// 控制共享内存的相关信息：成功返回0，失败返回-1int shmctl(int shm_id, int cmd, struct shmid_ds *buf); 当用shmget函数创建一段共享内存时，必须指定其 size；而如果引用一个已存在的共享内存，则将 size 指定为0 。 当一段共享内存被创建以后，它并不能被任何进程访问。必须使用shmat函数连接该共享内存到当前进程的地址空间，连接成功后把共享内存区对象映射到调用进程的地址空间，随后可像本地空间一样访问。 shmdt函数是用来断开shmat建立的连接的。注意，这并不是从系统中删除该共享内存，只是当前进程不能再访问该共享内存而已。 shmctl函数可以对共享内存执行多种操作，根据参数 cmd 执行相应的操作。常用的是IPC_RMID（从系统中删除该共享内存）。 例子下面这个例子，使用了【共享内存+信号量+消息队列】的组合来实现服务器进程与客户进程间的通信。 共享内存用来传递数据 信号量用来同步 消息队列用来在客户端修改了共享内存后 通知服务器读取 server.c123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#include&lt;sys/shm.h&gt; // shared memory#include&lt;sys/sem.h&gt; // semaphore#include&lt;sys/msg.h&gt; // message queue#include&lt;string.h&gt; // memcpy// 消息队列结构struct msg_form &#123; long mtype; char mtext;&#125;;// 联合体，用于semctl初始化union semun&#123; int val; /*for SETVAL*/ struct semid_ds *buf; unsigned short *array;&#125;;// 初始化信号量int init_sem(int sem_id, int value)&#123; union semun tmp; tmp.val = value; if(semctl(sem_id, 0, SETVAL, tmp) == -1) &#123; perror("Init Semaphore Error"); return -1; &#125; return 0;&#125;// P操作:// 若信号量值为1，获取资源并将信号量值-1// 若信号量值为0，进程挂起等待int sem_p(int sem_id)&#123; struct sembuf sbuf; sbuf.sem_num = 0; /*序号*/ sbuf.sem_op = -1; /*P操作*/ sbuf.sem_flg = SEM_UNDO; if(semop(sem_id, &amp;sbuf, 1) == -1) &#123; perror("P operation Error"); return -1; &#125; return 0;&#125;// V操作：// 释放资源并将信号量值+1// 如果有进程正在挂起等待，则唤醒它们int sem_v(int sem_id)&#123; struct sembuf sbuf; sbuf.sem_num = 0; /*序号*/ sbuf.sem_op = 1; /*V操作*/ sbuf.sem_flg = SEM_UNDO; if(semop(sem_id, &amp;sbuf, 1) == -1) &#123; perror("V operation Error"); return -1; &#125; return 0;&#125;// 删除信号量集int del_sem(int sem_id)&#123; union semun tmp; if(semctl(sem_id, 0, IPC_RMID, tmp) == -1) &#123; perror("Delete Semaphore Error"); return -1; &#125; return 0;&#125;// 创建一个信号量集int creat_sem(key_t key)&#123; int sem_id; if((sem_id = semget(key, 1, IPC_CREAT|0666)) == -1) &#123; perror("semget error"); exit(-1); &#125; init_sem(sem_id, 1); /*初值设为1资源未占用*/ return sem_id;&#125;int main()&#123; key_t key; int shmid, semid, msqid; char *shm; char data[] = "this is server"; struct shmid_ds buf1; /*用于删除共享内存*/ struct msqid_ds buf2; /*用于删除消息队列*/ struct msg_form msg; /*消息队列用于通知对方更新了共享内存*/ // 获取key值 if((key = ftok(".", 'z')) &lt; 0) &#123; perror("ftok error"); exit(1); &#125; // 创建共享内存 if((shmid = shmget(key, 1024, IPC_CREAT|0666)) == -1) &#123; perror("Create Shared Memory Error"); exit(1); &#125; // 连接共享内存 shm = (char*)shmat(shmid, 0, 0); if((int)shm == -1) &#123; perror("Attach Shared Memory Error"); exit(1); &#125; // 创建消息队列 if ((msqid = msgget(key, IPC_CREAT|0777)) == -1) &#123; perror("msgget error"); exit(1); &#125; // 创建信号量 semid = creat_sem(key); // 读数据 while(1) &#123; msgrcv(msqid, &amp;msg, 1, 888, 0); /*读取类型为888的消息*/ if(msg.mtext == 'q') /*quit - 跳出循环*/ break; if(msg.mtext == 'r') /*read - 读共享内存*/ &#123; sem_p(semid); printf("%s\n",shm); sem_v(semid); &#125; &#125; // 断开连接 shmdt(shm); /*删除共享内存、消息队列、信号量*/ shmctl(shmid, IPC_RMID, &amp;buf1); msgctl(msqid, IPC_RMID, &amp;buf2); del_sem(semid); return 0;&#125; client.c123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#include&lt;sys/shm.h&gt; // shared memory#include&lt;sys/sem.h&gt; // semaphore#include&lt;sys/msg.h&gt; // message queue#include&lt;string.h&gt; // memcpy// 消息队列结构struct msg_form &#123; long mtype; char mtext;&#125;;// 联合体，用于semctl初始化union semun&#123; int val; /*for SETVAL*/ struct semid_ds *buf; unsigned short *array;&#125;;// P操作:// 若信号量值为1，获取资源并将信号量值-1// 若信号量值为0，进程挂起等待int sem_p(int sem_id)&#123; struct sembuf sbuf; sbuf.sem_num = 0; /*序号*/ sbuf.sem_op = -1; /*P操作*/ sbuf.sem_flg = SEM_UNDO; if(semop(sem_id, &amp;sbuf, 1) == -1) &#123; perror("P operation Error"); return -1; &#125; return 0;&#125;// V操作：// 释放资源并将信号量值+1// 如果有进程正在挂起等待，则唤醒它们int sem_v(int sem_id)&#123; struct sembuf sbuf; sbuf.sem_num = 0; /*序号*/ sbuf.sem_op = 1; /*V操作*/ sbuf.sem_flg = SEM_UNDO; if(semop(sem_id, &amp;sbuf, 1) == -1) &#123; perror("V operation Error"); return -1; &#125; return 0;&#125;int main()&#123; key_t key; int shmid, semid, msqid; char *shm; struct msg_form msg; int flag = 1; /*while循环条件*/ // 获取key值 if((key = ftok(".", 'z')) &lt; 0) &#123; perror("ftok error"); exit(1); &#125; // 获取共享内存 if((shmid = shmget(key, 1024, 0)) == -1) &#123; perror("shmget error"); exit(1); &#125; // 连接共享内存 shm = (char*)shmat(shmid, 0, 0); if((int)shm == -1) &#123; perror("Attach Shared Memory Error"); exit(1); &#125; // 创建消息队列 if ((msqid = msgget(key, 0)) == -1) &#123; perror("msgget error"); exit(1); &#125; // 获取信号量 if((semid = semget(key, 0, 0)) == -1) &#123; perror("semget error"); exit(1); &#125; // 写数据 printf("***************************************\n"); printf("* IPC *\n"); printf("* Input r to send data to server. *\n"); printf("* Input q to quit. *\n"); printf("***************************************\n"); while(flag) &#123; char c; printf("Please input command: "); scanf("%c", &amp;c); switch(c) &#123; case 'r': printf("Data to send: "); sem_p(semid); /*访问资源*/ scanf("%s", shm); sem_v(semid); /*释放资源*/ /*清空标准输入缓冲区*/ while((c=getchar())!='\n' &amp;&amp; c!=EOF); msg.mtype = 888; msg.mtext = 'r'; /*发送消息通知服务器读数据*/ msgsnd(msqid, &amp;msg, sizeof(msg.mtext), 0); break; case 'q': msg.mtype = 888; msg.mtext = 'q'; msgsnd(msqid, &amp;msg, sizeof(msg.mtext), 0); flag = 0; break; default: printf("Wrong input!\n"); /*清空标准输入缓冲区*/ while((c=getchar())!='\n' &amp;&amp; c!=EOF); &#125; &#125; // 断开连接 shmdt(shm); return 0;&#125; 小结 管道：速度慢，容量有限，只有父子进程能通讯 FIFO：任何进程间都能通讯，但速度慢 消息队列：容量受到系统限制，且要注意第一次读的时候，要考虑上一次没有读完数据的问题 信号量：不能传递复杂消息，只能用来同步 共享内存区：能够很容易控制容量，速度快，但要保持同步，比如一个进程在写的时候，另一个进程要注意读写的问题 死锁必要条件 互斥：每个资源要么已经分配给了一个进程，要么就是可用的 占有和等待：已经得到了某个资源的进程可以再请求新的资源 不可抢占：已经分配给一个进程的资源不能强制性地被抢占，它只能被占有它的进程显式地释放 环路等待：有两个或者两个以上的进程组成一条环路，该环路中的每个进程都在等待下一个进程所占有的资源 处理方法鸵鸟策略把头埋在沙子里，假装根本没发生问题，因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任务措施的方案会获得更高的性能，当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略，大多数操作系统，包括 Unix，Linux 和 Windows，处理死锁问题的办法仅仅是忽略它。 死锁检测与死锁恢复不试图阻止死锁，而是当检测到死锁发生时，采取措施进行恢复。 死锁检测，类似银行家算法 死锁恢复 死锁预防在程序运行之前预防发生死锁，即破坏死锁的四个比要条件。 死锁避免在程序运行时避免发生死锁。 检查状态是否是安全的：如果没有死锁发生，并且即使所有进程突然请求对资源的最大需求，也仍然存在某种调度次序能够使得每一个进程运行完毕，则称该状态是安全的。 安全状态的检测：银行家算法。 内存管理虚拟内存虚拟内存的目的是为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。 为了更好的管理内存，操作系统将内存抽象成地址空间。每个程序拥有自己的地址空间，这个地址空间被分割成多个块，每一块称为一页。这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中。当程序引用到不在物理内存中的页时，由硬件执行必要的映射，将缺失的部分装入物理内存并重新执行失败的指令。 从上面的描述中可以看出，虚拟内存允许程序不用将地址空间中的每一页都映射到物理内存，也就是说一个程序不需要全部调入内存就可以运行，这使得有限的内存运行大程序成为可能。 caozuoxitong04 分页系统地址映射内存管理单元（MMU）管理着地址空间和物理内存的转换，其中的页表（Page table）存储着页（程序地址空间）和页框（物理内存空间）的映射表。 一个虚拟地址分成两个部分，一部分存储页面号，一部分存储偏移量。 下图的页表存放着 16 个页，这 16 个页需要用 4 个比特位来进行索引定位。例如对于虚拟地址（0010 000000000100），前 4 位是存储页面号 2，读取表项内容为（110 1），页表项最后一位表示是否存在于内存中，1 表示存在。后 12 位存储偏移量。这个页对应的页框的地址为 （110 000000000100）。 caozuoxitong05 页面置换算法在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断从而将该页调入内存中。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘对换区中来腾出空间。 页面置换算法和缓存淘汰策略类似，可以将内存看成磁盘的缓存。在缓存系统中，缓存的大小有限，当有新的缓存到达时，需要淘汰一部分已经存在的缓存，这样才有空间存放新的缓存数据。 页面置换算法的主要目标是使页面置换频率最低（也可以说缺页率最低）。 最佳所选择的被换出的页面将是最长时间内不再被访问，通常可以保证获得最低的缺页率。是一种理论上的算法，因为无法知道一个页面多长时间不再被访问。 最近最久未使用（LRU）虽然无法知道将来要使用的页面情况，但是可以知道过去使用页面的情况。LRU 将最近最久未使用的页面换出。 为了实现 LRU，需要在内存中维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。 因为每次访问都需要更新链表，因此这种方式实现的 LRU 代价很高。 例子：14，7，0，7，1，0，1，2，1，2，6 caozuoxitong06 先进先出(FIFO)选择换出的页面是最先进入的页面，导致缺页率升高。 引用： https://github.com/CyC2018/CS-Notes/blob/master/notes/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E7%9B%AE%E5%BD%95.md https://www.cnblogs.com/zgq0/p/8780893.html]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[epoll的实现原理]]></title>
    <url>%2F2020%2F04%2F19%2Fepoll%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[写在开篇浅析epoll的实现原理。 recv先看下只监听一个socket的程序流程：123456789101112//创建socketint s = socket(AF_INET, SOCK_STREAM, 0); //绑定bind(s, ...)//监听listen(s, ...)//接受客户端连接int c = accept(s, ...)//接收客户端数据recv(c, ...);//将数据打印出来printf(...) 这是一段最基础的网络编程代码，先新建socket对象，依次调用bind、listen与accept，最后调用recv接收数据。recv是个阻塞方法，当程序运行到recv时，它会一直等待，直到接收到数据才往下执行。 下图的计算机中运行着A、B与C三个进程，其中进程A执行着上述基础网络程序，一开始，这3个进程都被操作系统的工作队列所引用，处于运行状态，会分时执行。 epoll01 创建socket当进程A执行到创建socket的语句时，操作系统会创建一个由文件系统管理的socket对象。这个socket对象包含了发送缓冲区、接收缓冲区与等待队列等成员。 epoll02 阻塞进程当程序执行到recv时，操作系统会将进程A从工作队列移动到该socket的等待队列中。 epoll03 唤醒进程当socket接收到数据后，操作系统将该socket等待队列上的进程重新放回到工作队列。 epoll04 那我们接下来要讨论的问题是如何同时监视多个socket的数据？ select下面是selec的用法：123456789101112int s = socket(AF_INET, SOCK_STREAM, 0); bind(s, ...);listen(s, ...);int fds[] = 存放需要监听的socket;while(1)&#123; int n = select(..., fds, ...) for(int i=0; i &lt; fds.count; i++)&#123; if(FD_ISSET(fds[i], ...))&#123; //fds[i]的数据处理 &#125; &#125;&#125; 先准备一个数组fds，让fds存放着所有需要监视的socket。然后调用select，如果fds中的所有socket都没有数据，select会阻塞，直到有一个socket接收到数据，select返回，唤醒进程。 select的实现思路很直接，假如程序同时监视如下图的sock1、sock2和sock3三个socket，那么在调用select之后，操作系统把进程A分别加入这三个socket的等待队列中。 epoll05 假如sock2接收到了数据，中断程序唤起进程A。 epoll06 所谓唤起进程，就是将进程从所有的等待队列中移除，加入到工作队列里面。 epoll07 将进程A从所有等待队列中移除，再加入到工作队列里面。 经由这些步骤，当进程A被唤醒后，它知道至少有一个socket接收了数据。程序只需遍历一遍socket列表，就可以得到就绪的socket。 这种简单方式行之有效，在几乎所有操作系统都有对应的实现。 但是简单的方法往往有缺点，主要是： 每次调用select都需要将进程加入到所有监视socket的等待队列，每次唤醒都需要从每个队列中移除。这里涉及了两次遍历，而且每次都要将整个fds列表传递给内核，有一定的开销。正是因为遍历操作开销大，出于效率的考量，才会规定select的最大监视数量，默认只能监视1024个socket。 进程被唤醒后，程序并不知道哪些socket收到数据，还需要遍历一次。 epoll先看下epoll的程序流程：12345678910111213int s = socket(AF_INET, SOCK_STREAM, 0); bind(s, ...)listen(s, ...)int epfd = epoll_create(...);epoll_ctl(epfd, ...); //将所有需要监听的socket添加到epfd中while(1)&#123; int n = epoll_wait(...) for(接收到数据的socket)&#123; //处理 &#125;&#125; 可以看到epoll将select中的“维护等待队列”和“阻塞进程”这两个操作分开，先用epoll_ctl维护等待队列，再调用epoll_wait阻塞进程。 epoll08 每次调用select都需要这两步操作，然而大多数应用场景中，需要监视的socket相对固定，并不需要每次都修改。epoll将这两个操作分开，先用epoll_ctl维护等待队列，再调用epoll_wait阻塞进程。显而易见地，效率就能得到提升。 我们接着讲epoll的工作流程： 创建 epoll 对象当某个进程调用epoll_create方法时，内核会创建一个eventpoll对象。而eventpoll维护着一个等待队列和一个就绪列表（rdlist）。 epoll09 维护监视列表创建epoll对象后，可以用epoll_ctl添加或删除所要监听的socket。 如果通过epoll_ctl添加sock1、sock2和sock3的监视，内核会将eventpoll添加到这三个socket的等待队列中。 epoll10 阻塞进程假设计算机中正在运行进程A和进程B，在某时刻进程A运行到了epoll_wait语句。如下图所示，内核会将进程A放入eventpoll的等待队列中，阻塞进程。 epoll11 唤醒进程当socket收到数据后，中断程序会操作eventpoll对象，而不是直接操作进程。 当socket接收到数据，中断程序一方面修改就绪列表，另一方面唤醒eventpoll等待队列中的进程，进程A再次进入运行状态（如下图）。也因为rdlist的存在，进程A可以知道哪些socket发生了变化。 epoll12 小结epoll在select和poll的基础上引入了eventpoll作为中间层，使用了先进的数据结构，是一种高效的多路复用技术。这里也以表格形式简单对比一下select、poll与epoll结束此文。 epoll13 整理自：https://my.oschina.net/editorial-story/blog/3052308#comments]]></content>
      <categories>
        <category>I/O</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Socket]]></title>
    <url>%2F2020%2F04%2F17%2FSocket%2F</url>
    <content type="text"><![CDATA[I/O模型一个输入操作通常包括两个阶段： 等待数据准备好 从内核（kernel）向进程复制数据 对于一个套接字上的输入操作，第一步通常涉及等待数据从网络中到达。当所等待数据到达时，它被复制到内核中的某个缓冲区。第二步就是把数据从内核缓冲区复制到应用进程缓冲区。 正是因为这两个阶段，linux系统产生了下面五种网络模式的方案。 阻塞式I/O 非阻塞式I/O I/O复用（select和poll） 信号驱动式I/O（SIGIO） 异步I/O（AIO） 阻塞式I/O（blocking IO）应用进程被阻塞，直到数据从内核缓冲区复制到应用进程缓冲区中才返回，一个典型的读操作流程大概是这样： Socket01 可以看到blocking IO的特点就是在IO执行的两个阶段都被block了。 非阻塞I/O（nonblocking IO）应用进程执行系统调用之后，内核返回一个错误码。应用进程可以继续执行，但是需要不断的执行系统调用来获知I/O是否完成，这种方式称为轮询（polling）。 由于CPU要处理更多的系统调用，因此这种模型的CPU利用率比较低。 当对一个nonblocking socket执行读操作时，流程是这个样子： Socket02 当用户进程发出read操作时，如果kernel中的数据还没有准备好，那么它并不会block用户进程，而是立刻返回一个error。从用户进程角度讲，它发起一个read操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦kernel中的数据准备好了，并且又再次收到了用户进程的system call，那么它马上就将数据拷贝到了用户内存，然后返回。 所以，nonblocking IO的特点是用户进程需要不断的主动询问kernel数据好了没有。 I/O多路复用（IO multiplexing）使用select或者poll等待数据，并且可以等待多个套接字中的任何一个变为可读。这一过程会被阻塞，当某一个套接字可读时返回，之后再使用recvfrom把数据从内核复制到进程中。 它可以让单个进程具有处理多个 I/O 事件的能力。又被称为Event Driven I/O，即事件驱动I/O。 如果一个Web服务器没有I/O复用，那么每一个Socket连接都需要创建一个线程去处理。如果同时有几万个连接，那么就需要创建相同数量的线程。相比于多进程和多线程技术，I/O复用不需要进程线程创建和切换的开销，系统开销更小。 Socket03 当用户进程调用了select，那么整个进程会被block，而同时，kernel会“监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。 这个图和blocking IO的图其实并没有太大的不同，事实上，还更差一些。因为这里需要使用两个system call(select和recvfrom)，而blocking IO只调用了一个system call(recvfrom)。但是，用select的优势在于它可以同时处理多个connection。 信号驱动I/O（signal driven IO）应用进程使用sigaction系统调用，内核立即返回，应用进程可以继续执行，也就是说等待数据阶段应用进程是非阻塞的。内核在数据到达时向应用进程发送SIGIO信号，应用进程收到之后在信号处理程序中调用recvfrom将数据从内核复制到应用进程中。 相比于非阻塞式I/O的轮询方式，信号驱动I/O的CPU利用率更高。 Socket04 异步I/O（asynchronous IO）应用进程执行aio_read系统调用会立即返回，应用进程可以继续执行，不会被阻塞，内核会在所有操作完成之后向应用进程发送信号。 异步I/O与信号驱动I/O的区别在于，异步I/O的信号是通知应用进程I/O完成，而信号驱动I/O的信号是通知应用进程可以开始I/O。 Socket05 用户进程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。 五大I/O模型比较 同步I/O：将数据从内核缓冲区复制到应用进程缓冲区的阶段（第二阶段），应用进程会阻塞。 异步I/O：第二阶段应用进程不会阻塞。 同步I/O包括阻塞式I/O、非阻塞式I/O、I/O复用和信号驱动I/O，它们的主要区别在第一个阶段。 非阻塞式I/O、信号驱动I/O和异步I/O在第一阶段不会阻塞。 Socket06 I/O复用select/poll/epoll都是I/O多路复用的具体实现，select出现的最早，之后是poll，再是epoll。 selectselect允许应用程序监视一组文件描述符，等待一个或者多个描述符成为就绪状态，从而完成I/O操作。 fd_set使用数组实现，数组大小使用FD_SETSIZE定义，所以只能监听少于 FD_SETSIZE数量的描述符。有三种类型的描述符类型：readset、writeset、exceptset，分别对应读、写、异常条件的描述符集合。 timeout为超时参数，调用select会一直阻塞直到有描述符的事件到达或者等待的时间超过timeout。 成功调用返回结果大于0，出错返回结果为-1，超时返回结果为0。 pollpoll的功能与select类似，也是等待一组描述符中的一个成为就绪状态。 select和poll的功能基本相同，不过在一些实现细节上有所不同。 select会修改描述符，而poll不会； select的描述符类型使用数组实现，FD_SETSIZE大小默认为1024，因此默认只能监听少于1024个描述符。如果要监听更多描述符的话，需要修改FD_SETSIZE之后重新编译；而poll没有描述符数量的限制； poll提供了更多的事件类型，并且对描述符的重复利用上比 select 高。 如果一个线程对某个描述符调用了select或者poll，另一个线程关闭了该描述符，会导致调用结果不确定。 select和poll速度都比较慢，每次调用都需要将全部描述符从应用进程缓冲区复制到内核缓冲区。 几乎所有的系统都支持select，但是只有比较新的系统支持poll。 epollepoll_ctl()用于向内核注册新的描述符或者是改变某个文件描述符的状态。已注册的描述符在内核中会被维护在一棵红黑树上，通过回调函数内核会将I/O准备好的描述符加入到一个链表中管理，进程调用epoll_wait()便可以得到事件完成的描述符。 从上面的描述可以看出，epoll只需要将描述符从进程缓冲区向内核缓冲区拷贝一次，并且进程不需要通过轮询来获得事件完成的描述符。 epoll仅适用于Linux OS。 epoll比select和poll更加灵活而且没有描述符数量限制。 epoll对多线程编程更有友好，一个线程调用了epoll_wait()另一个线程关闭了同一个描述符也不会产生像select和poll的不确定情况。 应用场景很容易产生一种错觉认为只要用epoll就可以了，select和poll都已经过时了，其实它们都有各自的使用场景。 select应用场景 select的timeout参数精度为微秒，而poll和epoll为毫秒，因此select更加适用于实时性要求比较高的场景，比如核反应堆的控制。 select可移植性更好，几乎被所有主流平台所支持。 poll 应用场景 poll 没有最大描述符数量的限制，如果平台支持并且对实时性要求不高，应该使用 poll 而不是 select。 epoll 应用场景 只需要运行在 Linux 平台上，有大量的描述符需要同时轮询，并且这些连接最好是长连接。 需要同时监控小于 1000 个描述符，就没有必要使用 epoll，因为这个应用场景下并不能体现 epoll 的优势。 需要监控的描述符状态变化多，而且都是非常短暂的，也没有必要使用 epoll。因为 epoll 中的所有描述符都存储在内核中，造成每次需要对描述符的状态改变都需要通过 epoll_ctl() 进行系统调用，频繁系统调用降低效率。并且 epoll 的描述符存储在内核，不容易调试。 参考： https://github.com/CyC2018/CS-Notes/blob/master/notes/Socket.md https://segmentfault.com/a/1190000003063859]]></content>
      <categories>
        <category>I/O</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ConcurrentHashMap源码分析-JDK1.8]]></title>
    <url>%2F2020%2F03%2F16%2FConcurrentHashMap%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-JDK1-8%2F</url>
    <content type="text"><![CDATA[浅析JDK1.8 ConcurrentHashMap源码，不得不感慨一下Doug Lea真的太强了！ 写在开篇先贴张图看下ConcurrentHashMap JDK 1.8的结构： CHM01 先大体介绍一下：ConcurrentHashMap JDK1.8抛弃了JDK1.7中原有的Segment分段锁，而采用了CAS + synchronized来保证并发安全性。 类的继承关系12public class ConcurrentHashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements ConcurrentMap&lt;K,V&gt;, Serializable &#123; 继承于抽象的AbstractMap，ConcurrentMap，Serializable这两个接口。 重要属性12345678910111213141516171819202122232425262728293031323334353637/** * 存储Node结点数据，默认初始大小为16 */transient volatile Node&lt;K,V&gt;[] table;/** * 扩容生成的新数组 */private transient volatile Node&lt;K,V&gt;[] nextTable;/** * 用于统计容器中Node结点数量，在下文计算结点数量会详细介绍 */private transient volatile long baseCount;/** * 控制 table 的初始化和扩容操作，默认为0 * -1：table正在初始化 * -N：有N-1个线程正在进行扩容操作 * &gt;0：table.length * 0.75 扩容阈值调为table容量大小的0.75倍 */private transient volatile int sizeCtl;/** * 扩容时，当前转移的位置 */private transient volatile int transferIndex;/** * 代表计数桶状态，默认空闲时0，忙是1 */private transient volatile int cellsBusy;/** * 计数桶，容器中计算Node的数量相加baseCount以及CounterCell[]的值 */private transient volatile CounterCell[] counterCells; NodeNode：将JDK1.7中存放数据的HashEntry改为Node。123456789101112131415static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; volatile V val; volatile Node&lt;K,V&gt; next; Node(int hash, K key, V val, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.val = val; this.next = next; &#125; // ...&#125; ForwardingNode：一个特殊的 Node 结点，hash值为-1，作为一个占位符放在原数组中表示当前结点在nextTbale中已经被移动。12345678910111213static final class ForwardingNode&lt;K,V&gt; extends Node&lt;K,V&gt; &#123; final Node&lt;K,V&gt;[] nextTable; ForwardingNode(Node&lt;K,V&gt;[] tab) &#123; super(MOVED, null, null, null); this.nextTable = tab; &#125; // ... Node&lt;K,V&gt; find(int h, Object k) &#123; // 扩容时，get()会调用到，在下文会分析 &#125;&#125; 构造方法ConcurrentHashMapJDK1.8构造方法中，是还没有初始化Node[]的，没有参数的构造方法是个空方法，如下：12public ConcurrentHashMap() &#123;&#125; 其余的构造方法都只是设置了sizeCtl，举个例子：12345678public ConcurrentHashMap(int initialCapacity) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(); int cap = ((initialCapacity &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ? MAXIMUM_CAPACITY : tableSizeFor(initialCapacity + (initialCapacity &gt;&gt;&gt; 1) + 1)); this.sizeCtl = cap;&#125; put()1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677public V put(K key, V value) &#123; return putVal(key, value, false);&#125;final V putVal(K key, V value, boolean onlyIfAbsent) &#123; if (key == null || value == null) throw new NullPointerException(); // 对key的hashcode做了处理，hash 计算多了一步 &amp; HASH_BITS（0x7fffffff） // 是为了消除高位上的负号，hash的负在ConcurrentHashMap中有特殊意义，表示在扩容或者是树结点 int hash = spread(key.hashCode()); // 计算该桶链表结点数，若大于TREEIFY_THRESHOLD，需要链表转成红黑树或者数组扩容 int binCount = 0; for (Node&lt;K,V&gt;[] tab = table;;) &#123; // 无限循环 Node&lt;K,V&gt; f; int n, i, fh; if (tab == null || (n = tab.length) == 0) // 表为空 // 初始化表 tab = initTable(); else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; // 该桶没有结点 if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) // 插入结点 break; &#125; else if ((fh = f.hash) == MOVED) // 正在扩容 // 协助扩容 tab = helpTransfer(tab, f); else &#123; // 该桶有结点 V oldVal = null; synchronized (f) &#123; // 加锁同步 if (tabAt(tab, i) == f) &#123; // 再次确认Node对象还是原来的那一个 if (fh &gt;= 0) &#123; // 链表结点 binCount = 1; for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; // key值相同 if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; // 插入新结点 if ((e = e.next) == null) &#123; pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; else if (f instanceof TreeBin) &#123; // 树结点 Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; if (binCount != 0) &#123; // 如果binCount大于等于转为红黑树的阈值 if (binCount &gt;= TREEIFY_THRESHOLD) // 转换或扩容 treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125; &#125; // binCount++，并判断是否需要扩容 addCount(1L, binCount); return null;&#125; 初始化数组12345678910111213141516171819202122232425262728private final Node&lt;K,V&gt;[] initTable() &#123; Node&lt;K,V&gt;[] tab; int sc; // 每次循环都会获取最新table while ((tab = table) == null || tab.length == 0) &#123; if ((sc = sizeCtl) &lt; 0) // 代表有线程在进行初始化工作了 Thread.yield(); // 让出cpu else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; // sizeCtl设为-1 try &#123; if ((tab = table) == null || tab.length == 0) &#123; // 再检查一遍数组是否为空 // table容量 int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY; @SuppressWarnings("unchecked") // 创建数组 Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; // 将其赋值给table变量 table = tab = nt; // 相当于n * 0.75 sc = n - (n &gt;&gt;&gt; 2); &#125; &#125; finally &#123; // 设置扩容阈值 sizeCtl = sc; &#125; break; &#125; &#125; return tab;&#125; treeifyBin()treeifyBin()不一定就会进行红黑树转换，也可能是仅仅做数组扩容。1234567891011121314151617181920212223242526272829private final void treeifyBin(Node&lt;K,V&gt;[] tab, int index) &#123; Node&lt;K,V&gt; b; int n, sc; if (tab != null) &#123; if ((n = tab.length) &lt; MIN_TREEIFY_CAPACITY) // table长度小于最小的长度 tryPresize(n &lt;&lt; 1); // 扩容，调整某个桶中结点数量过多的问题 else if ((b = tabAt(tab, index)) != null &amp;&amp; b.hash &gt;= 0) &#123; // 转为红黑树的情况 synchronized (b) &#123; // 加锁同步 if (tabAt(tab, index) == b) &#123; // 再次确认Node对象还是原来的那一个 TreeNode&lt;K,V&gt; hd = null, tl = null; for (Node&lt;K,V&gt; e = b; e != null; e = e.next) &#123; // 遍历桶中结点 // 创建TreeNode结点 TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt;(e.hash, e.key, e.val, null, null); if ((p.prev = tl) == null) // 该结点前驱为空 hd = p; // 设置为头结点 else // 尾结点的next设为p tl.next = p; // 尾结点赋值为p tl = p; &#125; // 设置table中下标为index的值为hd setTabAt(tab, index, new TreeBin&lt;K,V&gt;(hd)); &#125; &#125; &#125; &#125;&#125; 扩容什么时候会扩容 addCount()：使用put()插入元素时会调用addCount()，检查是否需要扩容 tryPresize()： 链表转红黑树过程，table容量小于MIN_TREEIFY_CAPACITY时 调用putAll()一次性加入大量元素时，会触发扩容 helpTransfer()：使用put()插入元素时，发现Node为fwd时，会协助扩容 addCount()123456789101112131415161718192021222324252627private final void addCount(long x, int check) &#123; // ... // 上面代码是计算容器中结点的数量，我们最后再讲 // 现在只需要知道下面代码中的s是即是加入新元素后容器容量大小 if (check &gt;= 0) &#123; // check为结点数量，有新元素加入成功才检查是否要扩容 Node&lt;K,V&gt;[] tab, nt; int n, sc; while (s &gt;= (long)(sc = sizeCtl) &amp;&amp; (tab = table) != null &amp;&amp; (n = tab.length) &lt; MAXIMUM_CAPACITY) &#123; // 容量大于当前扩容阈值并且小于最大扩容值才扩容 int rs = resizeStamp(n); // 看下面分析 if (sc &lt; 0) &#123; // 已有线程在进行扩容工作 if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex &lt;= 0) break; if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) transfer(tab, nt); &#125; // 没有线程在进行扩容 else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) transfer(tab, null); s = sumCount(); &#125; &#125;&#125; resizeStamp()在上面的代码中调用到这个方法，我们来看一下:1234567private static int RESIZE_STAMP_BITS = 16;private static final int RESIZE_STAMP_SHIFT = 32 - RESIZE_STAMP_BITS;static final int resizeStamp(int n) &#123; return Integer.numberOfLeadingZeros(n) | (1 &lt;&lt; (RESIZE_STAMP_BITS - 1));&#125; Integer.numberOfLeadingZeros(n)：计算n转换成32位二进制之后1前面有几个0。因为ConcurrentHashMap的容量一定是2的幂次方，所以不同的容量n前面0的个数一定不同，这样可以保证是在原容量为n的情况下进行扩容。 1 &lt;&lt; (RESIZE_STAMP_BITS - 1)：即是1&lt;&lt;15，表示为二进制即是高16位为0，低16位为1：10000 0000 0000 0000 1000 0000 0000 0000 所以resizeStamp()的返回值（rs）：高16位置0，第16位为1，低15位存放当前容量n，用于表示是对n的扩容。 rs与RESIZE_STAMP_SHIFT配合可以求出新的sizeCtl的值，分情况如下： sc &lt; 0：已经有线程在扩容，将sizeCtl+1并调用transfer()让当前线程参与扩容 sc &gt;= 0：没有线程在扩容，使用CAS将sizeCtl的值改为(rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2) rs即resizeStamp(n)，记temp=rs &lt;&lt; RESIZE_STAMP_SHIFT。如当前容量为8时rs的值：123456//rs0000 0000 0000 0000 1000 0000 0000 1000//temp = rs &lt;&lt; RESIZE_STAMP_SHIFT，即 temp = rs &lt;&lt; 16，左移16后temp最高位为1，所以temp成了一个负数1000 0000 0000 1000 0000 0000 0000 0000//sc = (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)1000 0000 0000 1000 0000 0000 0000 0010 那么在扩容时sizeCtl值的意义：高15位为容量n，第16位位并行扩容线程数+1。 tryPresize()和addCount()的实现很相似，不多赘述。123456789101112131415161718192021222324252627282930313233343536373839404142434445private final void tryPresize(int size) &#123; // size传入时已*2 // c：size 的 1.5 倍，再加 1，再往上取最近的 2 的 n 次方 int c = (size &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ? MAXIMUM_CAPACITY : tableSizeFor(size + (size &gt;&gt;&gt; 1) + 1); int sc; while ((sc = sizeCtl) &gt;= 0) &#123; // 没有其他线程在初始化、扩容 Node&lt;K,V&gt;[] tab = table; int n; // 这个if分支和前面的初始化数组的代码基本上是一样的，在这里，我们可以不用管这块代码 if (tab == null || (n = tab.length) == 0) &#123; n = (sc &gt; c) ? sc : c; if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; try &#123; if (table == tab) &#123; @SuppressWarnings("unchecked") Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = nt; sc = n - (n &gt;&gt;&gt; 2); &#125; &#125; finally &#123; sizeCtl = sc; &#125; &#125; &#125; else if (c &lt;= sc || n &gt;= MAXIMUM_CAPACITY) break; else if (tab == table) &#123; int rs = resizeStamp(n); if (sc &lt; 0) &#123; // 已有线程在进行扩容工作 Node&lt;K,V&gt;[] nt; if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex &lt;= 0) break; // 将sizeCtl加1，然后执行transfer()，此时nextTab不为null if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) transfer(tab, nt); &#125; // 将sizeCtl设置为(rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2 else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) // 调用transfer()，此时nextTab参数为null transfer(tab, null); &#125; &#125;&#125; helpTransfer()和addCount()的实现很相似，不多赘述。1234567891011121314151617181920final Node&lt;K,V&gt;[] helpTransfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt; f) &#123; Node&lt;K,V&gt;[] nextTab; int sc; if (tab != null &amp;&amp; (f instanceof ForwardingNode) &amp;&amp; (nextTab = ((ForwardingNode&lt;K,V&gt;)f).nextTable) != null) &#123; int rs = resizeStamp(tab.length); while (nextTab == nextTable &amp;&amp; table == tab &amp;&amp; (sc = sizeCtl) &lt; 0) &#123; // 已有线程在进行扩容工作 if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || transferIndex &lt;= 0) break; // sizeCtl加1，表示多一个线程进来协助扩容 if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) &#123; transfer(tab, nextTab); break; &#125; &#125; return nextTab; &#125; return table;&#125; transfer()我们可以看到上面三种方法最后都调用了transfer()，显然transfer()才是真正进行并行扩容的地方。 当外围调用此方法的时候，会保证第一个发起数据迁移的线程，nextTab参数为null，之后再调用此方法的时候，nextTab不会为null。 理解为有n个迁移任务，让每个线程每次负责一个小任务，每做完一个任务再检测是否有其他没做完的任务。 Doug Lea使用了一个stride（步长），每个线程每次负责迁移其中的一部分，如每次迁移 16 个小任务。所以需要一个全局的调度者来安排哪个线程执行哪几个任务，这个就是属性 transferIndex 的作用。 transfer()并没有实现所有的迁移任务，每次调用这个方法只实现了transferIndex往前stride个位置的迁移工作，其他的需要由外围来控制。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156private final void transfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab) &#123; // 参数为原数组，扩展数组 int n = tab.length, stride; //根据cpu个数找出扩容时的数组跨度大小即最小分组 if ((stride = (NCPU &gt; 1) ? (n &gt;&gt;&gt; 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE) stride = MIN_TRANSFER_STRIDE; if (nextTab == null) &#123; // 普通扩容nextTab为空，竞争帮助扩容时不为空 // 初始化nextTable try &#123; @SuppressWarnings("unchecked") Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n &lt;&lt; 1]; nextTab = nt; &#125; catch (Throwable ex) &#123; sizeCtl = Integer.MAX_VALUE; return; &#125; nextTable = nextTab; // 当前转移的位置，说明是逆序迁移 transferIndex = n; &#125; int nextn = nextTab.length; // 扩容时的特殊节点，标明此节点正在进行迁移 ForwardingNode&lt;K,V&gt; fwd = new ForwardingNode&lt;K,V&gt;(nextTab); // 当前线程是否需要继续寻找下一个可处理的节点 boolean advance = true; // 所有桶是否都已迁移完成。 boolean finishing = false; for (int i = 0, bound = 0;;) &#123; // 无限循环 Node&lt;K,V&gt; f; int fh; // 此循环的作用是确定当前线程要迁移的桶的范围或通过更新i的值确定当前范围内下一个要处理的节点 while (advance) &#123; int nextIndex, nextBound; // i为当前正在处理的Node数组下标，每次处理一个Node节点就会自减1 if (--i &gt;= bound || finishing) // 检查结束条件 advance = false; else if ((nextIndex = transferIndex) &lt;= 0) &#123; // 迁移总进度&lt;=0，表示所有桶都已迁移完成 i = -1; advance = false; &#125; else if (U.compareAndSwapInt (this, TRANSFERINDEX, nextIndex, nextBound = (nextIndex &gt; stride ? nextIndex - stride : 0))) &#123; // 当前线程迁移桶的范围 bound = nextBound; i = nextIndex - 1; advance = false; &#125; &#125; /** * 1. 全部桶迁移完成 * 2. 下面"i = n"后，再次进入循环时要做的边界检查 */ if (i &lt; 0 || i &gt;= n || i + n &gt;= nextn) &#123; int sc; if (finishing) &#123; // 所有线程迁移完成 nextTable = null; // 替换table table = nextTab; // sizeCtl为新容量的0.75倍 sizeCtl = (n &lt;&lt; 1) - (n &gt;&gt;&gt; 1); return; &#125; if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) &#123; // 参与扩容线程数-1。 if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) // 根据前面addCount()或tryPresize()中的sizeCtl+2这里就有-2，相等时说明没有线程在参与扩容了 return; finishing = advance = true; i = n; // 赋值i为n，让其进入上面if进行是否结束的检查，并完成扩容后续操作 &#125; &#125; else if ((f = tabAt(tab, i)) == null) // 原数组i位置无结点 advance = casTabAt(tab, i, null, fwd); // 插入fwd结点 else if ((fh = f.hash) == MOVED) // 实际是检查上一步为null时CAS是否成功 advance = true; // 之后在上面的while中变更i后继续 else &#123; // 转移该桶 synchronized (f) &#123; // 加锁同步 if (tabAt(tab, i) == f) &#123; // 低位结点，高位结点 Node&lt;K,V&gt; ln, hn; if (fh &gt;= 0) &#123; // 链表结点 // 由于n是2的幂次方（所有二进制位中只有一个1) // 如n=16(0001 0000)，第4位为1，那么hash&amp;n后的值第4位只能为0或1。所以可以根据hash&amp;n的结果将所有结点分为两部分 int runBit = fh &amp; n; Node&lt;K,V&gt; lastRun = f; // 找出最后一段完整的fh&amp;n不变的链表，这样最后这一段链表就不用重新创建新结点了 for (Node&lt;K,V&gt; p = f.next; p != null; p = p.next) &#123; int b = p.hash &amp; n; if (b != runBit) &#123; runBit = b; lastRun = p; &#125; &#125; if (runBit == 0) &#123; // runBit=0，表示此Node为低位Node ln = lastRun; hn = null; &#125; else &#123; // 此Node为高位Node hn = lastRun; ln = null; &#125; // 迁移lastRun之前的结点 for (Node&lt;K,V&gt; p = f; p != lastRun; p = p.next) &#123; int ph = p.hash; K pk = p.key; V pv = p.val; if ((ph &amp; n) == 0) ln = new Node&lt;K,V&gt;(ph, pk, pv, ln); else hn = new Node&lt;K,V&gt;(ph, pk, pv, hn); &#125; // 低位链表放在i处 setTabAt(nextTab, i, ln); // 高位链表放在i+n处 setTabAt(nextTab, i + n, hn); // 在原table中设置ForwardingNode节点以提示该桶扩容完成 setTabAt(tab, i, fwd); advance = true; &#125; else if (f instanceof TreeBin) &#123; // 红黑树结点 TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f; TreeNode&lt;K,V&gt; lo = null, loTail = null; TreeNode&lt;K,V&gt; hi = null, hiTail = null; int lc = 0, hc = 0; for (Node&lt;K,V&gt; e = t.first; e != null; e = e.next) &#123; int h = e.hash; TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt; (h, e.key, e.val, null, null); if ((h &amp; n) == 0) &#123; if ((p.prev = loTail) == null) lo = p; else loTail.next = p; loTail = p; ++lc; &#125; else &#123; if ((p.prev = hiTail) == null) hi = p; else hiTail.next = p; hiTail = p; ++hc; &#125; &#125; // 扩容后结点数量太少降为链表 ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) : (hc != 0) ? new TreeBin&lt;K,V&gt;(lo) : t; hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) : (lc != 0) ? new TreeBin&lt;K,V&gt;(hi) : t; setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); advance = true; &#125; &#125; &#125; &#125; &#125;&#125; 代码有点长，在这里小结一下，这个方法主要分成两个部分： while循环：确定当前线程要迁移的桶的范围以及通过更新i的值确定当前范围内下一个要处理的结点 其他代码：转移桶中结点 get()这里我们主要关注扩容时，get()怎么做：1234567891011121314151617181920public V get(Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek; int h = spread(key.hashCode()); if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (e = tabAt(tab, (n - 1) &amp; h)) != null) &#123; if ((eh = e.hash) == h) &#123; if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) return e.val; &#125; else if (eh &lt; 0) // 在迁移或都是TreeBin // 调用节点对象的find方法查找值 return (p = e.find(h, key)) != null ? p.val : null; while ((e = e.next) != null) &#123; if (e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) return e.val; &#125; &#125; return null;&#125; 内部类ForwardingNode中的find()：这里的查找，是去新Node数组nextTable中查找的，过程与HashMap相似，不多赘述。12345678910111213141516171819202122232425Node&lt;K,V&gt; find(int h, Object k) &#123; // loop to avoid arbitrarily deep recursion on forwarding nodes outer: for (Node&lt;K,V&gt;[] tab = nextTable;;) &#123; Node&lt;K,V&gt; e; int n; if (k == null || tab == null || (n = tab.length) == 0 || (e = tabAt(tab, (n - 1) &amp; h)) == null) return null; for (;;) &#123; int eh; K ek; if ((eh = e.hash) == h &amp;&amp; ((ek = e.key) == k || (ek != null &amp;&amp; k.equals(ek)))) return e; if (eh &lt; 0) &#123; if (e instanceof ForwardingNode) &#123; tab = ((ForwardingNode&lt;K,V&gt;)e).nextTable; continue outer; &#125; else return e.find(h, k); &#125; if ((e = e.next) == null) return null; &#125; &#125;&#125; 容器结点数量统计容器大小其实是用了两种思路： CAS方式直接递增：在线程竞争不大的时候，直接使用CAS操作递增baseCount值即可，这里说的竞争不大指的是CAS操作不会失败的情况 分而治之桶计数：若出现了CAS操作失败的情况，则证明此时有线程竞争了，计数方式从CAS方式转变为分而治之的桶计数方式 countCell这里解释一下什么是计数桶： CHM02 这样减少了线程的冲突，查询总数的时候sum = countCell[0] + countCell[1] + countCell[2] + countCell[3] 在设计中，使用了分而治之的思想，将每一个计数都分散到各个countCell对象里面（下面称之为桶），使竞争最小化，又使用了CAS操作，就算有竞争，也可以对失败了的线程进行其他的处理。乐观锁的实现方式与悲观锁不同之处就在于乐观锁可以对竞争失败了的线程进行其他策略的处理，而悲观锁只能等待锁释放，所以这里使用CAS操作对竞争失败的线程做了其他处理，很巧妙的运用了CAS乐观锁。 代码实现CounterCell：1234@sun.misc.Contended static final class CounterCell &#123; volatile long value; CounterCell(long x) &#123; value = x; &#125;&#125; 接着补上addCount()我们在上面跳过的部分：12345678910111213141516171819202122232425262728293031323334private final void addCount(long x, int check) &#123; CounterCell[] as; long b, s; if ((as = counterCells) != null || !U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x)) &#123; /** * 进入此语句块有两种可能 * 1.counterCells被初始化完成了，不为null * 2.CAS操作递增baseCount值失败了，说明有竞争 */ CounterCell a; long v; int m; // 标志是否存在竞争 boolean uncontended = true; /** * 条件： * 1.计数桶是否还没初始化，若as == null，进入语句块 * 2.计数桶是否为空，若桶为空进入语句块 * 3.用一个线程变量随机数，与上（桶大小-1），若桶的这个位置为空，进入语句块 * 4.到这里说明桶已经初始化了，且随机的这个位置不为空，尝试CAS操作使桶加1，失败设置uncontended值并进入语句块 */ if (as == null || (m = as.length - 1) &lt; 0 || (a = as[ThreadLocalRandom.getProbe() &amp; m]) == null || !(uncontended = U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))) &#123; // 初始化或扩容counterCell[] fullAddCount(x, uncontended); return; &#125; if (check &lt;= 1) return; s = sumCount(); &#125; // ...&#125; 初始化CounterCell[]123456789101112131415161718192021222324252627282930313233343536373839404142private final void fullAddCount(long x, boolean wasUncontended) &#123; int h; // 线程随机变量 if ((h = ThreadLocalRandom.getProbe()) == 0) &#123; ThreadLocalRandom.localInit(); h = ThreadLocalRandom.getProbe(); wasUncontended = true; &#125; boolean collide = false; for (;;) &#123; CounterCell[] as; CounterCell a; int n; long v; // 此时计数桶为null，不走这部分if块 if ((as = counterCells) != null &amp;&amp; (n = as.length) &gt; 0) &#123; // ... &#125; // 进入此语句块进行计数桶的初始化 else if (cellsBusy == 0 &amp;&amp; counterCells == as &amp;&amp; U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) &#123; // CAS设置cellsBusy=1，表示现在计数桶Busy中 boolean init = false; try &#123; if (counterCells == as) &#123; // 再次确认计数桶为空 // 初始化一个长度为2的计数桶 CounterCell[] rs = new CounterCell[2]; // h为一个随机数，与上1则代表结果为0、1中随机的一个 // 也就是在0、1下标中随便选一个计数桶，x=1，放入1的值代表增加1个容量 rs[h &amp; 1] = new CounterCell(x); // 将初始化好的计数桶赋值给ConcurrentHashMap counterCells = rs; init = true; &#125; &#125; finally &#123; // 最后将busy标识设置为0，表示不busy了 cellsBusy = 0; &#125; if (init) break; &#125; // 若有线程同时来初始化计数桶，则没有抢到busy资格的线程就先来CAS递增baseCount else if (U.compareAndSwapLong(this, BASECOUNT, v = baseCount, v + x)) break; &#125;&#125; 扩容CounterCell[]从上面的分析中我们知道，计数桶初始化之后长度为2，在竞争大的时候肯定是不够用的，所以一定有计数桶的扩容操作：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485private final void fullAddCount(long x, boolean wasUncontended) &#123; int h; if ((h = ThreadLocalRandom.getProbe()) == 0) &#123; ThreadLocalRandom.localInit(); h = ThreadLocalRandom.getProbe(); wasUncontended = true; &#125; boolean collide = false; for (;;) &#123; CounterCell[] as; CounterCell a; int n; long v; // 计数桶初始化好了，进入该if块 if ((as = counterCells) != null &amp;&amp; (n = as.length) &gt; 0) &#123; if ((a = as[(n - 1) &amp; h]) == null) &#123; // 从计数桶数组随机选一个计数桶，若为null表示该桶位还没线程递增过 if (cellsBusy == 0) &#123; // 计数桶数组busy状态是否被标识 // 创建一个计数桶 CounterCell r = new CounterCell(x); // 标志计数桶数组busy状态 if (cellsBusy == 0 &amp;&amp; U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) &#123; boolean created = false; try &#123; CounterCell[] rs; int m, j; if ((rs = counterCells) != null &amp;&amp; (m = rs.length) &gt; 0 &amp;&amp; rs[j = (m - 1) &amp; h] == null) &#123; // 将刚刚创建的计数桶赋值给对应位置 rs[j] = r; created = true; &#125; &#125; finally &#123; // 标识不busy了 cellsBusy = 0; &#125; if (created) break; continue; &#125; &#125; collide = false; &#125; else if (!wasUncontended) wasUncontended = true; // 走到这里代表计数桶不为null，尝试递增计数桶 else if (U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x)) break; else if (counterCells != as || n &gt;= NCPU) collide = false; // 若CAS操作失败了，到了这里，会先进入一次下面的if块，然后再走一次刚刚的for循环 // 若是第二次for循环，collide=true，则不会走进去 else if (!collide) collide = true; // 计数桶扩容，一个线程若走了两次for循环，也就是进行了多次CAS操作递增计数桶失败了 // 则进行计数桶扩容，CAS标示计数桶busy中 else if (cellsBusy == 0 &amp;&amp; U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) &#123; try &#123; // 确认计数桶还是同一个 if (counterCells == as) &#123; // 将长度扩大到2倍 CounterCell[] rs = new CounterCell[n &lt;&lt; 1]; // 遍历旧计数桶，将引用直接搬过来 for (int i = 0; i &lt; n; ++i) rs[i] = as[i]; // 赋值 counterCells = rs; &#125; &#125; finally &#123; // 取消busy状态 cellsBusy = 0; &#125; collide = false; continue; &#125; // 重新设置线程随机数 h = ThreadLocalRandom.advanceProbe(h); &#125; else if (cellsBusy == 0 &amp;&amp; counterCells == as &amp;&amp; U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) &#123; // 初始化计数桶... &#125; // 初始化计数桶没抢到计数桶数组busy资格才能走到这 else if (U.compareAndSwapLong(this, BASECOUNT, v = baseCount, v + x)) break; &#125;&#125; 小结一下： 在CAS操作递增计数桶失败了3次之后，会进行扩容计数桶操作，注意此时同时进行了两次随机定位计数桶来进行CAS递增的，所以此时可以保证大概率是因为计数桶不够用了，才会进行计数桶扩容 计数桶长度增加到两倍长度，数据直接遍历迁移过来，由于计数桶不像HashMap数据结构那么复杂，有hash算法的影响，加上计数桶只是存放一个long类型的计数值而已，所以直接赋值引用即可 参考：https://blog.csdn.net/qq_41737716/article/details/90549847https://blog.csdn.net/tp7309/article/details/76532366https://www.jianshu.com/p/81d848ea6c1a]]></content>
      <categories>
        <category>Java乐园</category>
      </categories>
      <tags>
        <tag>HashMap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java代理模式]]></title>
    <url>%2F2020%2F03%2F10%2FJava%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[Java代理模式: 为其他对象提供一种代理以控制对这个对象的访问。 在学习代理模式之前建议先了解Java反射技术 概述为其他对象提供一种代理以控制对这个对象的访问。 如何理解呢，我先给大家举一个贴近生活的例子：你的公司是一家软件公司，你是一位软件工程师。客户带着需求去找公司显然不会直接和你谈，而是去找商务谈，此时客户会认为商务就代表公司。 proxy1 显然客户是通过商务去访问软件工程师的，那么商务（代理对象）的意义在于什么呢？商务可以进行谈判，软件的价格、交付、进度的时间节点等，或者项目完成后的商务追讨应收账单等，这些都不需要软件工程师来处理。因此，代理的作用就是，在真实对象访问之前或者之后加入对应的逻辑，或者根据其他规则是否使用真实对象， 显然在这个例子中商务控制了客户对软件工程师的访问。 经过上面的讨论，我们知道商务和软件工程师是代理和被代理的关系，客户就是经过商务去访问软件工程师的。此时客户就是程序中的调用着，商务就是代理对象，软件工程师就是真实对象。我们需要在调用者调用对象之前产生一个代理对象，而这个代理对象需要和真实对象建立代理关系，所以代理必须分为两个步骤： 代理对象和真实对象建立代理关系。 实现代理对象的代理逻辑方法。 静态代理 抽象角色我们先定义一个工程师的接口，他有实现用户需求的方法。 123public interface Icoder &#123; public void implDemands(String demandName);&#125; 真实角色接着定义一个Java工程师类，他通过Java语言实现需求。 12345678910public class JavaCoder implements ICoder&#123; private String name; public JavaCoder(String name)&#123; this.name = name; &#125; @Override public void implDemands(String demandName) &#123; System.out.println(name + " implemented demand:" + demandName + " in JAVA!"); &#125;&#125; 代理角色委屈一下商务，将其命名为工程师代理类，同时让他实现ICoder接口。 12345678910public class CoderProxy implements ICoder&#123; private ICoder coder; public CoderProxy(ICoder coder)&#123; this.coder = coder; &#125; @Override public void implDemands(String demandName) &#123; coder.implDemands(demandName); &#125;&#125; 上面一个接口，两个类，就实现了代理模式。Are you kidding me？这么简单？是的，就是这么简单。 我们通过一个场景类，模拟用户找商务提需求。12345678910public class Customer &#123; public static void main(String args[])&#123; //定义一个java码农 ICoder coder = new JavaCoder("Zhang"); //定义一个产品经理 ICoder proxy = new CoderProxy(coder); //让产品经理实现一个需求 proxy.implDemands(); &#125;&#125; 运行程序结果如下：1Zhang implemented demand:Add user manageMent in JAVA! 这样我们就可以知道代理模式的优点了： 职责清晰真实角色只需关注业务逻辑的实现，非业务逻辑部分，后期通过代理类完成即可。 高扩展性 不管真实角色如何变化，由于接口是固定的，代理类无需做任何改动。 动态代理前面讲的主要是静态代理。那么什么是动态代理呢？ 假设有这么一个需求，在方法执行前和执行完成后，打印系统时间。这很简单嘛，非业务逻辑，只要在代理类调用真实角色的方法前、后输出时间就可以了。像上例，只有一个implDemands方法，这样实现没有问题。但如果真实角色有10个方法，那么我们要写10遍完全相同的代码。有点追求的码农，肯定会对这种方法感到非常不爽。让我们接着往下看： 代理类在程序运行时创建的代理方式被称为动态代理。也就是说，代理类并不需要在Java代码中定义，而是在运行时动态生成的。相比于静态代理， 动态代理的优势在于可以很方便的对代理类的函数进行统一的处理，而不用修改每个代理类的函数。对于上例打印时间的需求，通过使用动态代理，我们可以做一个“统一指示”，对所有代理类的方法进行统一处理，而不用逐一修改每个方法。下面我们来具体介绍下如何使用动态代理方式实现我们的需求。 Java中有多种动态代理技术，接下来我们会谈论两种最常使用的动态代理技术：JDK和CGLIB。 JDK动态代理JDK动态代理是JDK自带的功能，它必须借助一个接口才能产生代理对象 与静态代理相比，抽象角色、真实角色都没有变化。变化的只有代理类。因此，抽象角色、真实角色，参考ICoder和JavaCoder。 在使用动态代理时，我们需要定义一个位于代理类与委托类之间的中介类，也叫动态代理类，这个类被要求实现InvocationHandler接口：1234567891011121314151617181920212223242526272829public class CoderDynamicProxy implements InvocationHandler&#123; //真实对象 private Object target; /** * 建立代理对象和真实对象的代理关系 * @param target真实对象 * @return 代理对象 **/ public Object bind(Object target)&#123; this.target = target; return Proxy.newProxyInstance(target.getClass().getClassLoader(), target.getClass().getInterfaces(), this); &#125; /** * @param proxy 代理对象 * @param method 当前调度的方法 * @param args 当前方法参数 * @return 代理结果返回 **/ @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println(System.currentTimeMillis()); //这行代码相当于调度真实对象的方法（只是通过反射实现而已） Object result = method.invoke(target, args); System.out.println(System.currentTimeMillis()); return result; &#125;&#125; 当我们调用代理类对象的方法时，这个“调用”会转送到中介类的invoke方法中，参数method标识了我们具体调用的是代理类的哪个方法，args为这个方法的参数。 我们通过一个场景类，模拟用户找产品经理更改需求。123456789public class DynamicClient &#123; public static void main(String args[])&#123; CoderDynamicProxy jdk = new CoderDynamicProxy(); //绑定关系 ICoder proxy = (ICoder)jdk.bind(new JavaCoder("Zhang")); //此时Icode对象已经是一个代理对象，它会进入逻辑方法invoke中 proxy.implDemands("Modify user management"); &#125;&#125; 执行结果如下：1231556694750883Zhang implemented demand:Modify user management in JAVA!1556694750883 通过上述代码，就实现了，在执行委托类的所有方法前、后打印时间。还是那个熟悉的小张，但我们并没有创建代理类，也没有时间ICoder接口。这就是动态代理。 CGLIB动态代理JDK动态代理必须提供接口才能使用，在一些不能提供接口的环境中，只能采取其他第三方技术，比如：CGLIB动态代理。它的优势在于不需要提供接口，只要一个非抽象类就能实现动态代理。 我们先修改一下JavaCoder，不实现ICoder接口12345678910public class JavaCoder &#123; private String name; public JavaCoder(String name)&#123; this.name = name; &#125; public void implDemands(String demandName) &#123; System.out.println(name + " implemented demand:" + demandName + " in JAVA!"); &#125;&#125; 接下来使用CGLIB动态代理技术，如下代码所示：12345678910111213141516171819202122232425262728293031323334public class CoderDynamicProxy implements MethodInterceptor &#123; /** * 生成CGLIB代理对象 * @param cls -- Class类 * @return Class类的CGLIB代理对象 **/ public Object getProxy(Class cls, String name)&#123; //CGLIB增强类对象 Enhancer enhancer = new Enhancer(); //设置增强类型 enhancer.setSuperclass(cls); //定义代理逻辑对象为当前对象，要求当前对象实现MethodInterceptor方法 enhancer.setCallback(this); //生成并返回代理对象 return enhancer.create(new Class[]&#123;String.class&#125;,new Object[]&#123;name&#125;); &#125; /** * 代理逻辑方法 * @param proxy 代理对象 * @param method 方法 * @param args 方法参数 * @param methodProxy 方法代理 * @return 代理逻辑返回 **/ @Override public Object intercept(Object proxy, Method method, Object[] args, MethodProxy methodProxy) throws Throwable &#123; System.out.println(System.currentTimeMillis()); //这行代码相当于调度真实对象的方法（只是通过反射实现而已） Object result = methodProxy.invokeSuper(proxy, args); System.out.println(System.currentTimeMillis()); return result; &#125;&#125; 测试CGLIB动态代理：123456789public class DynamicClient &#123; public static void main(String args[])&#123; CoderDynamicProxy cglib = new CoderDynamicProxy(); JavaCoder proxy = (JavaCoder)cglib.getProxy(JavaCoder.class, "zhang"); proxy.implDemands("Modify user management"); &#125;&#125; 执行结果如下：1231556694088088zhang implemented demand:Modify user management in JAVA!1556694088104 动态代理的优点 Proxy类的代码量被固定下来，不会因为业务的逐渐庞大而庞大 可以实现AOP编程，实际上静态代理也可以实现，总的来说，AOP可以算作是代理模式的一个典型应用 解耦，通过参数就可以判断真实类，不需要事先实例化，更加灵活多变]]></content>
      <categories>
        <category>Java乐园</category>
      </categories>
      <tags>
        <tag>代理模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ConcurrentModificationException]]></title>
    <url>%2F2020%2F03%2F10%2FConcurrentModificationException%2F</url>
    <content type="text"><![CDATA[浅析ConcurrentModificationException出现的原因。 写在开篇ConcurrentModificationException，也就是并发修改异常，当我们使用一些Java集合类时，有时需要遍历集合并根据条件remove其中的元素，此时就有可能出现该异常。 接下来我们通过下面这个例子来分析一下：12345678910111213141516public class Solution &#123; public static void main(String[] args) &#123; List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); list.add(0); list.add(1); list.add(2); list.add(3); list.add(4); for (Integer i : list) &#123; System.out.println(i); if (i == 2) list.remove(i); &#125; &#125;&#125; CME01 上图中我们可以看到，在程序输出“3”之前出现了ConcurrentModificationException，也就是说，异常是在遍历下一个元素时抛出的。也就是，删除和遍历产生了冲突。 从ArrayList内部看异常出现的原因ArrayList的遍历在例子中使用了foreach遍历元素，实际上，foreach遍历的原理就是使用Iterator进行迭代，可以通过javap进行反编译即可查看到相关的字节码指令（看64行的注释）：123456789101112......54: invokestatic #19 // Method java/lang/Integer.valueOf:(I)Ljava/lang/Integer;57: invokeinterface #25, 2 // InterfaceMethod java/util/List.add:(Ljava/lang/Object;)Z62: pop63: aload_164: invokeinterface #31, 1 // InterfaceMethod java/util/List.iterator:()Ljava/util/Iterator;69: astore_370: goto 10673: aload_374: invokeinterface #35, 1 // InterfaceMethod java/util/Iterator.next:()Ljava/lang/Object;79: checkcast #20 // class java/lang/Integer...... 这是因为集合类所实现的Collection接口继承了Iterable这个接口，因此都能够使用foreach的方式遍历。在ArrayList所实现的iterator方法中，返回的是ArrayList的内部类Itr。在Itr实现的next方法中，会先判断modCount和expectedModCount两个值是否相等，改变记录下标cursor和lastRet的值，从0下标开始返回ArrayList内部数组的值。1234567891011121314151617181920212223242526272829303132333435363738394041424344public Iterator&lt;E&gt; iterator() &#123; return new Itr();&#125;private class Itr implements Iterator&lt;E&gt; &#123; protected int limit = ArrayList.this.size; int cursor; // index of next element to return int lastRet = -1; // index of last element returned; -1 if no such int expectedModCount = modCount; // modCount是AbstractList的成员变量，表示对List的修改次数 public boolean hasNext() &#123; return cursor &lt; limit; &#125; public E next() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException(); int i = cursor; if (i &gt;= limit) throw new NoSuchElementException(); Object[] elementData = ArrayList.this.elementData; if (i &gt;= elementData.length) throw new ConcurrentModificationException(); cursor = i + 1; return (E) elementData[lastRet = i]; &#125; public void remove() &#123; if (lastRet &lt; 0) throw new IllegalStateException(); if (modCount != expectedModCount) throw new ConcurrentModificationException(); try &#123; ArrayList.this.remove(lastRet); cursor = lastRet; lastRet = -1; expectedModCount = modCount; limit--; &#125; catch (IndexOutOfBoundsException ex) &#123; throw new ConcurrentModificationException(); &#125; &#125;&#125; ArrayList的删除在next方法中，首先会判断两个表示修改次数的值是否相等，一次来自List的修改，一次来自Iterator的修改，如果不同就抛出ConcurrentModificationException。 接着看下ArrayList的remove()：12345678910111213141516171819202122232425public boolean remove(Object o) &#123; if (o == null) &#123; for (int index = 0; index &lt; size; index++) if (elementData[index] == null) &#123; fastRemove(index); return true; &#125; &#125; else &#123; for (int index = 0; index &lt; size; index++) if (o.equals(elementData[index])) &#123; fastRemove(index); return true; &#125; &#125; return false;&#125;private void fastRemove(int index) &#123; modCount++; int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work&#125; 可以看到，通过remove方法删除元素最终是调用的fastRemove()，改变modCount的值，然后通过调用arraycopy把index后的所有元素都往前移动，然后size-1。 真相大白回到例子中，代码list.remove(bean)对List进行了一次修改，那么modCount+1，但没有同步到Itr中的expectedModCount。因此，在list.remove(bean)后，iterator调用next()访问下一个元素时，就会导致modCount != expectedModCount，抛出异常。但是，在Itr的remove方法的实现中，每次操作都会把modCount同步到expectedModCount，这样，就不会抛出异常了。因此，正确的遍历删除如下：1234567Iterator&lt;Integer&gt; iterator = list.iterator();while (iterator.hasNext()) &#123; Integer i = iterator.next(); System.out.println(i); if (i == 2) iterator.remove();&#125; 另一种情况如果改变删除的元素为倒数第二个，就是 i = 3 时：12345for (Integer i : list) &#123; System.out.println(i); if (i == 3) list.remove(i);&#125; 运行结果： CME02 程序没有抛出ConcurrentModificationException，但是在打印“4”之前程序就结束了，这是为什么呢？ 因为List在删除元素后会减小记录自身元素个数的值，也就是size从5变为了4，而此时，遍历访问的下标由3来到了4，也就是访问i = 3的下标向后移了。Itr的hasNext()此时判断，List已经没有元素可以访问了，于是返回了false。 多线程下的解决方案上面我们已经给出了单线程环境下的解决方案，不过它在多线程下适用吗，我们一起来看看下面这个例子：1234567891011121314151617181920212223242526272829303132333435363738public class Solution &#123; public static void main(String[] args) &#123; List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); list.add(0); list.add(1); list.add(2); list.add(3); list.add(4); Thread thread1 = new Thread()&#123; public void run() &#123; Iterator&lt;Integer&gt; iterator = list.iterator(); while(iterator.hasNext())&#123; Integer integer = iterator.next(); System.out.println(integer); try &#123; Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;; &#125;; Thread thread2 = new Thread()&#123; public void run() &#123; Iterator&lt;Integer&gt; iterator = list.iterator(); while(iterator.hasNext())&#123; Integer integer = iterator.next(); if(integer==2) iterator.remove(); &#125; &#125;; &#125;; thread1.start(); thread2.start(); &#125;&#125; 运行结果： CME03 可能有人说ArrayList是非线程安全的容器，换成Vector就没问题了，实际上换成Vector还是会出现这种错误。 原因在于，虽然Vector的方法采用了synchronized进行了同步，但是实际上通过Iterator访问的情况下，每个线程里面返回的是不同的iterator，也即是说expectedModCount是每个线程私有。假若此时有2个线程，线程1在进行遍历，线程2在进行修改，那么很有可能导致线程2修改后导致Vector中的modCount自增了，线程2的expectedModCount也自增了，但是线程1的expectedModCount没有自增，此时线程1遍历时就会出现expectedModCount不等于modCount的情况了。 因此一般有2种解决办法： 在使用iterator迭代的时候使用synchronized或者Lock进行同步 使用并发容器CopyOnWriteArrayList代替ArrayList和Vector 参考：https://www.cnblogs.com/dolphin0520/p/3933551.html]]></content>
      <categories>
        <category>Java乐园</category>
      </categories>
      <tags>
        <tag>ConcurrentModificationException</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CAS]]></title>
    <url>%2F2019%2F10%2F10%2FCAS%2F</url>
    <content type="text"><![CDATA[这篇 https://juejin.im/post/5ae753d8f265da0ba56753ca 博客中，已经对CAS做了很详细的解释，这篇文章目的是整理一下思路。 写在开篇CAS（compareAndSwap，比较交换，一种无锁原子算法）过程是这样：它包含 3 个参数 CAS（V，E，N），V表示要更新变量的值，E表示预期值，N表示新值。仅当V值等于E值时，才会将V的值设为N，如果V值和E值不同，则说明已经有其他线程做两个更新，则当前线程则什么都不做。最后，CAS 返回当前V的真实值。CAS 操作时抱着乐观的态度进行的，它总是认为自己可以成功完成操作。 非阻塞算法一个线程失败或挂起，不应该影响其他线程失败或挂起算法。 底层原理归功硬件指令集的发展，硬件保证一个从语义上需要多次操作只通过一条指令就能完成。 Java如何实现原子操作Java提供了java.util.concurrent.atomic包。 我们可以通过AtomicInteger的compareAndSet简单看一下其内部实现。123public final boolean compareAndSet(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, valueOffset, expect, update);&#125; 该方法调用了unsafe类（本地方法）的compareAndSwapInt方法，有几个参数，一个是对象自身，一个是该变量的内存地址，一个是期望值，一个是更新值。完全符合我们之前CAS的定义。 缺点CAS存在ABA问题：假设一个变量A，修改为B之后又修改为A，CAS的机制是无法察觉的，但实际上已经被修改过了。如果在基本类型上是没有问题的，但是如果是引用类型呢？这个对象中有多个变量，我们怎么知道有没有被改过？ 聪明的你一定想到了，加个版本号啊。每次修改就检查版本号，如果版本号变了，说明改过，就算你还是A，也不行。 在java.util.concurrent.atomic包中，通过tomicReference来保证引用的原子性。]]></content>
      <categories>
        <category>Java乐园</category>
      </categories>
      <tags>
        <tag>CAS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ReentrantLock源码分析-JDK1.8]]></title>
    <url>%2F2019%2F09%2F24%2FReentrantLock%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-JDK1-8%2F</url>
    <content type="text"><![CDATA[浅析JDK1.8 ReentrantLock源码。 写在开篇ReentrantLock–重入锁，是实现Lock接口的一个同步组件。这篇文章建立在熟悉AQS源码的基础上，同时主要从两个方面来分析ReentrantLock： 重入性的实现原理 公平锁和非公平锁 类的继承关系ReentrantLock实现了Lock和Serializable接口。1public class ReentrantLock implements Lock, java.io.Serializable &#123; 成员变量1234/** * ReentrantLock通过sync(AQS的子类)来实现锁 */private final Sync sync; 这里再说明一下ReentrantLock语境下，AQS的成员变量：123456789101112/** * state用来表示该锁被线程重入的次数。 * 0表示该锁不被任何线程持有 * 1表示线程恰好持有该锁1次(未重入) * 大于1则表示锁被线程重入state次 */private volatile int state;/** * 标识锁被哪个线程持有 */private transient Thread exclusiveOwnerThread; 静态内部类Sync也是一个抽象类，因为锁有非公平和公平的区别。12345678910111213141516171819202122232425262728293031323334353637383940414243444546abstract static class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID = -5179523762034025860L; /** * 非公平和公平锁的lock()方法有不同的实现。 */ abstract void lock(); /** * 非公平的独占锁获取同步状态 */ final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; return false; &#125; /** * 尝试释放锁 */ protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free; &#125;&#125; 构造方法12345678910111213/** * 默认构造非公平锁 */public ReentrantLock() &#123; sync = new NonfairSync();&#125;/** * @param fair true构造公平锁，false构造非公平锁 */public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync();&#125; 非公平锁非公平模式加锁流程加锁流程从lock.lock()开始123public void lock() &#123; sync.lock();&#125; 非公平锁lock的实现：123456789final void lock() &#123; // 尝试快速获取锁，如果state为0，更新为1 if (compareAndSetState(0, 1)) // 将当前线程标记为持有锁的线程 setExclusiveOwnerThread(Thread.currentThread()); else // 获取锁失败 acquire(1);&#125; acquire()我们在看AQS源码就已经分析过了，再贴一下代码给大家看一下。12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 这里我们主要是要看ReentrantLock是怎么实现tryAcquire()的：12345678910111213141516171819202122protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires);&#125;final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; // 当前锁未被任何线程持有 if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; // 当前线程就是持有锁的线程 int nextc = c + acquires; if (nextc &lt; 0) throw new Error("Maximum lock count exceeded"); setState(nextc); // 更新state值 return true; &#125; return false;&#125; 关于非公平锁的加锁流程，我们就看到这里，后面的步骤我们在AQS源码分析已经分析过了，无非是把当前线程包装成结点插入同步队列，通过循环检测是否能够获取到锁，如果不满足，则可能会被阻塞，直至被唤醒，其流程如下图： ReentrantLock01 非公平模式解锁流程解锁从lock.unlock()开始：123public void unlock() &#123; sync.release(1); &#125; release()我们在看AQS源码也分析过了，再贴一下代码给大家看一下。123456789public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125; 我们的重点依旧放在tryRelease()中：123456789101112protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; // 待更新的state if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; // 持有锁的线程未重入 free = true; setExclusiveOwnerThread(null); // 清除锁的持有线程标记 &#125; setState(c); // 更新state return free;&#125; 接下来继续release()的操作。若当前线程已经完全释放锁,即锁可被其他线程使用,则还应该唤醒后续等待线程，其流程如下： ReentrantLock02 为什么基于FIFO的同步队列可以实现非公平锁看到这里，可能大家还是会有疑问：由FIFO队列的特性知，先加入同步队列等待的线程会比后加入的线程更靠近队列的头部，那么它将比后者更早的被唤醒,它也就能更早的得到锁。从这个意义上,对于在同步队列中等待的线程而言，它们获得锁的顺序和加入同步队列的顺序一致，这显然是一种公平模式。那为什么说这是一种非公平的模式呢？ 但线程并非只有在加入队列后才有机会获得锁,哪怕同步队列中已有线程在等待，非公平锁的不公平之处就在于此。回看下非公平锁的加锁流程,线程在进入同步队列等待之前有两次抢占锁的机会： 第一次是非重入式的获取锁,只有在当前锁未被任何线程占有(包括自身)时才能成功 第二次是在进入同步队列前,包含所有情况的获取锁的方式 只有这两次获取锁都失败后，线程才会构造结点并加入同步队列等待。而线程释放锁时是先释放锁(修改state值),然后才唤醒后继结点的线程的。试想下这种情况，线程A已经释放锁,但还没来得及唤醒后继线程C，而这时另一个线程B刚好尝试获取锁，此时锁恰好不被任何线程持有，它将成功获取锁而不用加入队列等待。线程C被唤醒尝试获取锁，而此时锁已经被线程B抢占，故而其获取失败并继续在队列中等待。 公平锁现在我们已经知道了为什么会出现非公平锁了，那么我们就接着看一下ReentrantLock是怎么实现公平锁的吧。 从公平锁加锁的入口开始：123final void lock() &#123; acquire(1);&#125; 对比非公平锁，少了非重入式获取锁的方法,这是第一个不同点。 接着看tryAcquire()：12345678910111213141516171819protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; return false;&#125; 在真正CAS获取锁之前加了判断，我们看一下hasQueuedPredecessors()：1234567public final boolean hasQueuedPredecessors() &#123; Node t = tail; Node h = head; Node s; return h != t &amp;&amp; ((s = h.next) == null || s.thread != Thread.currentThread());&#125; 从方法名我们就可知道这是判断队列中是否有优先级更高的等待线程，队列中哪个线程优先级最高？由于头结点是当前获取锁的线程，所以队列中的第二个结点代表的线程优先级最高。 为什么非公平锁性能好非公平锁对锁的竞争是抢占式的(队列中线程除外)，线程在进入等待队列前可以进行两次尝试，这大大增加了获取锁的机会。这种好处体现在两个方面： 线程不必加入等待队列就可以获得锁，不仅免去了构造结点并加入队列的繁琐操作，同时也节省了线程阻塞唤醒的开销，线程阻塞和唤醒涉及到线程上下文的切换和操作系统的系统调用，是非常耗时的。在高并发情况下，如果线程持有锁的时间非常短，短到线程入队阻塞的过程超过线程持有并释放锁的时间开销，那么这种抢占式特性对并发性能的提升会更加明显。 减少CAS竞争。如果线程必须要加入阻塞队列才能获取锁，那入队时CAS竞争将变得异常激烈，CAS操作虽然不会导致失败线程挂起，但不断失败重试导致的对CPU的浪费也不能忽视。除此之外，加锁流程中至少有两处通过将某些特殊情况提前来减少CAS操作的竞争，增加并发情况下的性能。一处就是获取锁时将非重入的情况提前：123456final void lock() &#123; if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1);&#125; 另一处就是入队的操作,将同步队列非空的情况提前处理:1234567891011121314private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; enq(node); return node;&#125; 参考：https://www.cnblogs.com/takumicx/p/9402021.html]]></content>
      <categories>
        <category>Java乐园</category>
      </categories>
      <tags>
        <tag>ReentrantLock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ConcurrentLinkedQueue源码分析-JDK1.8]]></title>
    <url>%2F2019%2F09%2F23%2FConcurrentLinkedQueue%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[浅析JDK1.8 ConcurrentLinkedQueue源码。 写在开篇ConcurrentLinkedQueue是一个基于链表的无界非阻塞队列，并且是线程安全的，它采用的是先进先出的规则，当我们增加一个元素时，它会添加到队列的末尾，当我们取一个元素时，它会返回一个队列头部的元素。 类的继承关系ConcurrentLinkedQueue继承于AbstractQueue。实现了Queue（规定了Queue的操作规范）、Serializable（可序列化）这两个接口。12public class ConcurrentLinkedQueue&lt;E&gt; extends AbstractQueue&lt;E&gt; implements Queue&lt;E&gt;, java.io.Serializable &#123; 存储结点–Node12345678910111213141516171819202122232425262728private static class Node&lt;E&gt; &#123; volatile E item; // 目标元素 volatile Node&lt;E&gt; next; // 当前Node下一个元素 Node(E item) &#123; UNSAFE.putObject(this, itemOffset, item); &#125; /** * 表示设置当前Node的item值 * 需要两个参数：期望值（cmp）和目标值（val） * 当当前值等于cmp时，就会将目标设置为val */ boolean casItem(E cmp, E val) &#123; return UNSAFE.compareAndSwapObject(this, itemOffset, cmp, val); &#125; void lazySetNext(Node&lt;E&gt; val) &#123; UNSAFE.putOrderedObject(this, nextOffset, val); &#125; /** * casNext和casItem类似，但它用于设置next字段 */ boolean casNext(Node&lt;E&gt; cmp, Node&lt;E&gt; val) &#123; return UNSAFE.compareAndSwapObject(this, nextOffset, cmp, val); &#125;&#125; 成员变量ConcurrentLinkedQueue由head节点和tail节点组成，每个节点（Node）由节点元素（item）和指向下一个节点的引用(next)组成，节点与节点之间就是通过这个next关联起来，从而组成一张链表结构的队列。123private transient volatile Node&lt;E&gt; head; private transient volatile Node&lt;E&gt; tail; 构造方法123456789101112131415161718192021222324252627/** * 默认构造方法 */ public ConcurrentLinkedQueue() &#123; head = tail = new Node&lt;E&gt;(null); &#125; /** * 以一个实现了Collection接口的集合类，来构造ConcurrentLinkedQueue */ public ConcurrentLinkedQueue(Collection&lt;? extends E&gt; c) &#123; Node&lt;E&gt; h = null, t = null; for (E e : c) &#123; checkNotNull(e); Node&lt;E&gt; newNode = new Node&lt;E&gt;(e); if (h == null) h = t = newNode; else &#123; t.lazySetNext(newNode); t = newNode; &#125; &#125; if (h == null) h = t = new Node&lt;E&gt;(null); head = h; tail = t; &#125; Queue接口的实现add()123public boolean add(E e) &#123; return offer(e); &#125; 接下来看一下add()中的核心方法offer()。这个方法没有任何锁操作，线程安全完全由CAS操作和队列的算法来保证，整个方法的核心是for循环，这个循环没有出口，直到尝试成功。123456789101112131415161718192021222324public boolean offer(E e) &#123; checkNotNull(e); final Node&lt;E&gt; newNode = new Node&lt;E&gt;(e); for (Node&lt;E&gt; t = tail, p = t;;) &#123; Node&lt;E&gt; q = p.next; if (q == null) &#123; // p是最后一个结点 if (p.casNext(null, newNode)) &#123; // 每两次更新一下tail if (p != t) casTail(t, newNode); return true; &#125; // CAS竞争失败，再次尝试 &#125; else if (p == q) // 遇到哨兵结点，都从head开始遍历 // 但如果tail被修改，则使用tail（因为可能被修改正确了） p = (t != (t = tail)) ? t : head; else // 取下一个结点或者最后一个结点 p = (p != t &amp;&amp; t != (t = tail)) ? t : q; &#125;&#125; 看到这里，或许大家会有两个疑问： 为什么会出现p == q（即遇到哨兵结点）的情况？ p = (t != (t = tail)) ? t : head;这行代码是什么情况？ 关于第一个问题，先简单解释一下：所谓哨兵结点，就是next指向自己的结点。这种结点在队列中存在的意义不大，主要表示删除的结点，或者空结点。当遇到哨兵结点时，由于无法通过next取得后续的结点，因此很可能直接返回head，期望从链表头部开始遍历，进一步找到链表末尾。一旦在执行过程中发生tail被其他线程修改的情况，则进行一次“打赌”，使用新的tail作为链表末尾（这样就避免了重新查找tail的开销）。 第二个问题：这句代码虽然只有短短的一行，但是包含的信息比较多。首先“!=”并不是原子操作，它是可以被中断的。也就是说，在执行“!=”时，程序会先取得t的值，再执行t=tail，并取得新的t的值，然后比较这两个值是否相等。在单线程时，t!=t这种语句显然不会成立。但是在并发环境中，有可能在获得左边的t值后，右边的t值被其他线程修改。这样，t!=t就可能成立了，这里就是这种情况。如果在比较的过程中，tail被其他线程修改，当它再次赋值给t时，就会导致等式左边的t和右边的t不同。如果两个t不相同，表示tail在中途被其他线程篡改。这时，我们就可以用新的tail作为链表的结尾，也就是这里等式右边的t。但如果没有被修改，则返回head，要求从头部开始，重新查找尾部。 poll()12345678910111213141516171819202122232425262728public E poll() &#123; restartFromHead: for (;;) &#123; // p节点表示首节点，即需要出队的节点 for (Node&lt;E&gt; h = head, p = h, q;;) &#123; E item = p.item; // 如果p节点的元素不为null，则通过CAS来设置p节点引用的元素为null，如果成功则返回p节点的元素 if (item != null &amp;&amp; p.casItem(item, null)) &#123; // 如果p != h，则更新head if (p != h) updateHead(h, ((q = p.next) != null) ? q : p); return item; &#125; // 如果头节点的元素为空或头节点发生了变化，这说明头节点已经被另外一个线程修改了。 // 那么获取p节点的下一个节点，如果p节点的下一节点为null，则表明队列已经空了 else if ((q = p.next) == null) &#123; updateHead(h, p); return null; &#125; // p == q，则使用新的head重新开始 else if (p == q) continue restartFromHead; // 如果下一个元素不为空，则将头节点的下一个节点设置成头节点 else p = q; &#125; &#125; &#125; 在这个地方我们停下来分析一下，哨兵结点是如何产生的。 123ConcurrentLinkedQueue&lt;String&gt; q = new ConcurrentLinkedQueue&lt;String&gt;();q.add("1");q.poll(); 对于上面例子的poll()，由于队列中只有一个元素，根据前文的描述，此时tail并没有更新，而是指向head相同的位置。而此时，head本身的item域为null，其next为列表的第一个元素。故在第一个循环中，代码直接走到最后的else，将p赋值为q，而q就是p.next，也就是当前列表中的第一个元素。接着，在第2轮循环中，p.item显然不为null。因此，代码应该可以顺利进入第一个if块（如果CAS操作成功）。进入第一个if块，也意味着p的item域被设置为null。同时，此时p和h是不相等的。故执行了updataHead()，其实现如下：1234final void updateHead(Node&lt;E&gt; h, Node&lt;E&gt; p) &#123; if (h != p &amp;&amp; casHead(h, p)) h.lazySetNext(h);&#125; 可以看到，在updateHead()中将p作为新的链表头部（通过casHead()实现），而原有的head就被设置为哨兵了（通过lazySetNext()实现）。 这样一个哨兵结点就产生了，而由于此时原有的head头部和tail实际上就是同一个元素。因此，再次用offer()插入元素时，就会遇到这个tail，也就是哨兵。这就是offer()中else if (p == q)这行代码的意义。 peek()获取链表的首部元素。12345678910111213141516public E peek() &#123; restartFromHead: for (;;) &#123; for (Node&lt;E&gt; h = head, p = h, q;;) &#123; E item = p.item; if (item != null || (q = p.next) == null) &#123; updateHead(h, p); return item; &#125; else if (p == q) continue restartFromHead; else p = q; &#125; &#125; &#125; 从源码中可以看到，peek操作会改变head指向，执行peek()方法后head会指向第一个具有非空元素的节点。 remove()12345678910111213141516171819202122232425262728// 删除的元素不能为nullpublic boolean remove(Object o) &#123; if (o != null) &#123; Node&lt;E&gt; next, pred = null; for (Node&lt;E&gt; p = first(); p != null; pred = p, p = next) &#123; boolean removed = false; E item = p.item; if (item != null) &#123; // 若不匹配，则获取next节点继续匹配 if (!o.equals(item)) &#123; next = succ(p); continue; &#125; // 若匹配，则通过CAS操作将对应节点元素置为null removed = p.casItem(item, null); &#125; // 获取删除节点的后继节点 next = succ(p); // 将被删除的节点移除队列 if (pred != null &amp;&amp; next != null) // unlink pred.casNext(p, next); if (removed) return true; &#125; &#125; return false; &#125; size()12345678public int size() &#123; int count = 0; for (Node&lt;E&gt; p = first(); p != null; p = succ(p)) if (p.item != null) if (++count == Integer.MAX_VALUE) break; return count;&#125; size()用来获取当前队列的元素个数，但在并发环境中，其结果可能不精确，因为整个过程都没有加锁，所以从调用size()到返回结果期间有可能增删元素，导致统计的元素个数不精确。 为什么每两次更新一下tail为什么不让tail结点永远成为队列的尾结点，实现代码会更少且逻辑也会更加清晰？ 这是因为，如果让tail永远成为队列的尾结点，则每次都需要使用循环CAS更新tail结点，如果能减少更新tail结点的次数，入队性能岂不更高？所以说并不是每次入队都需要更新尾结点，只有tail结点和尾结点不相等的情况下才更新，减少更新，提高效率。 总结通过以上的分析，大家应该可以明显感觉到，不使用锁而单纯使用CAS操作会要求在应用层面保证线程安全，并处理一些可能存在不一致的问题，大大增加了程序设计和实现的难度。它带来的好处就是使性能飞速提升，因此，在有些场合也是值得的。 参考： 《Java高并发程序设计》 https://blog.csdn.net/qq_38293564/article/details/80798310]]></content>
      <categories>
        <category>Java乐园</category>
      </categories>
      <tags>
        <tag>ConcurrentLinkedQueue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hashtable源码分析-JDK1.8]]></title>
    <url>%2F2019%2F09%2F23%2FHashtable%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-JDK1-8%2F</url>
    <content type="text"><![CDATA[浅析JDK1.8 Hashtable源码。 写在开篇简单介绍一下Hashtable： 和HashMap一样，Hashtable 也是一个散列表，它存储的内容是键值对(key-value)映射 Hashtable是线程安全的，HashMap是非线程安全的 Hashtable的key、value都不可以为null 类的继承关系Hashtable继承于Dictionary，实现了Map（规定了Map的操作规范）、Cloneable（可拷贝）、java.io.Serializable（可序列化）这几个接口。123public class Hashtable&lt;K,V&gt; extends Dictionary&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, java.io.Serializable &#123; 存储结点–Entry12345678910111213private static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Entry&lt;K,V&gt; next; protected Entry(int hash, K key, V value, Entry&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; &#125; 成员变量123456789101112131415161718192021222324/** * Hashtable采用数组+链表的存储结构 */ private transient Entry&lt;?,?&gt;[] table; /** * table中键值对的个数 */ private transient int count; /** * 阈值 */ private int threshold; /** * 负载因子 */ private float loadFactor; /** * Hashtable结构上修改（比如put，remove等操作）的的次数，保证并发访问 */ private transient int modCount = 0; 构造方法1234567891011121314151617181920212223242526272829303132333435363738/** * 使用指定的初始容量大小和指定加载因子构建Hashtable */ public Hashtable(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal Capacity: "+ initialCapacity); if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException("Illegal Load: "+loadFactor); if (initialCapacity==0) initialCapacity = 1; this.loadFactor = loadFactor; table = new Entry&lt;?,?&gt;[initialCapacity]; threshold = (int)Math.min(initialCapacity * loadFactor, MAX_ARRAY_SIZE + 1); &#125; /** * 使用指定的初始容量大小和默认的加载因子0.75构造Hashtable */ public Hashtable(int initialCapacity) &#123; this(initialCapacity, 0.75f); &#125; /** * 使用Hashtable的默认容量大小11和默认加载因子0.75构造Hashtable */ public Hashtable() &#123; this(11, 0.75f); &#125; /** * 以实现了Map接口的集合类构造Hashtable */ public Hashtable(Map&lt;? extends K, ? extends V&gt; t) &#123; this(Math.max(2*t.size(), 11), 0.75f); putAll(t); &#125; 可以看到： HashMap对底层数组采取的懒加载，即当执行第一次插入时才会创建数组，而Hashtable在初始化时就创建了数组 HashMap中数组的默认初始容量是16，并且必须的是2的指数倍数，而Hashtable中默认的初始容量是11，并且不要求必须是2的指数倍数。 Map接口的实现put()123456789101112131415161718192021222324public synchronized V put(K key, V value) &#123; if (value == null) &#123; throw new NullPointerException(); &#125; Entry&lt;?,?&gt; tab[] = table; int hash = key.hashCode(); int index = (hash &amp; 0x7FFFFFFF) % tab.length; Entry&lt;K,V&gt; entry = (Entry&lt;K,V&gt;)tab[index]; // 遍历下标为index的链表 for(; entry != null ; entry = entry.next) &#123; // 存在键值相同的元素，则替换旧值 if ((entry.hash == hash) &amp;&amp; entry.key.equals(key)) &#123; V old = entry.value; entry.value = value; return old; &#125; &#125; // 如果没有找到相同键值，那么添加新节点 addEntry(hash, key, value, index); return null; &#125; 接着看下addEntry()123456789101112131415161718private void addEntry(int hash, K key, V value, int index) &#123; modCount++; Entry&lt;?,?&gt; tab[] = table; if (count &gt;= threshold) &#123; // 扩容 rehash(); tab = table; // 更新tab hash = key.hashCode(); // 更新hash index = (hash &amp; 0x7FFFFFFF) % tab.length; // 更新下标 &#125; // 头插法插入新元素 Entry&lt;K,V&gt; e = (Entry&lt;K,V&gt;) tab[index]; tab[index] = new Entry&lt;&gt;(hash, key, value, e); count++; &#125; 再看看rehash()：1234567891011121314151617181920212223242526272829protected void rehash() &#123; int oldCapacity = table.length; Entry&lt;?,?&gt;[] oldMap = table; // 扩容操作 int newCapacity = (oldCapacity &lt;&lt; 1) + 1; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) &#123; if (oldCapacity == MAX_ARRAY_SIZE) return; newCapacity = MAX_ARRAY_SIZE; &#125; Entry&lt;?,?&gt;[] newMap = new Entry&lt;?,?&gt;[newCapacity]; modCount++; threshold = (int)Math.min(newCapacity * loadFactor, MAX_ARRAY_SIZE + 1); table = newMap; // 采用头插法将原数组元素复制到新数组 for (int i = oldCapacity ; i-- &gt; 0 ;) &#123; for (Entry&lt;K,V&gt; old = (Entry&lt;K,V&gt;)oldMap[i] ; old != null ; ) &#123; Entry&lt;K,V&gt; e = old; old = old.next; int index = (e.hash &amp; 0x7FFFFFFF) % newCapacity; e.next = (Entry&lt;K,V&gt;)newMap[index]; newMap[index] = e; &#125; &#125; &#125; get()12345678910111213public synchronized V get(Object key) &#123; Entry&lt;?,?&gt; tab[] = table; int hash = key.hashCode(); int index = (hash &amp; 0x7FFFFFFF) % tab.length; // 遍历下标为index的链表 for (Entry&lt;?,?&gt; e = tab[index] ; e != null ; e = e.next) &#123; // 如果键值相同，则返回 if ((e.hash == hash) &amp;&amp; e.key.equals(key)) &#123; return (V)e.value; &#125; &#125; return null; &#125; remove()remove()先查询键值相同的元素，如果存在则删除结点，同时modCount++，count–。12345678910111213141516171819202122public synchronized V remove(Object key) &#123; Entry&lt;?,?&gt; tab[] = table; int hash = key.hashCode(); int index = (hash &amp; 0x7FFFFFFF) % tab.length; Entry&lt;K,V&gt; e = (Entry&lt;K,V&gt;)tab[index]; for(Entry&lt;K,V&gt; prev = null ; e != null ; prev = e, e = e.next) &#123; if ((e.hash == hash) &amp;&amp; e.key.equals(key)) &#123; modCount++; if (prev != null) &#123; prev.next = e.next; &#125; else &#123; tab[index] = e.next; &#125; count--; V oldValue = e.value; e.value = null; return oldValue; &#125; &#125; return null; &#125;]]></content>
      <categories>
        <category>Java乐园</category>
      </categories>
      <tags>
        <tag>Hashtable</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashSet源码分析-JDK1.8]]></title>
    <url>%2F2019%2F09%2F23%2FHashSet%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-JDK1-8%2F</url>
    <content type="text"><![CDATA[浅析JDK1.8 HashSet源码。 写在开篇HashSet源码比较简单，所以文章就会比较过水。 先简单介绍一下HashSet： 实现了Set接口,不允许元素重复 底层实现是基于HashMap的，它利用HashMap中的key存储数据，使用成员变量PRESENT来填充value 是线程不安全的 类的继承关系HashSet继承AbstractSet抽象类，实现了Set（规定了Set的操作规范）、Cloneable（可拷贝）、Serializable（可序列化）这几个接口。123public class HashSet&lt;E&gt; extends AbstractSet&lt;E&gt; implements Set&lt;E&gt;, Cloneable, java.io.Serializable &#123; 成员变量12345// 使用HashMap来保存HashSet的元素private transient HashMap&lt;E,Object&gt; map; // 由于Set只使用到了HashMap的key，所以此处定义一个静态的常量Object类，来充当HashMap的value private static final Object PRESENT = new Object(); 构造方法12345678910111213141516171819202122232425262728293031323334353637/** * 使用HashMap的默认容量大小16和默认加载因子0.75初始化map，构造HashSet */ public HashSet() &#123; map = new HashMap&lt;&gt;(); &#125; /** * 以实现了Collection接口的集合类初始化map，来构造HashSet */ public HashSet(Collection&lt;? extends E&gt; c) &#123; map = new HashMap&lt;&gt;(Math.max((int) (c.size()/.75f) + 1, 16)); addAll(c); &#125; /** * 使用指定的初始容量大小和加载因子初始化map，构造HashSet使用指定的初始容量大小和默认的加载因子0.75初始化map，构造一个HashSet */ public HashSet(int initialCapacity, float loadFactor) &#123; map = new HashMap&lt;&gt;(initialCapacity, loadFactor); &#125; /**使用指定的初始容量大小和默认的加载因子0.75初始化map，构造HashSet * */ public HashSet(int initialCapacity) &#123; map = new HashMap&lt;&gt;(initialCapacity); &#125; /** * 不对外公开的一个构造方法（默认default修饰） * 底层构造的是LinkedHashMap * dummy只是一个标示参数，无具体意义 */ HashSet(int initialCapacity, float loadFactor, boolean dummy) &#123; map = new LinkedHashMap&lt;&gt;(initialCapacity, loadFactor); &#125; Set接口的实现add()HashSet将添加的元素通过map中的key来保存，当有相同的key时，也就是添加了相同的元素，那么map会讲value给覆盖掉，而key还是原来的key。123public boolean add(E e) &#123; return map.put(e, PRESENT)==null; &#125; remove()HashSet通过删除map中key的返回值是否为PRESENT判断set中是否有该值。123public boolean remove(Object o) &#123; return map.remove(o)==PRESENT; &#125; contains()直接调用map中containsKey()。123public boolean contains(Object o) &#123; return map.containsKey(o); &#125; isEmpty()123public boolean isEmpty() &#123; return map.isEmpty(); &#125; size()123public int size() &#123; return map.size(); &#125; iterator()12345678910111213141516171819202122232425262728293031323334353637383940414243444546// 重点看一下这个迭代器，这个迭代器在HashMap中就已经构建好了。public Iterator&lt;E&gt; iterator() &#123; return map.keySet().iterator(); &#125; // 实例化KeySet public Set&lt;K&gt; keySet() &#123; Set&lt;K&gt; ks = keySet; if (ks == null) &#123; ks = new KeySet(); keySet = ks; &#125; return ks; &#125; // KeySet类是HashMap中的一个内部类 private final class KeySet extends AbstractSet&lt;K&gt; &#123; public Iterator&lt;K&gt; iterator() &#123; return newKeyIterator(); &#125; public int size() &#123; return size; &#125; public boolean contains(Object o) &#123; return containsKey(o); &#125; public boolean remove(Object o) &#123; return HashMap.this.removeEntryForKey(o) != null; &#125; public void clear() &#123; HashMap.this.clear(); &#125; &#125; // 实例化KeyIterator Iterator&lt;K&gt; newKeyIterator() &#123; return new KeyIterator(); &#125; // 对key进行迭代的迭代器（重点） // 因为set存放的元素就是存放在HashMap中的key，所以为了能够迭代set，HashMap就实现了这个专门遍历key的迭代器 private final class KeyIterator extends HashIterator&lt;K&gt; &#123; public K next() &#123; return nextEntry().getKey(); &#125; &#125;]]></content>
      <categories>
        <category>Java乐园</category>
      </categories>
      <tags>
        <tag>HashSet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AbstractQueuedSynchronizer源码分析]]></title>
    <url>%2F2019%2F09%2F23%2FAbstractQueuedSynchronizer%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[写在开篇文章转载自：https://www.cnblogs.com/micrari/p/6937995.html。 背景AQS（java.util.concurrent.locks.AbstractQueuedSynchronizer）是Doug Lea大师创作的用来构建锁或者其他同步组件（信号量、事件等）的基础框架类。JDK中许多并发工具类的内部实现都依赖于AQS，如ReentrantLock, Semaphore, CountDownLatch等等。学习AQS的使用与源码实现对深入理解concurrent包中的类有很大的帮助。 本文重点介绍AQS中的基本实现思路，包括独占锁、共享锁的获取和释放实现原理和一些代码细节。 简介AQS的主要使用方式是继承它作为一个内部辅助类实现同步原语，它可以简化你的并发工具的内部实现，屏蔽同步状态管理、线程的排队、等待与唤醒等底层操作。 AQS设计基于模板方法模式，开发者需要继承同步器并且重写指定的方法，将其组合在并发组件的实现中，调用同步器的模板方法，模板方法会调用使用者重写的方法。 实现思路下面介绍下AQS具体实现的大致思路。 AQS内部维护一个CLH队列来管理锁。线程会首先尝试获取锁，如果失败，则将当前线程以及等待状态等信息包成一个Node节点加到同步队列里。接着会不断循环尝试获取锁（条件是当前节点为head的直接后继才会尝试）,如果失败则会阻塞自己，直至被唤醒；而当持有锁的线程释放锁时，会唤醒队列中的后继线程。 下面列举JDK中几种常见使用了AQS的同步组件： ReentrantLock: 使用了AQS的独占获取和释放,用state变量记录某个线程获取独占锁的次数,获取锁时+1，释放锁时-1，在获取时会校验线程是否可以获取锁。 Semaphore: 使用了AQS的共享获取和释放，用state变量作为计数器，只有在大于0时允许线程进入。获取锁时-1，释放锁时+1。 CountDownLatch: 使用了AQS的共享获取和释放，用state变量作为计数器，在初始化时指定。只要state还大于0，获取共享锁会因为失败而阻塞，直到计数器的值为0时，共享锁才允许获取，所有等待线程会被逐一唤醒。 如何获取锁获取锁的思路很直接：123456while (不满足获取锁的条件) &#123; 把当前线程包装成节点插入同步队列 if (需要阻塞当前线程) 阻塞当前线程直至被唤醒&#125;将当前线程从同步队列中移除 以上是一个很简单的获取锁的伪代码流程，AQS的具体实现比这个复杂一些，也稍有不同，但思想上是与上述伪代码契合的。通过循环检测是否能够获取到锁，如果不满足，则可能会被阻塞，直至被唤醒。 如何释放锁释放锁的过程设计修改同步状态，以及唤醒后继等待线程：123修改同步状态if (修改后的状态允许其他线程获取到锁) 唤醒后继线程 这只是很简略的释放锁的伪代码示意，AQS具体实现中能看到这个简单的流程模型。 API简介通过上面的AQS大体思路分析，我们可以看到，AQS主要做了三件事情 同步状态的管理 线程的阻塞和唤醒 同步队列的维护 下面三个protected final方法是AQS中用来访问/修改同步状态的方法: int getState(): 获取同步状态 void setState(): 设置同步状态 boolean compareAndSetState(int expect, int update)：基于CAS，原子设置当前状态 在自定义基于AQS的同步工具时，我们可以选择覆盖实现以下几个方法来实现同步状态的管理： 方法 描述 boolean tryAcquire(int arg) 试获取独占锁 boolean tryRelease(int arg) 试释放独占锁 int tryAcquireShared(int arg) 试获取共享锁 boolean tryReleaseShared(int arg) 试释放共享锁 boolean isHeldExclusively() 当前线程是否获得了独占锁 以上的几个试获取/释放锁的方法的具体实现应当是无阻塞的。 AQS本身将同步状态的管理用模板方法模式都封装好了，以下列举了AQS中的一些模板方法： 方法 描述 void acquire(int arg) 获取独占锁。会调用tryAcquire方法，如果未获取成功，则会进入同步队列等待 void acquireInterruptibly(int arg) 响应中断版本的acquire boolean tryAcquireNanos(int arg,long nanos) 响应中断+带超时版本的acquire void acquireShared(int arg) 获取共享锁。会调用tryAcquireShared方法 void acquireSharedInterruptibly(int arg) 响应中断版本的acquireShared boolean tryAcquireSharedNanos(int arg,long nanos) 响应中断+带超时版本的acquireShared boolean release(int arg) 释放独占锁 boolean releaseShared(int arg) 释放共享锁 Collection getQueuedThreads() 获取同步队列上的线程集合 上面看上去很多方法，其实从语义上来区分就是获取和释放，从模式上区分就是独占式和共享式，从中断相应上来看就是支持和不支持。 代码解读数据结构定义首先看一下AQS中的嵌套类Node的定义。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495static final class Node &#123; /** * 用于标记一个节点在共享模式下等待 */ static final Node SHARED = new Node(); /** * 用于标记一个节点在独占模式下等待 */ static final Node EXCLUSIVE = null; /** * 等待状态：取消 */ static final int CANCELLED = 1; /** * 等待状态：通知 */ static final int SIGNAL = -1; /** * 等待状态：条件等待 */ static final int CONDITION = -2; /** * 等待状态：传播 */ static final int PROPAGATE = -3; /** * 等待状态 */ volatile int waitStatus; /** * 前驱节点 */ volatile Node prev; /** * 后继节点 */ volatile Node next; /** * 节点对应的线程 */ volatile Thread thread; /** * 等待队列中的后继节点 */ Node nextWaiter; /** * 当前节点是否处于共享模式等待 */ final boolean isShared() &#123; return nextWaiter == SHARED; &#125; /** * 获取前驱节点，如果为空的话抛出空指针异常 */ final Node predecessor() throws NullPointerException &#123; Node p = prev; if (p == null) &#123; throw new NullPointerException(); &#125; else &#123; return p; &#125; &#125; Node() &#123; &#125; /** * addWaiter会调用此构造函数 */ Node(Thread thread, Node mode) &#123; this.nextWaiter = mode; this.thread = thread; &#125; /** * Condition会用到此构造函数 */ Node(Thread thread, int waitStatus) &#123; this.waitStatus = waitStatus; this.thread = thread; &#125;&#125; 这里有必要专门梳理一下节点等待状态的定义，因为AQS源码中有大量的状态判断与跃迁。 值 描述 CANCELLED (1) 当前线程因为超时或者中断被取消。这是一个终结态，也就是状态到此为止 SIGNAL (-1) 当前线程的后继线程被阻塞或者即将被阻塞，当前线程释放锁或者取消后需要唤醒后继线程。这个状态一般都是后继线程来设置前驱节点的 CONDITION (-2) 当前线程在condition队列中 PROPAGATE (-3) 用于将唤醒后继线程传递下去，这个状态的引入是为了完善和增强共享锁的唤醒机制。在一个节点成为头节点之前，是不会跃迁为此状态的 0 表示无状态 对于分析AQS中不涉及ConditionObject部分的代码，可以认为队列中的节点状态只会是CANCELLED, SIGNAL, PROPAGATE, 0这几种情况。 AQS01 上图为自制的AQS状态的流转图，AQS中0状态和CONDITION状态为始态，CANCELLED状态为终态。0状态同时也可以是节点生命周期的终态。 注意，上图仅表示状态之间流转的可达性，并不代表一定能够从一个状态沿着线随意跃迁。 在AQS中包含了head和tail两个Node引用，其中head在逻辑上的含义是当前持有锁的线程，head节点实际上是一个虚节点，本身并不会存储线程信息。当一个线程无法获取锁而被加入到同步队列时，会用CAS来设置尾节点tail为当前线程对应的Node节点。head和tail在AQS中是延迟初始化的，也就是在需要的时候才会被初始化，也就意味着在所有线程都能获取到锁的情况下，队列中的head和tail都会是null。 获取独占锁的实现下面来具体看看acquire(int arg)的实现：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231/** * 获取独占锁，对中断不敏感。 * 首先尝试获取一次锁，如果成功，则返回； * 否则会把当前线程包装成Node插入到队列中，在队列中会检测是否为head的直接后继，并尝试获取锁, * 如果获取失败，则会通过LockSupport阻塞当前线程，直至被释放锁的线程唤醒或者被中断，随后再次尝试获取锁，如此反复。 */public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125;/** * 在队列中新增一个节点。 */private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); Node pred = tail; // 快速尝试 if (pred != null) &#123; node.prev = pred; // 通过CAS在队尾插入当前节点 if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; // 初始情况或者在快速尝试失败后插入节点 enq(node); return node;&#125;/** * 通过循环+CAS在队列中成功插入一个节点后返回。 */private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; // 初始化head和tail if (t == null) &#123; if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; /* * AQS的精妙就是体现在很多细节的代码，比如需要用CAS往队尾里增加一个元素 * 此处的else分支是先在CAS的if前设置node.prev = t，而不是在CAS成功之后再设置。 * 一方面是基于CAS的双向链表插入目前没有完美的解决方案，另一方面这样子做的好处是： * 保证每时每刻tail.prev都不会是一个null值，否则如果node.prev = t * 放在下面if的里面，会导致一个瞬间tail.prev = null，这样会使得队列不完整。 */ node.prev = t; // CAS设置tail为node，成功后把老的tail也就是t连接到node。 if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125;/** * 在队列中的节点通过此方法获取锁，对中断不敏感。 */final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); /* * 检测当前节点前驱是否head，这是试获取锁的资格。 * 如果是的话，则调用tryAcquire尝试获取锁, * 成功，则将head置为当前节点。 */ if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; /* * 如果未成功获取锁则根据前驱节点判断是否要阻塞。 * 如果阻塞过程中被中断，则置interrupted标志位为true。 * shouldParkAfterFailedAcquire方法在前驱状态不为SIGNAL的情况下都会循环重试获取锁。 */ if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125;/** * 根据前驱节点中的waitStatus来判断是否需要阻塞当前线程。 */private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; if (ws == Node.SIGNAL) /* * 前驱节点设置为SIGNAL状态，在释放锁的时候会唤醒后继节点， * 所以后继节点（也就是当前节点）现在可以阻塞自己。 */ return true; if (ws &gt; 0) &#123; /* * 前驱节点状态为取消,向前遍历，更新当前节点的前驱为往前第一个非取消节点。 * 当前线程会之后会再次回到循环并尝试获取锁。 */ do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; /** * 等待状态为0或者PROPAGATE(-3)，设置前驱的等待状态为SIGNAL, * 并且之后会回到循环再次重试获取锁。 */ compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125;/** * 该方法实现某个node取消获取锁。 */private void cancelAcquire(Node node) &#123; if (node == null) return; node.thread = null; // 遍历并更新节点前驱，把node的prev指向前部第一个非取消节点。 Node pred = node.prev; while (pred.waitStatus &gt; 0) node.prev = pred = pred.prev; // 记录pred节点的后继为predNext，后续CAS会用到。 Node predNext = pred.next; // 直接把当前节点的等待状态置为取消,后继节点即便也在cancel可以跨越node节点。 node.waitStatus = Node.CANCELLED; /* * 如果CAS将tail从node置为pred节点了 * 则剩下要做的事情就是尝试用CAS将pred节点的next更新为null以彻底切断pred和node的联系。 * 这样一来就断开了pred与pred的所有后继节点，这些节点由于变得不可达，最终会被回收掉。 * 由于node没有后继节点，所以这种情况到这里整个cancel就算是处理完毕了。 * * 这里的CAS更新pred的next即使失败了也没关系，说明有其它新入队线程或者其它取消线程更新掉了。 */ if (node == tail &amp;&amp; compareAndSetTail(node, pred)) &#123; compareAndSetNext(pred, predNext, null); &#125; else &#123; // 如果node还有后继节点，这种情况要做的事情是把pred和后继非取消节点拼起来。 int ws; if (pred != head &amp;&amp; ((ws = pred.waitStatus) == Node.SIGNAL || (ws &lt;= 0 &amp;&amp; compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &amp;&amp; pred.thread != null) &#123; Node next = node.next; /* * 如果node的后继节点next非取消状态的话，则用CAS尝试把pred的后继置为node的后继节点 * 这里if条件为false或者CAS失败都没关系，这说明可能有多个线程在取消，总归会有一个能成功的。 */ if (next != null &amp;&amp; next.waitStatus &lt;= 0) compareAndSetNext(pred, predNext, next); &#125; else &#123; /* * 这时说明pred == head或者pred状态取消或者pred.thread == null * 在这些情况下为了保证队列的活跃性，需要去唤醒一次后继线程。 * 举例来说pred == head完全有可能实际上目前已经没有线程持有锁了， * 自然就不会有释放锁唤醒后继的动作。如果不唤醒后继，队列就挂掉了。 * * 这种情况下看似由于没有更新pred的next的操作，队列中可能会留有一大把的取消节点。 * 实际上不要紧，因为后继线程唤醒之后会走一次试获取锁的过程， * 失败的话会走到shouldParkAfterFailedAcquire的逻辑。 * 那里面的if中有处理前驱节点如果为取消则维护pred/next,踢掉这些取消节点的逻辑。 */ unparkSuccessor(node); &#125; /* * 取消节点的next之所以设置为自己本身而不是null, * 是为了方便AQS中Condition部分的isOnSyncQueue方法, * 判断一个原先属于条件队列的节点是否转移到了同步队列。 * * 因为同步队列中会用到节点的next域，取消节点的next也有值的话， * 可以断言next域有值的节点一定在同步队列上。 * * 在GC层面，和设置为null具有相同的效果。 */ node.next = node; &#125;&#125;/** * 唤醒后继线程。 */private void unparkSuccessor(Node node) &#123; int ws = node.waitStatus; // 尝试将node的等待状态置为0,这样的话,后继争用线程可以有机会再尝试获取一次锁。 if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); Node s = node.next; /* * 这里的逻辑就是如果node.next存在并且状态不为取消，则直接唤醒s即可 * 否则需要从tail开始向前找到node之后最近的非取消节点。 * * 这里为什么要从tail开始向前查找也是值得琢磨的: * 如果读到s == null，不代表node就为tail，参考addWaiter以及enq函数中的我的注释。 * 不妨考虑到如下场景： * 1. node某时刻为tail * 2. 有新线程通过addWaiter中的if分支或者enq方法添加自己 * 3. compareAndSetTail成功 * 4. 此时这里的Node s = node.next读出来s == null，但事实上node已经不是tail，它有后继了! */ if (s == null || s.waitStatus &gt; 0) &#123; s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) LockSupport.unpark(s.thread);&#125; AQS独占锁的获取的流程示意如下： AQS02 释放独占锁的实现上面已经分析了acquire的实现，下面来看看release的实现：对于释放一个独占锁，首先会调用tryRelease，在完全释放掉独占锁后，这时后继线程是可以获取到独占锁的，因此释放者线程需要做的事情是唤醒一个队列中的后继者线程，让它去尝试获取独占锁。 上述所谓完全释放掉锁的含义，简单来说就是当前锁处于无主状态，等待线程有可能可以获取。举例：对于可重入锁ReentrantLock, 每次tryAcquire后，state会+1，每次tryRelease后，state会-1，如果state变为0了，则此时称独占锁被完全释放了。 下面，我们来看一下release的具体代码实现：12345678910111213141516171819202122232425262728public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; /* * 此时的head节点可能有3种情况: * 1. null (AQS的head延迟初始化+无竞争的情况) * 2. 当前线程在获取锁时new出来的节点通过setHead设置的 * 3. 由于通过tryRelease已经完全释放掉了独占锁，有新的节点在acquireQueued中获取到了独占锁，并设置了head * 第三种情况可以再分为两种情况： * （一）时刻1:线程A通过acquireQueued，持锁成功，set了head * 时刻2:线程B通过tryAcquire试图获取独占锁失败失败，进入acquiredQueued * 时刻3:线程A通过tryRelease释放了独占锁 * 时刻4:线程B通过acquireQueued中的tryAcquire获取到了独占锁并调用setHead * 时刻5:线程A读到了此时的head实际上是线程B对应的node * （二）时刻1:线程A通过tryAcquire直接持锁成功，head为null * 时刻2:线程B通过tryAcquire试图获取独占锁失败失败，入队过程中初始化了head，进入acquiredQueued * 时刻3:线程A通过tryRelease释放了独占锁，此时线程B还未开始tryAcquire * 时刻4:线程A读到了此时的head实际上是线程B初始化出来的傀儡head */ Node h = head; // head节点状态不会是CANCELLED，所以这里h.waitStatus != 0相当于h.waitStatus &lt; 0 if (h != null &amp;&amp; h.waitStatus != 0) // 唤醒后继线程，此函数在acquire中已经分析过，不再列举说明 unparkSuccessor(h); return true; &#125; return false;&#125; 整个release做的事情就是 调用tryRelease 如果tryRelease返回true也就是独占锁被完全释放，唤醒后继线程。 这里的唤醒是根据head几点来判断的，上面代码的注释中也分析了head节点的情况，只有在head存在并且等待状态小于零的情况下唤醒。 获取共享锁的实现与获取独占锁的实现不同的关键在于，共享锁允许多个线程持有。如果需要使用AQS中共享锁，在实现tryAcquireShared方法时需要注意，返回负数表示获取失败;返回0表示成功，但是后继争用线程不会成功;返回正数表示获取成功，并且后继争用线程也可能成功。 下面来看一下具体的代码实现：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg);&#125;private void doAcquireShared(int arg) &#123; final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head) &#123; int r = tryAcquireShared(arg); // 一旦共享获取成功，设置新的头结点，并且唤醒后继线程 if (r &gt;= 0) &#123; setHeadAndPropagate(node, r); p.next = null; // help GC if (interrupted) selfInterrupt(); failed = false; return; &#125; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125;/** * 这个函数做的事情有两件: * 1. 在获取共享锁成功后，设置head节点 * 2. 根据调用tryAcquireShared返回的状态以及节点本身的等待状态来判断是否要需要唤醒后继线程。 */private void setHeadAndPropagate(Node node, int propagate) &#123; // 把当前的head封闭在方法栈上，用以下面的条件检查。 Node h = head; setHead(node); /* * propagate是tryAcquireShared的返回值，这是决定是否传播唤醒的依据之一。 * h.waitStatus为SIGNAL或者PROPAGATE时也根据node的下一个节点共享来决定是否传播唤醒， * 这里为什么不能只用propagate &gt; 0来决定是否可以传播在本文下面的思考问题中有相关讲述。 */ if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) &#123; Node s = node.next; if (s == null || s.isShared()) doReleaseShared(); &#125;&#125;/** * 这是共享锁中的核心唤醒函数，主要做的事情就是唤醒下一个线程或者设置传播状态。 * 后继线程被唤醒后，会尝试获取共享锁，如果成功之后，则又会调用setHeadAndPropagate,将唤醒传播下去。 * 这个函数的作用是保障在acquire和release存在竞争的情况下，保证队列中处于等待状态的节点能够有办法被唤醒。 */private void doReleaseShared() &#123; /* * 以下的循环做的事情就是，在队列存在后继线程的情况下，唤醒后继线程； * 或者由于多线程同时释放共享锁由于处在中间过程，读到head节点等待状态为0的情况下， * 虽然不能unparkSuccessor，但为了保证唤醒能够正确稳固传递下去，设置节点状态为PROPAGATE。 * 这样的话获取锁的线程在执行setHeadAndPropagate时可以读到PROPAGATE，从而由获取锁的线程去释放后继等待线程。 */ for (;;) &#123; Node h = head; // 如果队列中存在后继线程。 if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; unparkSuccessor(h); &#125; // 如果h节点的状态为0，需要设置为PROPAGATE用以保证唤醒的传播。 else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; &#125; // 检查h是否仍然是head，如果不是的话需要再进行循环。 if (h == head) break; &#125;&#125; 从中，我们可以看出，共享锁的获取和释放都会涉及到doReleaseShared,也就是后继线程的唤醒。关于PROPAGATE状态的必要性，后文会作进一步介绍。 一些思考AQS的代码实在是很精妙，要看懂大致套路并不困难，但是要完全领悟其中的一些细节是一件需要花功夫来仔细琢磨品味的事情。 下面列出一些看源码时的问题与思考: 插入节点时的代码顺序addWaiter和enq方法中新增一个节点时为什么要先将新节点的prev置为tail再尝试CAS，而不是CAS成功后来构造节点之间的双向链接? 这是因为，双向链表目前没有基于CAS原子插入的手段，如果我们将node.prev = t和t.next = node（t为方法执行时读到的tail，引用封闭在栈上）放到compareAndSetTail(t, node)成功后执行，如下所示： 12345if (compareAndSetTail(t, node)) &#123; node.prev = t; t.next = node; return t;&#125; 会导致这一瞬间的tail也就是t的prev为null，这就使得这一瞬间队列处于一种不一致的中间状态。 唤醒节点时为什么从tail向前遍历unparkSuccessor方法中为什么唤醒后继节点时要从tail向前查找最接近node的非取消节点，而不是直接从node向后找到第一个后break掉? 在上面的代码注释中已经提及到这一点：如果读到s == null，不代表node就为tail。 考虑如下场景： node某时刻为tail 有新线程通过addWaiter中的if分支或者enq方法添加自己 compareAndSetTail成功 此时这里的Node s = node.next读出来s == null，但事实上node已经不是tail，它有后继了!unparkSuccessor有新线程争锁是否存在漏洞unparkSuccessor方法在被release调用时是否存在这样的一个漏洞? 时刻1: node -&gt; tail &amp;&amp; tail.waitStatus == Node.CANCELLED (node的下一个节点为tail，并且tail处于取消状态)时刻2: unparkSuccessor读到s.waitStatus &gt; 0时刻3: unparkSuccessor从tail开始遍历时刻4: tail节点对应线程执行cancelAcquire方法中的if (node == tail &amp;&amp; compareAndSetTail(node, pred)) 返回true,此时tail变为pred(也就是node)时刻5: 有新线程进队列tail变为新节点时刻6: unparkSuccessor没有发现需要唤醒的节点最终新节点阻塞并且前驱节点结束调用，新节点再也无法被unpark 这种情况不会发生,确实可能出现从tail向前扫描，没有读到新入队的节点，但别忘了acquireQueued的思想就是不断循环检测是否能够独占获取锁，否则再进行判断是否要阻塞自己，而release的第一步就是tryRelease，它的语义为true表示完全释放独占锁，完全释放之后才会执行后面的逻辑，也就是unpark后继线程。在这种情况下，新入队的线程应当能获取到锁。 如果没有获取锁，则必然是在覆盖tryAcquire/tryRelease的实现有问题，导致前驱节点成功释放了独占锁，后继节点获取独占锁仍然失败。也就是说AQS框架的可靠性还在 某些程度上依赖于具体子类的实现，子类实现如果有bug，那AQS再精巧也扛不住。 AQS如何保证队列活跃AQS如何保证在节点释放的同时又有新节点入队的情况下，不出现原持锁线程释放锁，后继线程被自己阻塞死的情况,保持同步队列的活跃？回答这个问题，需要理解shouldParkAfterFailedAcquire和unparkSuccessor这两个方法。 以独占锁为例，后继争用线程阻塞自己的情况是读到前驱节点的等待状态为SIGNAL,只要不是这种情况都会再试着去争取锁。 假设后继线程读到了前驱状态为SIGNAL，说明之前在tryAcquire的时候，前驱持锁线程还没有tryRelease完全释放掉独占锁。 此时如果前驱线程完全释放掉了独占锁，则在unparkSuccessor中还没执行完置waitStatus为0的操作，也就是还没执行到下面唤醒后继线程的代码，否则后继线程会再去争取锁。 那么就算后继争用线程此时把自己阻塞了，也一定会马上被前驱线程唤醒。那么是否可能持锁线程执行唤醒后继线程的逻辑时，后继线程读到前驱等待状态为SIGNAL把自己给阻塞，再也无法苏醒呢？ 这个问题在上面的问题3中已经有答案了，确实可能在扫描后继需要唤醒线程时读不到新来的线程，但只要tryRelease语义实现正确，在true时表示完全释放独占锁，则后继线程理应能够tryAcquire成功，shouldParkAfterFailedAcquire在读到前驱状态不为SIGNAL会给当前线程再一次获取锁的机会的。别看AQS代码写的有些复杂，状态有些多，还真的就是没毛病，各种情况都能覆盖。 PROPAGATE状态存在的意义在setHeadAndPropagate中我们可以看到如下的一段代码:123456if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) &#123; Node s = node.next; if (s == null || s.isShared()) doReleaseShared();&#125; 为什么不只是用propagate &gt; 0来判断呢？我们知道目前AQS代码中的Node.PROPAGATE状态就是为了此处可以读取到h.waitStatus &lt; 0（PROPAGATE值为-3）；如果这里可以只用propagate &gt; 0来判断，是否PROPAGATE状态都没有存在的必要了？ 我接触JAVA比较晚，接触的时候就已经是JDK8的年代了。这个问题我思考了很久，没有想到很合理的解释来说明PROPAGATE状态存在的必要性。 在网上也鲜少有相关方面的资料、博客提及到这些。后来通过浏览Doug Lea的个人网站，发现在很久以前AQS的代码确实是没有PROPAGATE的，PROPAGATE的引入是为了解决共享锁并发释放导致的线程hang住问题。 在Doug Lea的JSR 166 repository上，我找到了PROPAGATE最早被引入的那一版。可以看到 Revision1.73中，PROPAGATE状态被引入用以修复bug 6801020,让我们来看看这个bug:1234567891011121314151617181920212223242526272829303132333435363738import java.util.concurrent.Semaphore;public class TestSemaphore &#123; private static Semaphore sem = new Semaphore(0); private static class Thread1 extends Thread &#123; @Override public void run() &#123; sem.acquireUninterruptibly(); &#125; &#125; private static class Thread2 extends Thread &#123; @Override public void run() &#123; sem.release(); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; for (int i = 0; i &lt; 10000000; i++) &#123; Thread t1 = new Thread1(); Thread t2 = new Thread1(); Thread t3 = new Thread2(); Thread t4 = new Thread2(); t1.start(); t2.start(); t3.start(); t4.start(); t1.join(); t2.join(); t3.join(); t4.join(); System.out.println(i); &#125; &#125;&#125; 很显然，这段程序一定能执行结束的，但是会偶现线程hang住的问题。当时的AQS中setHeadAndPropagate是这样的: AQS03 以上是bug 6801020修复点的对比，左边为修复之前的版本，右边为引入PROPAGATE修复之后的版本。 从左边可以看到原先的setHeadAndPropagate相比目前版本要简单很多，而releaseShared的实现也与release基本雷同，这也正是本问题的核心：为什么仅仅用调用的tryAcquireShared得到的返回值来判断是否需要唤醒不行呢？ 在PROPAGATE状态出现之前的源码可以点击这里查看 分析让我们来分析一下上面的程序： 上面的程序循环中做的事情就是放出4个线程，其中2个线程用于获取信号量，另外2个用于释放信号量。每次循环主线程会等待所有子线程执行完毕。 出现bug也就是线程hang住的问题就在于两个获取信号量的线程有一个会没办法被唤醒，队列就死掉了。 在AQS的共享锁中，一个被park的线程，不考虑线程中断和前驱节点取消的情况，有两种情况可以被unpark：一种是其他线程释放信号量，调用unparkSuccessor； 另一种是其他线程获取共享锁时通过传播机制来唤醒后继节点。 我们假设某次循环中队列里排队的节点为情况为: head -&gt; t1的node -&gt; t2的node(也就是tail) 信号量释放的顺序为t3先释放，t4后释放:时刻1: t3调用releaseShared，调用了unparkSuccessor(h)，head的等待状态从-1变为0时刻2: t1由于t3释放了信号量，被t3唤醒，调用Semaphore.NonfairSync的tryAcquireShared，返回值为0时刻3: t4调用releaseShared,读到此时h.waitStatus为0(此时读到的head和时刻1中为同一个head)，不满足条件,因此不会调用unparkSuccessor(h)时刻4: t1获取信号量成功，调用setHeadAndPropagate时，因为不满足propagate &gt; 0（时刻2的返回值也就是propagate==0）,从而不会唤醒后继节点 这就好比是一个精巧的多米诺骨牌最终由于设计的失误导致动力无法传递下去，至此AQS中的同步队列宣告死亡。 那么引入PROPAGATE是怎么解决问题的呢？引入之后，调用releaseShared方法不再简单粗暴地直接unparkSuccessor,而是将传播行为抽了一个doReleaseShared方法出来。 再看上面的那种情况: 时刻1：t3调用releaseShared -&gt; doReleaseShared -&gt; unparkSuccessor，完了之后head的等待状态为0 时刻2：t1由于t3释放了信号量，被t3唤醒，调用Semaphore.NonfairSync的tryAcquireShared，返回值为0 时刻3：t4调用releaseShared,读到此时h.waitStatus为0(此时读到的head和时刻1中为同一个head)，将等待状态置为PROPAGATE 时刻4：t1获取信号量成功，调用setHeadAndPropagate时，可以读到h.waitStatus &lt; 0，从而可以接下来调用doReleaseShared唤醒t2 也就是说，上面会产生线程hang住bug的case在引入PROPAGATE后可以被规避掉。在PROPAGATE引入之前，之所以可能会出现线程hang住的情况，就是在于releaseShared有竞争的情况下，可能会有队列中处于等待状态的节点因为第一个线程完成释放唤醒，第二个线程获取到锁，但还没设置好head，又有新线程释放锁，但是读到老的head状态为0导致释放但不唤醒，最终后一个等待线程既没有被释放线程唤醒，也没有被持锁线程唤醒。 所以，仅仅靠tryAcquireShared的返回值来决定是否要将唤醒传递下去是不充分的。 AQS如何防止内存泄露AQS维护了一个FIFO队列，它是如何保证在运行期间不发生内存泄露的？ AQS在无竞争条件下，甚至都不会new出head和tail节点。线程成功获取锁时设置head节点的方法为setHead，由于头节点的thread并不重要，此时会置node的thread和prev为null，完了之后还会置原先head也就是线程对应node的前驱的next为null，从而实现队首元素的安全移出。而在取消节点时，也会令node.thread = null，在node不为tail的情况下，会使node.next = node（之所以这样也是为了isOnSyncQueue实现更加简洁） 总结AQS毫无疑问是Doug Lea大师令人叹为观止的作品，它实现精巧、鲁棒、优雅，很好地封装了同步状态的管理、线程的等待与唤醒，足以满足大多数同步工具的需求。阅读AQS的源码不是一蹴而就就能完全读懂的，阅读源码大致分为三步： 读懂大概思路以及一些重要方法之间的调用关系 逐行看代码的具体实现，知道每一段代码是干什么的 琢磨参悟某一段代码为什么是这么写的，能否换一种写法，能否前后几行代码调换顺序，作者是怎么想的 从Doug Lea大师的论文中，我们也能够看出他设计并实现了AQS本身一方面是本人功力深厚，另一方面也阅读了大量的文献与资料，也做了很多方面的测试。 读AQS最难的地方不在于明白套路和思路，而在于代码中点点滴滴的细节。从一行行的代码角度来说，比如改一个值，是否需要CAS，是否一定要CAS成功；读一个值，在多线程环境下含义是什么，有哪些种情况。从一个个方法角度来说，这些方法的调用关系是如何保证框架的正确性、鲁棒性、伸缩性等。如果能把这些细节都想清楚，明白作者的思路与考虑，才可以源码理解入木三分了。 对于PROPAGATE状态，网上大多AQS的介绍也都只是浅显地提及是用来设置传播的，缺少对于这个状态存在必要性的思考。一开始我也想了很久不明白为什么一定需要一个PROPAGATE状态而不是直接根据tryAcquireShared的返回值来判断是否需要传播。后来也是去了Doug Lea的个人网站翻出当时最早引入PROPAGATE状态的提交，看到了原来的代码，以及http://bugs.java.com/上的bug才更厘清PROPAGATE状态引入的前因后果。 尽管看懂源码，也可能远远达不到能再造一个能与之媲美的轮子的程度，但是能对同步框架、锁、线程等有更深入的理解，也是很丰硕的收获了。 当然，AQS也有其局限性，由于维护的是FIFO队列。如果想要实现一个具有优先级的锁，AQS就派不上什么用处了。]]></content>
      <categories>
        <category>Java乐园</category>
      </categories>
      <tags>
        <tag>AQS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CopyOnWriteArrayList源码分析-JDK1.7]]></title>
    <url>%2F2019%2F09%2F19%2FCopyOnWriteArrayList%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-JDK1-7%2F</url>
    <content type="text"><![CDATA[浅析JDK1.7 CopyOnWriteArrayList源码。 写在开篇CopyOnWriteArrayList使用了一种写时复制的方法，当有新元素添加到CopyOnWriteArrayList时，先从原有的数组中拷贝一份出来，然后在新的数组做写操作，写完之后，再将原来的数组引用指向到新数组。 CopyOnWriteArrayList采用了读写分离的思想，读和写不同的容器。如果写操作未完成或者引用还未指向新数组，那么从原数组读取数据；如果写操作完成，并且引用已经指向了新的数组，那么从新数组中读取数据。所以CopyOnWriteArrayList只能保证数据的最终一致性，不能保证数据的实时一致性。 类的继承关系CopyOnWriteArrayList跟ArrayList一样实现了List，RandomAccess， Cloneable，Serializable接口，但是没有继承AbstractList。12public class CopyOnWriteArrayList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable &#123; 成员变量12345/** 可重入锁 */ transient final ReentrantLock lock = new ReentrantLock(); /** 对象数组 */ private volatile transient Object[] array; 构造方法CopyOnWriteArrayList有三个构造方法。123456789101112131415161718192021222324/** * 创建一个空数组 */public CopyOnWriteArrayList() &#123; setArray(new Object[0]); &#125; /** * 以一个实现了Collection接口的集合类，来创建array */ public CopyOnWriteArrayList(Collection&lt;? extends E&gt; c) &#123; Object[] elements = c.toArray(); if (elements.getClass() != Object[].class) elements = Arrays.copyOf(elements, elements.length, Object[].class); setArray(elements); &#125; /** * 以一个CopyOnWriteArrayList的集合类，来创建array */ public CopyOnWriteArrayList(E[] toCopyIn) &#123; setArray(Arrays.copyOf(toCopyIn, toCopyIn.length, Object[].class)); &#125; List接口的实现add()和ArrayList一样的，CopyOnWriteArrayList有两种插入元素的方法。先看第一种，默认在数组尾部插入元素。1234567891011121314public boolean add(E e) &#123; final ReentrantLock lock = this.lock; lock.lock(); // 获得锁 try &#123; Object[] elements = getArray(); int len = elements.length; Object[] newElements = Arrays.copyOf(elements, len + 1); // 将array复制到一个扩容了的新数组 newElements[len] = e; // 插入新值 setArray(newElements); // 将array引用指向新数组 return true; &#125; finally &#123; lock.unlock(); // 释放锁 &#125; &#125; 另一种是在指定下标插入元素。12345678910111213141516171819202122232425262728public void add(int index, E element) &#123; final ReentrantLock lock = this.lock; lock.lock(); // 获得锁 try &#123; Object[] elements = getArray(); int len = elements.length; if (index &gt; len || index &lt; 0) // 检查下标 throw new IndexOutOfBoundsException("Index: "+index+ ", Size: "+len); Object[] newElements; int numMoved = len - index; if (numMoved == 0) // 在数组尾部插入元素 newElements = Arrays.copyOf(elements, len + 1); else &#123; // 扩容 newElements = new Object[len + 1]; // 拷贝旧数组0到index处的到新数组0到index System.arraycopy(elements, 0, newElements, 0, index); // 拷贝旧数组index到最后的数组到新数组index+1到最后 System.arraycopy(elements, index, newElements, index + 1, numMoved); &#125; newElements[index] = element; // 插入新元素 setArray(newElements); // 将array引用指向新数组 &#125; finally &#123; lock.unlock(); // 释放锁 &#125; &#125; get()读的时候不加锁，代码很简单。1234567public E get(int index) &#123; return get(getArray(), index); &#125;private E get(Object[] a, int index) &#123; return (E) a[index]; &#125; set()12345678910111213141516171819202122 public E set(int index, E element) &#123; final ReentrantLock lock = this.lock; lock.lock(); // 获取锁 try &#123; Object[] elements = getArray(); E oldValue = get(elements, index);// 新旧值不相等才进行替换 if (oldValue != element) &#123; int len = elements.length; // 拷贝一份到新数组 Object[] newElements = Arrays.copyOf(elements, len); newElements[index] = element; // 替换旧元素 setArray(newElements); // 将array引用指向新数组 &#125; else &#123; setArray(elements); &#125; return oldValue; &#125; finally &#123; lock.unlock(); // 释放锁 &#125; &#125; remove()同样地，CopyOnWriteArrayList有两个remove()，先来看一下根据下标删除元素的。123456789101112131415161718192021222324public E remove(int index) &#123; final ReentrantLock lock = this.lock; lock.lock(); // 获取锁 try &#123; Object[] elements = getArray(); int len = elements.length; E oldValue = get(elements, index); int numMoved = len - index - 1; if (numMoved == 0) // 删除元素在数组尾部 setArray(Arrays.copyOf(elements, len - 1)); else &#123; Object[] newElements = new Object[len - 1]; // 拷贝旧数组0到index处的到新数组0到index System.arraycopy(elements, 0, newElements, 0, index); // 拷贝旧数组index+1到最后处的到新数组index到最后 System.arraycopy(elements, index + 1, newElements, index, numMoved); setArray(newElements); // 将array引用指向新数组 &#125; return oldValue; &#125; finally &#123; lock.unlock(); // 释放锁 &#125;&#125; 接着看一下删除第一个相同元素的。123456789101112131415161718192021222324252627282930313233public boolean remove(Object o) &#123; final ReentrantLock lock = this.lock; lock.lock(); // 获取锁 try &#123; Object[] elements = getArray(); int len = elements.length; if (len != 0) &#123; int newlen = len - 1; Object[] newElements = new Object[newlen]; // 删除第一个出现的相同元素 for (int i = 0; i &lt; newlen; ++i) &#123; if (eq(o, elements[i])) &#123; // 将相同元素后面的元素复制到新数组末尾 for (int k = i + 1; k &lt; len; ++k) newElements[k-1] = elements[k]; setArray(newElements); // 将array引用指向新数组 return true; &#125; else newElements[i] = elements[i]; &#125; if (eq(o, elements[newlen])) &#123; setArray(newElements); return true; &#125; &#125; return false; &#125; finally &#123; lock.unlock(); // 释放锁 &#125; &#125;]]></content>
      <categories>
        <category>Java乐园</category>
      </categories>
      <tags>
        <tag>ArrayList</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LinkedList源码分析-JDK1.7]]></title>
    <url>%2F2019%2F09%2F18%2FLinkedList%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-JDK1-7%2F</url>
    <content type="text"><![CDATA[浅析JDK1.7 LinkedList源码。 写在开篇简单介绍一下LinkedList，它使用了双向循环链表作为其存储的数据结构。由于链表的特点是可以自由的添加新的元素，因此LinkedList不需要初始化大小，且列表伸缩性比ArrayList强(ArrayList只能伸展，不能收缩)。LinkedList在根据一个index查找随机节点时，会判断此index在左半区还是右半区，这样就可以选择是从头节点正向遍历，还是从尾节点反向遍历，要比只从头节点遍历的效率高一些。 类的继承结构ArrayList继承AbstractSequentialList抽象类，实现了List（规定了List的操作规范）、Deque（双端队列）、Cloneable（可拷贝）、Serializable（可序列化）这几个接口。123public class LinkedList&lt;E&gt; extends AbstractSequentialList&lt;E&gt; implements List&lt;E&gt;, Deque&lt;E&gt;, Cloneable, java.io.Serializable &#123; 存储结点–Node123456private static class Node&lt;E&gt; &#123; E item; //结点数据元素 Node&lt;E&gt; next; //后置结点 Node&lt;E&gt; prev; //前置结点 // ... &#125; 成员变量1234567891011121314/** * 元素个数 */transient int size = 0;/** * 链表的头结点 */transient Node&lt;E&gt; first;/** * 链表的尾结点 */transient Node&lt;E&gt; last; 构造方法LinkedList有两个构造方法。12345678910111213/** * 空构造方法 */ public LinkedList() &#123; &#125; /** * 以实现了Collection接口的集合类，来初始化链表 */ public LinkedList(Collection&lt;? extends E&gt; c) &#123; this(); addAll(c); &#125; List接口的实现add()LinkedList有两个add()，第一个是默认在链表末尾插入新元素。1234public boolean add(E e) &#123; linkLast(e); return true; &#125; 另一个是在指定下标插入元素。12345678public void add(int index, E element) &#123; checkPositionIndex(index); // 检查下标 if (index == size) linkLast(element); else linkBefore(element, node(index)); &#125; 接下来详细看看add()方法的核心：12345678910111213141516171819202122232425void linkLast(E e) &#123; final Node&lt;E&gt; l = last; final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); last = newNode; // 添加的新元素默认作为尾节点 if (l == null) first = newNode; else // 如果尾结点不为空 l.next = newNode; // 将尾结点下一个结点设为新结点 size++; modCount++;&#125;void linkBefore(E e, Node&lt;E&gt; succ) &#123; final Node&lt;E&gt; pred = succ.prev; // 保存succ的前置结点 final Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, succ); succ.prev = newNode; // 将succ的前置结点改为新结点 if (pred == null) // 如果succ的前置结点为空，则设置新结点为头结点 first = newNode; else // 如果不为空，设置新结点前置结点为刚刚保存的pred pred.next = newNode; size++; modCount++;&#125; put()put()比较简单，直接贴源码。1234567public E set(int index, E element) &#123; checkElementIndex(index); Node&lt;E&gt; x = node(index); E oldVal = x.item; x.item = element; return oldVal; &#125; get()12345678910111213141516171819public E get(int index) &#123; checkElementIndex(index); return node(index).item; &#125; Node&lt;E&gt; node(int index) &#123; // 判断下标在前半段还是后半段，决定从头结点还是尾结点开始遍历 if (index &lt; (size &gt;&gt; 1)) &#123; Node&lt;E&gt; x = first; for (int i = 0; i &lt; index; i++) x = x.next; return x; &#125; else &#123; Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; &#125; &#125; remove()123456789101112131415161718192021222324252627282930313233343536373839404142434445public boolean remove(Object o) &#123; if (o == null) &#123; // 删除元素值为null的结点 for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (x.item == null) &#123; unlink(x); return true; &#125; &#125; &#125; else &#123; // 删除元素值相等的结点 for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (o.equals(x.item)) &#123; unlink(x); return true; &#125; &#125; &#125; return false; &#125; E unlink(Node&lt;E&gt; x) &#123; final E element = x.item; final Node&lt;E&gt; next = x.next; final Node&lt;E&gt; prev = x.prev; // prev为空，则next为头结点 if (prev == null) &#123; first = next; &#125; else &#123; prev.next = next; x.prev = null; &#125; // next为空，则prev为尾结点 if (next == null) &#123; last = prev; &#125; else &#123; next.prev = prev; x.next = null; &#125; x.item = null; size--; modCount++; return element; &#125;]]></content>
      <categories>
        <category>Java乐园</category>
      </categories>
      <tags>
        <tag>LinkedList</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ArrayList源码分析-JDK1.7]]></title>
    <url>%2F2019%2F09%2F18%2FArrayList%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-JDK1-7%2F</url>
    <content type="text"><![CDATA[浅析JDK1.7 ArrayList源码。 写在开篇ArrayList源码相比我们之前看过的Map系列的源码要简单一些，所以接下来我们按照原来的套路，简单分析一下ArrayList的源码吧。 类的继承关系ArrayList继承AbstractList抽象类，实现了List（规定了List的操作规范）、RandomAccess（可随机访问）、Cloneable（可拷贝）、Serializable（可序列化）这几个接口。12public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable &#123; 成员变量12345678910111213141516171819/** * 使用默认构造方法创建数组时的大小 */ private static final int DEFAULT_CAPACITY = 10; /** * 标识 elementData 使用默认构造方法创建 */ private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;; /** * 元素数组 */ private transient Object[] elementData; /** * 实际数组大小 */ private int size; 构造方法ArrayList中有三个构造方法。1234567891011121314151617181920212223242526272829/** * 给定参数初始化数组的大小 */ public ArrayList(int initialCapacity) &#123; super(); if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal Capacity: "+ initialCapacity); this.elementData = new Object[initialCapacity]; &#125; /** * 默认初始化一个空数组 */ public ArrayList() &#123; super(); this.elementData = EMPTY_ELEMENTDATA; &#125; /** * 以实现了Collection接口的集合类，来初始化elementData */ public ArrayList(Collection&lt;? extends E&gt; c) &#123; elementData = c.toArray(); size = elementData.length; if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); &#125; List接口的实现add()ArrayList中有两个add方法，第一个是默认在下标为size+1的位置添加元素。1234567public boolean add(E e) &#123; // 扩容检查 ensureCapacityInternal(size + 1); // 数组末尾添加元素 elementData[size++] = e; return true; &#125; 另一个add()则是在指定位置添加元素。123456789101112131415161718public void add(int index, E element) &#123; rangeCheckForAdd(index); ensureCapacityInternal(size + 1); /** * 将旧数组拷贝到一个新数组中 * @param elementData 被复制的原数组 * @param index 被复制数组的第几个元素开始复制 * @param elementData 复制的目标数组 * @param index + 1 从目标数组index + 1位置开始粘贴 * @param size - index 复制的元素个数 */ System.arraycopy(elementData, index, elementData, index + 1, size - index); // 将新元素赋给该下标 elementData[index] = element; size++; &#125; 扩容1234567891011121314151617181920212223242526272829private void ensureCapacityInternal(int minCapacity) &#123; // 是否为空数组 if (elementData == EMPTY_ELEMENTDATA) &#123; minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); &#125; ensureExplicitCapacity(minCapacity); &#125; private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; // 增加数组的操作次数（其为AbstractList的成员变量） // 如果需要的最小容量比elementData数组长度小，则扩容 if (minCapacity - elementData.length &gt; 0) grow(minCapacity); &#125; private void grow(int minCapacity) &#123; int oldCapacity = elementData.length; // 新容量为旧容量的3/2 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); // 如果新容量还是小于扩容需要的最小容量，则将新容量调整为扩容需要的最小容量 if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; // 新容量不超过Integer.MAX_VALUE-8 if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); elementData = Arrays.copyOf(elementData, newCapacity); &#125; set()1234567public E set(int index, E element) &#123; rangeCheck(index); // 检查下标 E oldValue = elementData(index); elementData[index] = element; // 将element赋值为指定下标 return oldValue; &#125; get()12345public E get(int index) &#123; rangeCheck(index); // 检查下标 return elementData(index); // 返回指定下标的元素 &#125; remove()同样地，有两个remove()方法。一个是删除下标为index的元素。12345678910111213141516public E remove(int index) &#123; rangeCheck(index); // 检查下标 modCount++; E oldValue = elementData(index); int numMoved = size - index - 1; // 需要移动的个数 if (numMoved &gt; 0) // 将下标为index+1后的元素向前移动一位 System.arraycopy(elementData, index+1, elementData, index, numMoved); // 将下标为size的元素置为空，同时将size-1 elementData[--size] = null; return oldValue; &#125; 另一个是删除数组中相同的元素。1234567891011121314151617181920212223242526public boolean remove(Object o) &#123; if (o == null) &#123; // 删除数组中的空元素 for (int index = 0; index &lt; size; index++) if (elementData[index] == null) &#123; fastRemove(index); return true; &#125; &#125; else &#123; // 输出数组中和o相同的元素 for (int index = 0; index &lt; size; index++) if (o.equals(elementData[index])) &#123; fastRemove(index); return true; &#125; &#125; return false; &#125; // 与上面讲的删除remove()过程相似 private void fastRemove(int index) &#123; modCount++; int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; &#125; 为什么是线程不安全的主要有两个线程不安全的隐患，都出现在下面这段代码中：1234567public boolean add(E e) &#123; // 扩容检查 ensureCapacityInternal(size + 1); // 数组末尾添加元素 elementData[size++] = e; return true; &#125; 扩容检查时假设现在有A、B两个线程在对数组进行插入元素操作，此时size=9（ArrayList 数组大小为默认的10）。 线程 A 进入add()，获取到size为9，调用ensureCapacityInternal()后判断不需要扩容，时间片消耗完，线程A挂起。 线程 B 开始执行，调用ensureCapacityInternal()后发现也不需要扩容。于是插入元素，且size自增1（size=10）。 线程 A 接着执行，尝试在下标为10的位置插入元素，此时就会抛出ArrayIndexOutOfBoundsException。 向数组末尾添加元素时同样现在有两个线程A、B在对数组进行插入元素操作，size=0。 线程 A 执行完elementData[size] = e;后时间片耗尽，挂起。 线程 B 开始执行，由于size还是为0，所以在elementData[size] = e;时，会将线程 A 插入的元素覆盖掉。]]></content>
      <categories>
        <category>Java乐园</category>
      </categories>
      <tags>
        <tag>ArrayList</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ConcurrentHashMap源码分析-JDK1.7]]></title>
    <url>%2F2019%2F09%2F07%2FConcurrentHashMap%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-JDK1-7%2F</url>
    <content type="text"><![CDATA[浅析JDK1.7 ConcurrentHashMap源码。 写在开篇先贴张图看下ConcurrentHashMap JDK 1.7的结构： CHM1.7.01 先大体介绍一下：ConcurrentHashMap 是由Segment数组结构和HashEntry数组结构组成。 Segment是一种可重入锁ReentrantLock，在ConcurrentHashMap里扮演锁的角色，HashEntry则用于存储键值对数据 一个Segment里包含一个HashEntry数组，每个HashEntry是一个链表结构的元素，这与HashMap结构相似 简单来讲，就是ConcurrentHashMap比HashMap多了一次hash过程，第1次hash定位到Segment，第2次hash定位到HashEntry，然后链表搜索找到指定节点。 该种实现方式的缺点是hash过程比普通的HashMap要长，但是优点也很明显，在进行写操作时，只需锁住写元素所在的Segment即可，其他Segment无需加锁，提高了并发读写的效率。 Segment先看下Segment的定义，是ConcurrentHashMap的一个静态内部类，继承了ReentrantLock。1static final class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable &#123; 接着看下其中几个重要的属性：12345678910111213141516171819/** * 一个HashEntry数组table，HashEntry是链表的节点定义 */transient volatile HashEntry&lt;K,V&gt;[] table;/** * Segment中Entry的数量 */transient int count;/** * 阈值 */transient int threshold;/** * 负载因子 */final float loadFactor; HashEntry12345678static final class HashEntry&lt;K,V&gt; &#123; final int hash; final K key; volatile V value; volatile HashEntry&lt;K,V&gt; next; // ...&#125; 由定义可知，value和next均为使用volatile修饰，一个线程对该Segment内部的某个链表节点HashEntry的value或下一个节点next修改能够对其他线程可见。 ConcurrentHashMap类的继承关系12public class ConcurrentHashMap&lt;K, V&gt; extends AbstractMap&lt;K, V&gt; implements ConcurrentMap&lt;K, V&gt;, Serializable &#123; 继承于抽象的AbstractMap，实现了ConcurrentMap，Serializable这两个接口。 几个重要的属性1234567891011121314/** * 段掩码 */final int segmentMask;/** * 段偏移量 */final int segmentShift;/** * ConcurrentHashMap中的桶 */final Segment&lt;K,V&gt;[] segments; segmentShift和segmentMask，这两个全局变量在定位segment时的哈希算法里需要使用。 几个重要的默认常量1234567891011121314151617181920212223242526272829/** * 指的是整个ConcurrentHashMap默认的初始容量 */static final int DEFAULT_INITIAL_CAPACITY = 16;/** * ConcurrentHashMap容量的最大值 */static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;/** * Segment 数组不可以扩容，所以这个负载因子是给每个 Segment 内部使用的。 */static final float DEFAULT_LOAD_FACTOR = 0.75f;/** * 默认的并发数，即segments数组的大小，ConcurrentHashMap会使用大于等于该值的最小2幂指数作为实际并发度 */static final int DEFAULT_CONCURRENCY_LEVEL = 16;/** * segment中table的最小容量 */static final int MIN_SEGMENT_TABLE_CAPACITY = 2;/** * segment数组最大的大小 */static final int MAX_SEGMENTS = 1 &lt;&lt; 16; ConcurrentHashMap的构造函数 Segment数组初始化后，不能再扩容 只初始化了segment[0]，其他位置仍然是 null 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public ConcurrentHashMap(int initialCapacity, float loadFactor, int concurrencyLevel) &#123; if (!(loadFactor &gt; 0) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0) throw new IllegalArgumentException(); if (concurrencyLevel &gt; MAX_SEGMENTS) concurrencyLevel = MAX_SEGMENTS; int sshift = 0; int ssize = 1; /** * ssize：segments数组的大小 * 不能小于concurrencyLevel，默认为16 */ while (ssize &lt; concurrencyLevel) &#123; ++sshift; ssize &lt;&lt;= 1; &#125; // segmentShift和segmentMask将用于取segment的下标 /** * 比如concurrencyLevel为17，那么ssize为32，即2^5；sshift为5 * segmentShift即27了，后面在取segment下标的时候，会无符号左移27位，也就是取高5位的时候，就是0-31，此时segment下标也是0-31，取模后对应着每个segment * * segmentMask就是2的n次方-1，这里是5，用于取模 */ this.segmentShift = 32 - sshift; this.segmentMask = ssize - 1; if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; int c = initialCapacity / ssize; if (c * ssize &lt; initialCapacity) ++c; /** * cap：Segment内部HashEntry数组的大小 * 最小为MIN_SEGMENT_TABLE_CAPACITY，默认为2 * 实际大小根据initialCapacity/ssize得到 * 即整体容量大小除以Segment数组的数量 * 得到每个Segment内部的table的大小 */ int cap = MIN_SEGMENT_TABLE_CAPACITY; while (cap &lt; c) cap &lt;&lt;= 1; // 创建segments和segments[0] Segment&lt;K,V&gt; s0 = new Segment&lt;K,V&gt;(loadFactor, (int)(cap * loadFactor), (HashEntry&lt;K,V&gt;[])new HashEntry[cap]); Segment&lt;K,V&gt;[] ss = (Segment&lt;K,V&gt;[])new Segment[ssize]; // 往数组写入 segment[0] UNSAFE.putOrderedObject(ss, SBASE, s0); this.segments = ss;&#125; put()在ConcurrentHashMap中的put操作是没有加锁的，而在Segment中的put操作，通过ReentrantLock加锁。 首先通过key的hash确定segments数组的下标，即需要往哪个segment存放数据。确定好segment之后，则调用该segment的put方法，写到该segment内部的table数组的某个链表中。 先看下ConcurrentHashMap中的put():1234567891011121314public V put(K key, V value) &#123; Segment&lt;K,V&gt; s; if (value == null) throw new NullPointerException(); // 根据key的hash，确定具体的Segment int hash = hash(key); int j = (hash &gt;&gt;&gt; segmentShift) &amp; segmentMask; // 如果segments数组的该位置还没segment，初始化 if ((s = (Segment&lt;K,V&gt;)UNSAFE.getObject (segments, (j &lt;&lt; SSHIFT) + SBASE)) == null) s = ensureSegment(j); // 插入新值至槽s中 return s.put(key, hash, value, false);&#125; 看下ensureSegment()如何初始化槽：12345678910111213141516171819202122232425private Segment&lt;K,V&gt; ensureSegment(int k) &#123; final Segment&lt;K,V&gt;[] ss = this.segments; long u = (k &lt;&lt; SSHIFT) + SBASE; // raw offset Segment&lt;K,V&gt; seg; if ((seg = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(ss, u)) == null) &#123; // 使用当前 segment[0] 处的数组长度和负载因子来初始化 segment[k] Segment&lt;K,V&gt; proto = ss[0]; int cap = proto.table.length; float lf = proto.loadFactor; int threshold = (int)(cap * lf); // 初始化 segment[k] 内部的数组 HashEntry&lt;K,V&gt;[] tab = (HashEntry&lt;K,V&gt;[])new HashEntry[cap]; if ((seg = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(ss, u)) == null) &#123; // recheck Segment&lt;K,V&gt; s = new Segment&lt;K,V&gt;(lf, threshold, tab); while ((seg = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(ss, u)) == null) &#123; // 循环CAS赋值给Segment[]后退出 if (UNSAFE.compareAndSwapObject(ss, u, null, seg = s)) break; &#125; &#125; &#125; return seg;&#125; 接下来是Segment中的put()，首先获取lock锁，然后根据key的hash值，获取在segment内部的HashEntry数组table的下标，从而获取对应的链表：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253final V put(K key, int hash, V value, boolean onlyIfAbsent) &#123; /** * tryLock：非阻塞获取lock * scanAndLockForPut：该segment锁被其他线程持有了，则非阻塞重试3次，超过3次则阻塞等待锁。 */ HashEntry&lt;K,V&gt; node = tryLock() ? null : scanAndLockForPut(key, hash, value); V oldValue; try &#123; HashEntry&lt;K,V&gt;[] tab = table; int index = (tab.length - 1) &amp; hash; // 链表头结点 HashEntry&lt;K,V&gt; first = entryAt(tab, index); for (HashEntry&lt;K,V&gt; e = first;;) &#123; // table中已存在结点 if (e != null) &#123; K k; // 已经存在，则更新value值 if ((k = e.key) == key || (e.hash == hash &amp;&amp; key.equals(k))) &#123; oldValue = e.value; if (!onlyIfAbsent) &#123; e.value = value; // 更新value时，也递增modCount，而在HashMap中是结构性修改才递增。 ++modCount; &#125; break; &#125; e = e.next; &#125; // 头插法新增结点 else &#123; if (node != null) node.setNext(first); else node = new HashEntry&lt;K,V&gt;(hash, key, value, first); int c = count + 1; // 扩容 if (c &gt; threshold &amp;&amp; tab.length &lt; MAXIMUM_CAPACITY) rehash(node); else setEntryAt(tab, index, node); ++modCount; count = c; oldValue = null; break; &#125; &#125; &#125; finally &#123; unlock(); &#125; return oldValue;&#125; 我们详细看一下scanAndLockForPut()是怎么实现的：123456789101112131415161718192021222324252627282930313233private HashEntry&lt;K,V&gt; scanAndLockForPut(K key, int hash, V value) &#123; HashEntry&lt;K,V&gt; first = entryForHash(this, hash); HashEntry&lt;K,V&gt; e = first; HashEntry&lt;K,V&gt; node = null; int retries = -1; // 非阻塞自旋获取lock锁 while (!tryLock()) &#123; HashEntry&lt;K,V&gt; f; if (retries &lt; 0) &#123; if (e == null) &#123; if (node == null) node = new HashEntry&lt;K,V&gt;(hash, key, value, null); retries = 0; &#125; else if (key.equals(e.key)) retries = 0; else e = e.next; &#125; // MAX_SCAN_RETRIES为2，尝试3次后，则当前线程阻塞等待lock锁 else if (++retries &gt; MAX_SCAN_RETRIES) &#123; lock(); break; &#125; // 如果链表被修改过，重置retries else if ((retries &amp; 1) == 0 &amp;&amp; (f = entryForHash(this, hash)) != first) &#123; e = first = f; retries = -1; &#125; &#125; return node;&#125; 扩容接下来看下Segment的rehash()：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354private void rehash(HashEntry&lt;K,V&gt; node) &#123; HashEntry&lt;K,V&gt;[] oldTable = table; int oldCapacity = oldTable.length; // 新容量为旧容量的2倍 int newCapacity = oldCapacity &lt;&lt; 1; threshold = (int)(newCapacity * loadFactor); // 创建新数组 HashEntry&lt;K,V&gt;[] newTable = (HashEntry&lt;K,V&gt;[]) new HashEntry[newCapacity]; // 新掩码 int sizeMask = newCapacity - 1; for (int i = 0; i &lt; oldCapacity ; i++) &#123; HashEntry&lt;K,V&gt; e = oldTable[i]; if (e != null) &#123; HashEntry&lt;K,V&gt; next = e.next; // 元素在新数组中的位置 int idx = e.hash &amp; sizeMask; if (next == null) // 该位置只有一个元素 newTable[idx] = e; else &#123; // e是链表表头 HashEntry&lt;K,V&gt; lastRun = e; int lastIdx = idx; // for 循环找到一个 lastRun 结点，这个结点之后的所有元素是将要放到一起的 for (HashEntry&lt;K,V&gt; last = next; last != null; last = last.next) &#123; int k = last.hash &amp; sizeMask; if (k != lastIdx) &#123; lastIdx = k; lastRun = last; &#125; &#125; // 将lastRun及其之后的所有结点组成的这个链表放到 lastIdx这个位置 newTable[lastIdx] = lastRun; // 下面的操作是处理lastRun之前的结点，看看分配在哪个链表中 for (HashEntry&lt;K,V&gt; p = e; p != lastRun; p = p.next) &#123; V v = p.value; int h = p.hash; int k = h &amp; sizeMask; HashEntry&lt;K,V&gt; n = newTable[k]; // 头插法插入元素 newTable[k] = new HashEntry&lt;K,V&gt;(h, p.key, v, n); &#125; &#125; &#125; &#125; // 头插法插入新结点 int nodeIndex = node.hash &amp; sizeMask; node.setNext(newTable[nodeIndex]); newTable[nodeIndex] = node; // 赋值新数组给table table = newTable;&#125; get()get()是不用加锁的，通过使用UNSAFE的volatile版本的方法保证线程可见性。12345678910111213141516171819public V get(Object key) &#123; Segment&lt;K,V&gt; s; HashEntry&lt;K,V&gt;[] tab; int h = hash(key); long u = (((h &gt;&gt;&gt; segmentShift) &amp; segmentMask) &lt;&lt; SSHIFT) + SBASE; // 获取segment if ((s = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(segments, u)) != null &amp;&amp; (tab = s.table) != null) &#123; // 遍历table，返回该key对应的value for (HashEntry&lt;K,V&gt; e = (HashEntry&lt;K,V&gt;) UNSAFE.getObjectVolatile (tab, ((long)(((tab.length - 1) &amp; h)) &lt;&lt; TSHIFT) + TBASE); e != null; e = e.next) &#123; K k; if ((k = e.key) == key || (e.hash == h &amp;&amp; key.equals(k))) return e.value; &#125; &#125; return null;&#125; remove()remove()和put()实现逻辑还是挺相似的。 先看下ConcurrentHashMap中的remove():123456public V remove(Object key) &#123; int hash = hash(key); // 找到对应的segment Segment&lt;K,V&gt; s = segmentForHash(hash); return s == null ? null : s.remove(key, hash, null);&#125; 接着继续看segment中的remove():12345678910111213141516171819202122232425262728293031323334353637final V remove(Object key, int hash, Object value) &#123; // 获取锁 if (!tryLock()) scanAndLock(key, hash); V oldValue = null; try &#123; HashEntry&lt;K,V&gt;[] tab = table; int index = (tab.length - 1) &amp; hash; // 获取table对应下标的列表的第一个元素 HashEntry&lt;K,V&gt; e = entryAt(tab, index); HashEntry&lt;K,V&gt; pred = null; while (e != null) &#123; K k; HashEntry&lt;K,V&gt; next = e.next; if ((k = e.key) == key || (e.hash == hash &amp;&amp; key.equals(k))) &#123; V v = e.value; if (value == null || value == v || value.equals(v)) &#123; // 若将删除的是首结点，则将下一个Entry设置为首结点 if (pred == null) setEntryAt(tab, index, next); else pred.setNext(next); ++modCount; --count; oldValue = v; &#125; break; &#125; pred = e; e = next; &#125; &#125; finally &#123; unlock(); &#125; return oldValue;&#125; size()size方法主要是计算当前hashmap中存放的元素的总个数，即累加各个segments的内部的哈希表table数组内的所有链表的所有链表节点的个数。 实现逻辑为：整个计算过程刚开始是不对segments加锁的，重复计算两次，如果前后两次hashmap都没有修改过，则直接返回计算结果，如果修改过了，则再加锁计算一次。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public int size() &#123; final Segment&lt;K,V&gt;[] segments = this.segments; int size; boolean overflow; // true if size overflows 32 bits // 累加modCounts long sum; // 记录前一次累加的modCounts long last = 0L; // 尝试的次数 int retries = -1; try &#123; for (;;) &#123; /** * RETRIES_BEFORE_LOCK值为2 * retries++ == RETRIES_BEFORE_LOCK，表示已经是第三次了，故需要加锁 */ if (retries++ == RETRIES_BEFORE_LOCK) &#123; // 每个segment都加锁，此时不能执行写操作了 for (int j = 0; j &lt; segments.length; ++j) ensureSegment(j).lock(); // force creation &#125; // sum重置为0 sum = 0L; size = 0; overflow = false; // 遍历每个segment for (int j = 0; j &lt; segments.length; ++j) &#123; Segment&lt;K,V&gt; seg = segmentAt(segments, j); if (seg != null) &#123; // 累加各个segment的modCount，以便与上一次的modCount进行比较 sum += seg.modCount; int c = seg.count; // size+=c 计算ConcurrentHashMap中size的数量 if (c &lt; 0 || (size += c) &lt; 0) overflow = true; &#125; &#125; // 如果前后两次都相等，说明在这期间没有写的操作，可以直接返回 if (sum == last) break; last = sum; &#125; &#125; finally &#123; if (retries &gt; RETRIES_BEFORE_LOCK) &#123; // 释放锁 for (int j = 0; j &lt; segments.length; ++j) segmentAt(segments, j).unlock(); &#125; &#125; return overflow ? Integer.MAX_VALUE : size;&#125;]]></content>
      <categories>
        <category>Java乐园</category>
      </categories>
      <tags>
        <tag>HashMap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap源码分析-JDK1.7]]></title>
    <url>%2F2019%2F09%2F05%2FHashMap%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-JDK1-7%2F</url>
    <content type="text"><![CDATA[浅析JDK1.7 HashMap源码。 HashMap中几个重要的属性1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/** * 默认初始化化容量,即16 */ static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16 /** * 最大容量，即2的30次方 */ static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; /** * 默认负载因子 */ static final float DEFAULT_LOAD_FACTOR = 0.75f; /** * 空数组，表示没有初始化之前的状态 */ static final Entry&lt;?,?&gt;[] EMPTY_TABLE = &#123;&#125;; /** * 空的存储实体 */ transient Entry&lt;K,V&gt;[] table = (Entry&lt;K,V&gt;[]) EMPTY_TABLE; /** * HashMap中Entry的数量 */ transient int size; /** * 阈值，当size大于threshold时会执行resize操作 * threshold = capacity * loadFactor */ int threshold; /** * 负载因子，默认是0.75 */ final float loadFactor; /** * HashMap结构上修改（比如put，remove等操作）的的次数，保证并发访问时，若HashMap内部结构发生变化，快速响应失败 */ transient int modCount; /** * 默认的threshold值，下文会具体讲到 */ static final int ALTERNATIVE_HASHING_THRESHOLD_DEFAULT = Integer.MAX_VALUE; /** * 哈希种子，与此实例关联的随机值，应用于键的哈希码以使哈希冲突更难找到 * 如果为0，则禁用备用散列，同样在下文具体分析 */ transient int hashSeed = 0; Entry当实例化一个HashMap时，会创建一个长度为Capacity的Entry数组。在这个数组中可以存放元素的位置我们称之为“桶”(bucket)，每个bucket都有自己的索引，系统可以根据索引快速的查找bucket中的元素。每个bucket中存储一个元素，即一个Entry对象，但每一个Entry对象可以带一个引用变量，用于指向下一个元素，因此，在一个桶中，就有可能生成一个Entry链。 Entry源码如下:12345678910111213static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final K key; V value; Entry&lt;K,V&gt; next; int hash; Entry(int h, K k, V v, Entry&lt;K,V&gt; n) &#123; value = v; next = n; key = k; hash = h; &#125;&#125; 构造方法HashMap有4个构造器，其他构造器如果用户没有传入initialCapacity或loadFactor，会使用默认值。123456789101112131415public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal initial capacity: " + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException("Illegal load factor: " + loadFactor); this.loadFactor = loadFactor; threshold = initialCapacity; // 在HashMap中没有实际实现 init();&#125; 在常规构造器中，并没有马上为数组table分配内存空间（有一个入参为指定Map的构造器例外），事实上是在执行第一次put操作的时候才真正构建table数组。 put()123456789101112131415161718192021222324252627282930public V put(K key, V value) &#123; // 如果table数组为空数组，创建存储实体 if (table == EMPTY_TABLE) &#123; inflateTable(threshold); &#125; // 如果key为null，存储位置为table[0]，或table[0]的冲突链上 if (key == null) return putForNullKey(value); // 对key的hashcode进一步计算，确保散列均匀 int hash = hash(key); // 获取在table数组中的下标 int i = indexFor(hash, table.length); // 如果出现对应key已存在，则覆盖 for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; // 如果key没出现过，则modCount++ modCount++; // 添加entry addEntry(hash, key, value, i); return null;&#125; 建哈希表是在inflateTable()中实现的，我们来看一看：1234567891011private void inflateTable(int toSize) &#123; // 比容量（capacity）大的2的次幂，作为哈希表的容量 int capacity = roundUpToPowerOf2(toSize); // 计算新的扩容阈值 threshold = (int) Math.min(capacity * loadFactor, MAXIMUM_CAPACITY + 1); // 分配空间 table = new Entry[capacity]; // 根据容量判断是否需要初始化hashSeed initHashSeedAsNeeded(capacity);&#125; 继续看下addEntry()源码：1234567891011void addEntry(int hash, K key, V value, int bucketIndex) &#123; if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123; // 扩容，新容量为旧容量的2倍 resize(2 * table.length); hash = (null != key) ? hash(key) : 0; bucketIndex = indexFor(hash, table.length); &#125; // 将新Entry放入HashMap的桶的对应位置 createEntry(hash, key, value, bucketIndex);&#125; 使用头插法将Entry插入桶中：12345void createEntry(int hash, K key, V value, int bucketIndex) &#123; Entry&lt;K,V&gt; e = table[bucketIndex]; table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e); size++;&#125; Alternative hashing和hashSeed这里我要补充一下hashSeed这个属性，inflateTable()中最后还调用了一个initHashSeedAsNeeded()方法，该方法是用来依据容量决定是否需要初始化hashSeed。 在源码中有一个常量ALTERNATIVE_HASHING_THRESHOLD_DEFAULT，它是一个默认的阈值，当一个键值对的键是String类型时，且map的容量达到了这个阈值，就启用备用哈希(alternative hashing)。备用哈希可以减少String类型的key计算哈希码（更容易）发生哈希碰撞的发生率。该值可以通过定义系统属性jdk.map.althashing.threshold来指定。如果该值是1，表示强制总是使用备用哈希；如果是-1则表示禁用。 HashMap有一个静态内部类Holder,它的作用是在虚拟机启动后根据jdk.map.althashing.threshold和ALTERNATIVE_HASHING_THRESHOLD_DEFAULT初始化ALTERNATIVE_HASHING_THRESHOLD，相关代码如下：1234567891011121314151617181920212223242526272829303132333435363738394041/** * Holder维护着一些只有在虚拟机启动后才能初始化的值 */private static class Holder &#123; /** * 触发启用备用哈希的哈希表容量阈值 */ static final int ALTERNATIVE_HASHING_THRESHOLD; static &#123; // 读取JVM参数 -Djdk.map.althashing.threshold String altThreshold = java.security.AccessController.doPrivileged( new sun.security.action.GetPropertyAction( "jdk.map.althashing.threshold")); int threshold; try &#123; // 如果该参数没有值，采用默认值 threshold = (null != altThreshold) ? Integer.parseInt(altThreshold) : ALTERNATIVE_HASHING_THRESHOLD_DEFAULT; // 如果参数值为-1，禁用备用哈希 // ALTERNATIVE_HASHING_THRESHOLD_DEFAULT也是等于Integer.MAX_VALUE // 所以jdk默认是禁用备用哈希的 if (threshold == -1) &#123; threshold = Integer.MAX_VALUE; &#125; // 参数为其它负数，则视为非法参数 if (threshold &lt; 0) &#123; throw new IllegalArgumentException("value must be positive integer."); &#125; &#125; catch(IllegalArgumentException failed) &#123; throw new Error("Illegal value for 'jdk.map.althashing.threshold'", failed); &#125; ALTERNATIVE_HASHING_THRESHOLD = threshold; &#125;&#125; 继续看inflateTable()中initHashSeedAsNeeded()这个方法，该方法是用来依据容量决定是否需要初始化hashSeed，hashSeed默认是0，如果初始化hashSeed。所以下面来看看这个方法：1234567891011121314151617181920212223/** * A randomizing value associated with this instance that is applied to * hash code of keys to make hash collisions harder to find. If 0 then * alternative hashing is disabled. */transient int hashSeed = 0;final boolean initHashSeedAsNeeded(int capacity) &#123; // 如果hashSeed != 0，表示当前正在使用备用哈希 boolean currentAltHashing = hashSeed != 0; // 如果vm启动了且map的容量大于阈值，使用备用哈希 boolean useAltHashing = sun.misc.VM.isBooted() &amp;&amp; (capacity &gt;= Holder.ALTERNATIVE_HASHING_THRESHOLD); // 异或操作，如果两值同时为false，或同时为true，都算是false。 boolean switching = currentAltHashing ^ useAltHashing; if (switching) &#123; // 把hashSeed设置成随机值 hashSeed = useAltHashing ? sun.misc.Hashing.randomHashSeed(this) : 0; &#125; return switching;&#125; 从hashSeed变量的注释可以看出，哈希种子一个随机值，在计算key的哈希码时会用到这个种子，目的是为了进一步减少哈希碰撞。如果hashSeed=0表示禁用备用哈希。 而Holder中维护的ALTERNATIVE_HASHING_THRESHOLD是触发启用备用哈希的阈值，该值表示，如果容器的容量（注意是容量，不是实际大小）达到了该值，容器应该启用备用哈希。 Holder会尝试读取JVM启动时传入的参数-Djdk.map.althashing.threshold并赋值给ALTERNATIVE_HASHING_THRESHOLD。它的值有如下含义： ALTERNATIVE_HASHING_THRESHOLD = 1，总是使用备用哈希 ALTERNATIVE_HASHING_THRESHOLD = -1，禁用备用哈希 在initHashSeedAsNeeded(int capacity)方法中，会判断如果容器的容量&gt;=ALTERNATIVE_HASHING_THRESHOLD，就会生成一个随机的哈希种子hashSeed，该种子会在put方法调用过程中的hash()中使用到：12345678910111213final int hash(Object k) &#123; // 如果哈希种子是随机值，使用备用哈希 int h = hashSeed; if (0 != h &amp;&amp; k instanceof String) &#123; return sun.misc.Hashing.stringHash32((String) k); &#125; h ^= k.hashCode(); // h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4);&#125; 扩容123456789101112131415161718void resize(int newCapacity) &#123; Entry[] oldTable = table; int oldCapacity = oldTable.length; // 旧容量值已经到了最大容量值 if (oldCapacity == MAXIMUM_CAPACITY) &#123; // 将阀值修改至最大整数 threshold = Integer.MAX_VALUE; return; &#125; // 新的Entry数组 Entry[] newTable = new Entry[newCapacity]; // 将旧数组的数据拷贝到新数组中 transfer(newTable, initHashSeedAsNeeded(newCapacity)); table = newTable; // 修改阀值 threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1);&#125; 这个时候不得不提resize()中的核心方法transfer()：12345678910111213141516void transfer(Entry[] newTable, boolean rehash) &#123; int newCapacity = newTable.length; // 新容量 for (Entry&lt;K,V&gt; e : table) &#123; // 遍历所有桶 while(null != e) &#123; // 遍历桶中所有的元素 Entry&lt;K,V&gt; next = e.next; if (rehash) &#123; e.hash = null == e.key ? 0 : hash(e.key); &#125; // 采用头插法的方式将旧数组中的数据拷贝到新数组中 int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; &#125; &#125;&#125; get()123456789public V get(Object key) &#123; // 获取key为空的元素 if (key == null) return getForNullKey(); // 依据key获取元素 Entry&lt;K,V&gt; entry = getEntry(key); return null == entry ? null : entry.getValue();&#125; 获取key为空的值：1234567891011private V getForNullKey() &#123; if (size == 0) &#123; return null; &#125; // key为null的元素存储在table的下标为0的位置 for (Entry&lt;K,V&gt; e = table[0]; e != null; e = e.next) &#123; if (e.key == null) return e.value; &#125; return null;&#125; getEntry()相对简单，直接贴源码：12345678910111213141516final Entry&lt;K,V&gt; getEntry(Object key) &#123; if (size == 0) &#123; return null; &#125; int hash = (key == null) ? 0 : hash(key); for (Entry&lt;K,V&gt; e = table[indexFor(hash, table.length)]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; return null;&#125; remove()remove()也比较简单直接贴源码：1234public V remove(Object key) &#123; Entry&lt;K,V&gt; e = removeEntryForKey(key); return (e == null ? null : e.value);&#125; 1234567891011121314151617181920212223242526272829final Entry&lt;K,V&gt; removeEntryForKey(Object key) &#123; if (size == 0) &#123; return null; &#125; int hash = (key == null) ? 0 : hash(key); int i = indexFor(hash, table.length); Entry&lt;K,V&gt; prev = table[i]; Entry&lt;K,V&gt; e = prev; while (e != null) &#123; Entry&lt;K,V&gt; next = e.next; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; modCount++; size--; if (prev == e) table[i] = next; else prev.next = next; e.recordRemoval(this); return e; &#125; prev = e; e = next; &#125; return e;&#125; 为什么JDK1.7 HashMap是线程不安全的？在多线程环境下，HashMap主要会出现下面三种问题： 死循环 数据丢失 数据覆盖 死循环和数据丢失死循环问题出现在resize()中的核心方法transfer()中：123e.next = newTable[i];newTable[i] = e;e = next; 头插法会将链表的顺序翻转，这也是形成死循环的关键点。 假设现在有两个线程A、B同时对下面这个HashMap进行扩容操作： HashMap01 正常扩容后的结果是下面这样的： HashMap02 但如果线程A在e.next = newTable[i];处CPU时间片耗尽，线程A被挂起，此时线程A中：e=3、next=7、e.next=null即： HashMap03 当线程A的时间片耗尽后，CPU开始执行线程B，并在线程B中成功的完成了数据拷贝，此时线程B中7.next=3、3.next=null，即： HashMap02 随后线程A获得CPU时间片继续执行，将3放入新数组对应的位置，执行完此轮循环后线程A的情况如下： HashMap04 接着继续执行下一轮循环，此时e=7，从主内存中读取e.next时发现主内存中7.next=3，于是乎next=3，并将7采用头插法的方式放入新数组中，并继续执行完此轮循环，结果如下： HashMap05 执行下一次循环可以发现，next=3.next=null，所以此轮循环将会是最后一轮循环。接下来当执行完e.next=newTable[i]即3.next=7后，3和7之间就相互连接了，当执行完newTable[i]=e后，3被头插法重新插入到链表中，执行结果如下图所示： HashMap06 此时next=null，将不会进行下一轮循环。到此线程A、B的扩容操作完成，很明显当线程A执行完后，HashMap中出现了环形结构，当在以后对该HashMap进行操作时会出现死循环。 并且从上图可以发现，元素5在扩容期间被莫名的丢失了，这就发生了数据丢失的问题。 数据覆盖还是在put()中：比如有两个线程A和B，首先A希望插入一个元素到HashMap中，首先计算记录所要落到的桶的索引坐标，然后获取到该桶里面的链表头结点，此时线程A后由于时间片耗尽导致被挂起，而线程B得到时间片后在该下标处插入了元素，完成了正常的插入，假设线程A插入的记录计算出来的桶索引和线程B要插入的记录计算出来的桶索引是一样的，那么当线程B成功插入之后，线程A再次被调度运行时，它依然持有过期的链表头，这就导致了线程B插入的数据被线程A覆盖了。 参考：Alternative hashing和hashSeed部分 https://segmentfault.com/a/1190000018520768]]></content>
      <categories>
        <category>Java乐园</category>
      </categories>
      <tags>
        <tag>HashMap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程中断]]></title>
    <url>%2F2019%2F09%2F02%2F%E7%BA%BF%E7%A8%8B%E4%B8%AD%E6%96%AD%2F</url>
    <content type="text"><![CDATA[今天同学给了我一道题目，发现自己对interrupt()、isInterrupted()、interrupted()理解的不好。 interrupt()、isInterrupted()、interrupted()我们先看一下例子。123456789101112131415161718192021222324252627282930313233343536373839public class Thread2 &#123; public static void main(String[] args) throws InterruptedException &#123; final Thread sleepThread = new Thread() &#123; @Override public void run() &#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;; Thread busyThread = new Thread() &#123; @Override public void run() &#123; while (true) &#123; &#125; &#125; &#125;; sleepThread.start(); busyThread.start(); sleepThread.interrupt(); busyThread.interrupt(); Thread.sleep(2000); System.out.println("sleepThread 0: " + sleepThread.isInterrupted()); while (sleepThread.isInterrupted()) ; System.out.println("sleepThread 1: " + sleepThread.isInterrupted()); System.out.println("busyThread 1: " + busyThread.isInterrupted()); System.out.println("sleepThread 2: " + sleepThread.interrupted()); System.out.println("busyThread 2: " + busyThread.interrupted()); System.out.println("sleepThread 3: " + sleepThread.isInterrupted()); System.out.println("busyThread 3: " + busyThread.isInterrupted()); &#125;&#125; 运行结果：12345678910java.lang.InterruptedException: sleep interrupted at java.base/java.lang.Thread.sleep(Native Method) at test.Thread2$1.run(Thread2.java:9)sleepThread 0: falsesleepThread 1: falsebusyThread 1: truesleepThread 2: falsebusyThread 2: falsesleepThread 3: falsebusyThread 3: true 很奇怪，为什么busyThread 2变成了false，接着busyThread 3又是true了呢？ 认识interrupt()、isInterrupted()、interrupted()interrupt()中断调用该方法的线程。 其有两个作用： 将线程的中断状态设置为true（不论线程是处于运行的还是阻塞状态） 让被阻塞的线程抛出InterruptedException异常（同时中断状态为false） 这样，对于那些阻塞方法(比如 wait() 和 sleep())而言，当另一个线程调用interrupt()中断该线程时，该线程会从阻塞状态退出并且抛出中断异常。这样，我们就可以捕捉到中断异常，并根据实际情况对该线程从阻塞方法中异常退出而进行一些处理。 isInterrupted()检测调用该方法的线程是否被中断，中断状态不会被清除。 先看一下源码：123public boolean isInterrupted() &#123; return isInterrupted(false); &#125; 可以看到isInterrupted()和interrupted()一样调用了isInterrupted()，不过isInterrupted()参数ClearInterrupted为false，即不清除中断状态。 interrupted()检测当前线程是否被中断，并且中断状态会被清除。 同样先看下源码：12345public static boolean interrupted() &#123; return currentThread().isInterrupted(true);&#125;private native boolean isInterrupted(boolean ClearInterrupted); 如果一个线程已经被终止了，中断状态是否被重置取决于ClearInterrupted的值，即ClearInterrupted为true时，中断状态会被重置，为false则不会被重置。 需要强调的是：interrupted()是static方法，调用的时候是Thread.interrupted()，而isInterrupted()是实例方法，调用时是用线程的实例调用。 因此，我们可以很容易知道上述例子中busyThread.isInterrupted()还是通过当前线程调用的，而当前线程为main，自然结果为false。 另一个问题为什么sleepThread 0 isInterrupted()的返回结果是false，同时如果将其上一行代码Thread.sleep(2000);删掉，其返回结果却是true。 我们是上面说过线程一旦被中断，isInterrupted()返回true，而一旦sleep等方法抛出异常，它将清除中断状态，此时方法将返回false。 再来，去掉Thread.sleep(2000);为什么返回结果是true呢，很简单呀这是两个线程，main线程需要等一等sleepThread这个线程抛出异常后，isInterrupted()才将中断状态清除。]]></content>
      <categories>
        <category>Java乐园</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap源码分析-JDK1.8]]></title>
    <url>%2F2019%2F08%2F20%2FHashMap%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-JDK1-8%2F</url>
    <content type="text"><![CDATA[浅析JDK1.8 HashMap源码。 写在开篇HashMap是最常用的数据结构之一，是JDK中util包下的一个集合类，基于Map接口实现、允许null键/值、非同步、不保证有序(比如插入的顺序)、也不保证顺序不随时间变化。 类的继承关系12public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable &#123; 继承于抽象的AbstractMap，实现了Map，Cloneable，Serializable这三个接口。 HashMap构造函数我们看下不带参数的构造方法：1234567/** * Constructs an empty &#123;@code HashMap&#125; with the default initial capacity * (16) and the default load factor (0.75). */public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted&#125; 我们可以看到HashMap的构造函数中只是简单地为负载因子（loadFactor）赋了一个默认的值0.75，其他的什么都没做。 HashMap的put函数向HashMap中插入一个键值对主要涉及到下面的三个函数：123public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125; 在进一步了解putVal之前，我们还需要知道后面我们会讲到的table究竟是何方神圣。1234567/** * The table, initialized on first use, and resized as * necessary. When allocated, length is always a power of two. * (We also tolerate length zero in some operations to allow * bootstrapping mechanics that are currently not needed.) */transient Node&lt;K,V&gt;[] table; //实际上table就是HashMap中的数组。 putVal函数才是真正的put方法。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283/** * Implements Map.put and related methods. * * @param hash hash for key * @param key the key * @param value the value to put * @param onlyIfAbsent if true, don't change existing value * @param evict if false, the table is in creation mode. * @return previous value, or null if none */final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; /* //调用resize()初始化数组 final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; //0 int oldThr = threshold; //0 int newCap, newThr = 0; if (oldCap &gt; 0) &#123; //... &#125; else if (oldThr &gt; 0) //... else &#123; //初始化数组容量和阈值 newCap = DEFAULT_INITIAL_CAPACITY; //16 newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); // 0.75 * 16 = 12（也就是map的size达到12时，就会扩容） &#125; if (newThr == 0) &#123; //... &#125; threshold = newThr; //将新阈值赋给threshold @SuppressWarnings(&#123;"rawtypes","unchecked"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; //... &#125; return newTab; //返回初始化的新数组 &#125; */ if ((p = tab[i = (n - 1) &amp; hash]) == null) //数组该位置上仍没有结点 tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) //key值相等 e = p; else if (p instanceof TreeNode) //p为树结点 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; //p为链表结点 for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; // 尾插法插入新结点 p.next = newNode(hash, key, value, null); //static final int TREEIFY_THRESHOLD = 8; if (binCount &gt;= TREEIFY_THRESHOLD - 1) // 超过TREEIFY_THRESHOLD将把链表转化为红黑树 treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // 存在key冲突（key值相同） V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; //modCount是此HashMap经过结构修改的次数 ++modCount; if (++size &gt; threshold) resize(); //这里的resize()是扩容的含义了 afterNodeInsertion(evict); return null;&#125; 接下来我们讲讲resize扩容操作（当map的size达到threshold时，就会扩容）。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; //超过HashMap的容量上限就不再继续扩容 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; //新容量为原容量的2倍，新的上线为原上线的2倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) newCap = oldThr; else &#123; newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; //初始化新容量数组 @SuppressWarnings(&#123;"rawtypes","unchecked"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; //oldTab[j]不为空 oldTab[j] = null; if (e.next == null) //若该节点不存在散列冲突，计算在新数组中的槽位，直接插入 newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) //插入红黑树节点 ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; //按照原顺序插入链表节点（不同于jdk1.7） Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; /* *(e.hash &amp; oldCap) == 0 * 如果这个判断为true则说明e这个节点在resize之后不需要挪位置，反之则需要换个位置。 * 虽然这个代码难理解，但是自己举几个例子也能判断出来 * 比如有1，17两个数，在HashMap大小是16的时候，他们的hash值都是1， * 如果此时扩容为32，可以看出1的hash是不变的， * 但是17是会变，也就是说 1 &amp; 16 = 0， 17 &amp; 16 != 0 */ if ((e.hash &amp; oldCap) == 0) &#123; //保持原槽位 if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; //原槽位+原容量 if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; //原槽位插入新数组中 loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; //原槽位+原容量插入新数组中 hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; HashMap如何降低冲突主要从两个地方来说明： 为什么HashMap要采用2的n次方的数量级作为数组的长度答案是因为HashMap需要用length-1的数量级和hash值做一个与操作1p = tab[i = (n - 1) &amp; hash] 如果长度是17,那么length-1就是16那么与下来的值要么是0要么是16,也就是说16个槽子只用了两个槽,效率是很低的,而如果采用16(2的四次方),就是15(01111)做与操作,均匀分不到0-15的槽子上我们可以从下面的例子中说明问题： 12345n = 17 -&gt; 0001 0001n - 1 -&gt; 0001 0000假设hash值为 0000 0001 那么和(n-1)执行&amp;运算后结果为 0000 0000假设hash值为 0000 0011 那么和(n-1)执行&amp;运算后结果为 0000 0000 如果长度是17,那么length-1就是16，那么与下来的值要么是0要么是16,也就是说16个槽子只用了两个槽,效率是很低的。 12345n = 16 -&gt; 0001 0000n - 1 -&gt; 0000 1111假设hash值为 0000 0001 那么和(n-1)执行&amp;运算后结果为 0000 0001假设hash值为 0000 0011 那么和(n-1)执行&amp;运算后结果为 0000 0011 而如果长度是16,那么length-1就是15，做与操作可以均匀分配到0-15的槽子上。 hash函数如果是自己实现hash算法的话，最简单的话就是直接用hasCode对(n-1)取余：1index = key.hasCode() &amp; (n-1) 这种方法是有缺陷的，就是取余的计算结果对高位是无效的，只是对低位有效，当计算出来的hasCode()只有高位有变化时，取余的结果还是一样的。 当key计算出来的hashCode()只有高位变化时，最终算出来的index索引就会引起hash冲突，如果冲突太多的话，HashMap的效率就会非常低下了。 我们看看JDK1.8中hash算法的实现。123456static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); &#125; index = (n - 1) &amp; hash(key) //n表示长度 首先，对hashCode进行16位的无符号右移，然后对自身进行异或运算，最后取余。通过上面的操作，hash能够把高位的变化影响到低位的变化。 至于为什么是使用异或（^）,因为&amp;和|都会使得结果偏向0或者1 ,并不是均匀的概念。 HashMap的get函数get()比较简单，直接贴源码。123456789101112131415161718192021222324public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125;final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; HashMap的remove函数remove()和get()差不多，通过node将查找的结点记录下，再进行删除相关的操作。12345678910111213141516171819202122232425262728293031323334353637383940414243444546public V remove(Object key) &#123; Node&lt;K,V&gt; e; return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value;&#125;final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) &#123; Node&lt;K,V&gt; node = null, e; K k; V v; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) node = p; else if ((e = p.next) != null) &#123; if (p instanceof TreeNode) node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); else &#123; do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; node = e; break; &#125; p = e; &#125; while ((e = e.next) != null); &#125; &#125; if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) &#123; if (node instanceof TreeNode) ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); else if (node == p) tab[index] = node.next; else p.next = node.next; ++modCount; --size; afterNodeRemoval(node); return node; &#125; &#125; return null;&#125; 为什么HashMap是线程不安全的JDK1.7 HashMap中出现的死循环、数据丢失已经得到了解决，可是它仍然存在数据覆盖的问题。 在putVal()如果不存在hash冲突：12if ((p = tab[i = (n - 1) &amp; hash]) == null) // 如果没有hash碰撞则直接插入元素 tab[i] = newNode(hash, key, value, null); 假设两个线程A、B都在进行put操作，并且hash函数计算出的插入下标是相同的，当线程A执行完if ((p = tab[i = (n - 1) &amp; hash]) == null)后由于时间片耗尽导致被挂起，而线程B得到时间片后在该下标处插入了元素，完成了正常的插入，然后线程A获得时间片，由于之前已经进行了hash碰撞的判断，所有此时不会再进行判断，而是直接进行插入，这就导致了线程B插入的数据被线程A覆盖了，从而线程不安全。 putval()最后size+1的时候：12if (++size &gt; threshold) resize(); ++size，一个最常见的线程不安全问题，还是由于数据覆盖又导致了线程不安全。 被transient所修饰table变量最后还想提一个容易被大家忽略的点，如果大家细心阅读HashMap的源码，会发现桶数组table被申明为transient。transient表示易变的意思，在Java中，被该关键字修饰的变量不会被默认的序列化机制序列化。我们再回到源码中，考虑一个问题：桶数组table是HashMap底层重要的数据结构，不序列化的话，别人还怎么还原呢？ 这里简单说明一下吧，HashMap并没有使用默认的序列化机制，而是通过实现readObject/writeObject两个方法自定义了序列化的内容。这样做是有原因的，试问一句，HashMap中存储的内容是什么？不用说，大家也知道是键值对。所以只要我们把键值对序列化了，我们就可以根据键值对数据重建HashMap。有的朋友可能会想，序列化table不是可以一步到位，后面直接还原不就行了吗？这样一想，倒也是合理。但序列化talbe存在着两个问题： table 多数情况下是无法被存满的，序列化未使用的部分，浪费空间 同一个键值对在不同 JVM 下，所处的桶位置可能是不同的，在不同的 JVM 下反序列化 table 可能会发生错误。 以上两个问题中，第一个问题比较好理解，第二个问题解释一下。HashMap的get/put/remove等方法第一步就是根据hash找到键所在的桶位置，但如果键没有覆写hashCode方法，计算hash时最终调用Object中的hashCode方法。但Object中的hashCode方法是native型的，不同的JVM下，可能会有不同的实现，产生的hash可能也是不一样的。也就是说同一个键在不同平台下可能会产生不同的 hash，此时再对在同一个table继续操作，就会出现问题。 参考：transient所修饰table变量 https://segmentfault.com/a/1190000012926722?utm_source=tag-newest#item-3-6]]></content>
      <categories>
        <category>Java乐园</category>
      </categories>
      <tags>
        <tag>HashMap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为何不能创建参数化类型数组]]></title>
    <url>%2F2019%2F08%2F10%2F%E4%B8%BA%E4%BD%95%E4%B8%8D%E8%83%BD%E5%88%9B%E5%BB%BA%E5%8F%82%E6%95%B0%E5%8C%96%E7%B1%BB%E5%9E%8B%E6%95%B0%E7%BB%84%2F</url>
    <content type="text"><![CDATA[对https://blog.csdn.net/s10461/article/details/53941091中泛型数组做一下补充总结。（这篇博客对于泛型总结得挺好） 在Java中是不能实例化参数化类型数组的，例如：1List&lt;String&gt;[] ls = new ArrayList&lt;String&gt;[10]; 而使用通配符创建泛型数组是可以的，例如：1List&lt;?&gt;[] ls = new ArrayList&lt;?&gt;[10]; 这样也是可以的：1List&lt;String&gt;[] ls = new ArrayList[10]; 文中举了一个例子：1234567List&lt;String&gt;[] lsa = new List&lt;String&gt;[10]; // Not really allowed. Object o = lsa; Object[] oa = (Object[]) o; List&lt;Integer&gt; li = new ArrayList&lt;Integer&gt;(); li.add(new Integer(3)); oa[1] = li; // Unsound, but passes run time store check String s = lsa[1].get(0); // Run-time error: ClassCastException. 对于oa[1] = li; 如果试图存储其他类型的元素，就会抛出一个ArrayStoreException异常，不过对于泛型类型，擦除会使这种机制无效。所以文中会说 Unsound, but passes run time store check（不健全，但通过运行时存储检查 ）。 它的重点在下一句String s = lsa[1].get(0);抛出Run-time error: ClassCastException。在取出数据的时候却要做一次类型转换，所以就会出现ClassCastException，如果可以进行泛型数组的声明，上面说的这种情况在编译期将不会出现任何的警告和错误，只有在运行时才会出错。但通配符方式取出数据是会做显示的类型转换的，所以不会抛出这个运行时异常。这也就是为什么第一种情况不被允许而使用通配符创建泛型数组可以。 下面采用通配符的方式是被允许的:1234567List&lt;?&gt;[] lsa = new List&lt;?&gt;[10]; // OK, array of unbounded wildcard type. Object o = lsa; Object[] oa = (Object[]) o; List&lt;Integer&gt; li = new ArrayList&lt;Integer&gt;(); li.add(new Integer(3)); oa[1] = li; // Correct. Integer i = (Integer) lsa[1].get(0); // OK]]></content>
      <categories>
        <category>Java乐园</category>
      </categories>
      <tags>
        <tag>泛型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通配符类型]]></title>
    <url>%2F2019%2F08%2F10%2F%E9%80%9A%E9%85%8D%E7%AC%A6%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[在 Java 泛型中存在通配符的概念: &lt;? extends C&gt;是上界通配符&lt;? super C&gt;是下界通配符 接下来对这些进行说明，先定义几个类：1234567class A&#123;&#125;;class B extends A&#123;&#125;;class C extends B&#123;&#125;;class D extends B&#123;&#125;; 为什么会出现这个呢？12A a = new B();List&lt;A&gt; list= new ArrayList&lt;B&gt;(); // 报错Type mismatch 这是因为无论A和B有什么关系，通常，List和List没有什么联系。那么我们通过&lt;? extends B&gt;解决这个问题：12345public class Test&#123; public static void main(String[] args) &#123; List&lt;? extends A&gt; list = new ArrayList&lt;B&gt;(); //OK &#125;&#125; 这里用的是 ArrayList 做例子，但并不是只针对集合，是针对类似集合出现的问题的情景。 局限性上界&lt;? extends B&gt;不能往里存，只能往外取 add() 编译器只知道类型是B或者B的子类，所以可能是B、C、D其中的一个类型，但为了保证类型的安全就不能添加除了null之外的元素，即使是B本身也不行。（因为B不能代表C或者D） get() 此时不知道返回的是B、C、D其中哪个类型，所以返回类型是B 下界&lt;? super B&gt;可以存（存的只能是B或者B的子类），但往外取只能放在Object对象里 add() 可以添加B、C、D（因为C或D可以代表B） get() 因为是下边界，所以返回类型只能是Object，所以说它的get()受到限制]]></content>
      <categories>
        <category>Java乐园</category>
      </categories>
      <tags>
        <tag>泛型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java反射]]></title>
    <url>%2F2019%2F04%2F20%2FJava%E5%8F%8D%E5%B0%84%2F</url>
    <content type="text"><![CDATA[转载自：http://www.cnblogs.com/chanshuyi/p/head_first_of_reflection.html 概述 反射就是在运行时才知道要操作的类是什么，并且可以在运行时获取类的完整构造，并调用对应的方法。 反射之中包含了一个「反」字，所以想要解释反射就必须先从「正」开始解释。 一般情况下，我们使用某个类时必定知道它是什么类，是用来做什么的。于是我们直接对这个类进行实例化，之后使用这个类对象进行操作。 12Apple apple = new Apple(); //直接初始化，「正射」apple.setPrice(4); 上面这样子进行类对象的初始化，我们可以理解为「正」。 而反射则是一开始并不知道我要初始化的类对象是什么，自然也无法使用 new 关键字来创建对象了。 这时候，我们使用 JDK 提供的反射 API 进行反射调用： 12345Class clz = Class.forName("com.chenshuyi.reflect.Apple");Method method = clz.getMethod("setPrice", int.class);Constructor constructor = clz.getConstructor();Object object = constructor.newInstance();method.invoke(object, 4); 上面两段代码的执行结果，其实是完全一样的。但是其思路完全不一样，第一段代码在未运行时就已经确定了要运行的类（Apple），而第二段代码则是在运行时通过字符串值才得知要运行的类（com.chenshuyi.reflect.Apple）。 所以说什么是反射？ 当程序运行时，允许改变程序结构或变量类型，这种语言称为动态语言。我们认为 Java 并不是动态语言，但是它却又一个非常突出的动态相关的机制，俗称：反射。Reflection 是Java 程序开发语言的特征之一，它允许运行中的 Java 程序获取自身的信息，并且可以操作类和对象的内部属性。 通过反射，我们可以在运行时获得程序或程序集中每一个类型成员和成员变量的信息。 程序中一般的对象类型都是在编译期就确定下来的，而Java 反射机制可以动态的创建对象并调用其属性，这样对象的类型在编译期是未知的。所以我们可以通过反射机制直接创建对象即使这个对象在编译期是未知的. 反射的核心：是 JVM 在运行时 才动态加载的类或调用方法或属性，他不需要事先（写代码的时候或编译期）知道运行对象是谁。 Java反射框架提供以下功能： 在运行时判断任意一个对象所属的类 在运行时构造任意一个类的对象 在运行时判断任意一个类所具有的成员变量和方法（通过反射设置可以调用 private） 在运行时调用人一个对象的方法 反射的主要用途很多人都认为反射在实际Java中开发应用中并不广泛，其实不然。当我们在使用 IDE（如 Eclipse\IDEA）时，当我们输入一个队长或者类并向调用它的属性和方法时，一按 (“.”)点号，编译器就会自动列出她的属性或方法，这里就会用到反射。 反射最重要的用途就是开发各种通用框架。很多框架（比如 Spring）都是配置化的（比如通过 XML文件配置 JavaBean，Action之类的），为了保证框架的通用性，他们可能根据配置文件加载不同的对象或类，调用不同的方法，这个时候就必须用到反射——运行时动态加载需要加载的对象。举一个例子，在运用Struts 2框架的开发中我们一般会在struts.xml里去配置Action，比如：123456&lt;action name="login" class="org.ScZyhSoft.test.action.SimpleLoginAction" method="execute"&gt; &lt;result&gt;/shop/shop-index.jsp&lt;/result&gt; &lt;result name="error"&gt;login.jsp&lt;/result&gt;&lt;/action&gt; 配置文件与Action建立了一种映射关系，当View层发出请求时，请求会被StrutsPrepareAndExecuteFilter拦截，然后StrutsPrepareAndExecuteFilter会去动态地创建Action实例。 ——比如我们请求login.action，那么StrutsPrepareAndExecuteFilter就会去解析struts.xml文件，检索action中name为login的Action，并根据class属性创建SimpleLoginAction实例，并用invoke方法来调用execute方法，这个过程离不开反射。对与框架开发人员来说，反射虽小但作用非常大，它是各种容器实现的核心。而对于一般的开发者来说，不深入框架开发则用反射用的就会少一点，不过了解一下框架的底层机制有助于丰富自己的编程思想，也是很有益的。 一个简单的例子上面提到的示例程序，其完整的程序代码如下： 123456789101112131415161718192021222324252627public class Apple &#123; private int price; public int getPrice() &#123; return price; &#125; public void setPrice(int price) &#123; this.price = price; &#125; public static void main(String[] args) throws Exception&#123; //正常的调用 Apple apple = new Apple(); apple.setPrice(5); System.out.println("Apple Price:" + apple.getPrice()); //使用反射调用 Class clz = Class.forName("com.chenshuyi.api.Apple"); Method setPriceMethod = clz.getMethod("setPrice", int.class); Constructor appleConstructor = clz.getConstructor(); Object appleObj = appleConstructor.newInstance(); setPriceMethod.invoke(appleObj, 14); Method getPriceMethod = clz.getMethod("getPrice"); System.out.println("Apple Price:" + getPriceMethod.invoke(appleObj)); &#125;&#125; 从代码中可以看到我们使用反射调用了 setPrice 方法，并传递了 14 的值。之后使用反射调用了 getPrice 方法，输出其价格。上面的代码整个的输出结果是： 12Apple Price:5Apple Price:14 从这个简单的例子可以看出，一般情况下我们使用反射获取一个对象的步骤： 获取类的 Class 对象实例 1Class clz = Class.forName("com.zhenai.api.Apple"); 根据 Class 对象实例获取 Constructor 对象 1Constructor appleConstructor = clz.getConstructor(); 使用 Constructor 对象的 newInstance 方法获取反射类对象 1Object appleObj = appleConstructor.newInstance(); 而如果要调用某一个方法，则需要经过下面的步骤： 获取方法的 Method 对象 1Method setPriceMethod = clz.getMethod("setPrice", int.class); 利用 invoke 方法调用方法 1setPriceMethod.invoke(appleObj, 14); 到这里，我们已经能够掌握反射的基本使用。但如果要进一步掌握反射，还需要对反射的常用 API 有更深入的理解。 在 JDK 中，反射相关的 API 可以分为下面几个方面：获取反射的 Class 对象、通过反射创建类对象、通过反射获取类属性方法及构造器。 反射常用API获取反射中的Class对象在反射中，要获取一个类或调用一个类的方法，我们首先需要获取到该类的 Class 对象。 在 Java API 中，获取 Class 类对象有三种方法： 第一种，使用 Class.forName 静态方法。当你知道该类的全路径名时，你可以使用该方法获取 Class 类对象。1Class clz = Class.forName("java.lang.String"); 第二种，使用 .class 方法。 这种方法只适合在编译前就知道操作的 Class。1Class clz = String.class; 第三种，使用类对象的 getClass() 方法。12String str = new String("Hello");Class clz = str.getClass(); 通过反射创建类对象通过反射创建类对象主要有两种方式：通过 Class 对象的 newInstance() 方法、通过 Constructor 对象的 newInstance() 方法 第一种：通过 Class 对象的 newInstance() 方法12Class clz = Apple.class;Apple apple = (Apple)clz.newInstance(); 第二种：通过 Constructor 对象的 newInstance() 方法123Class clz = Apple.class;Constructor constructor = clz.getConstructor();Apple apple = (Apple)constructor.newInstance(); 通过 Constructor 对象创建类对象可以选择特定构造方法，而通过 Class 对象则只能使用默认的无参数构造方法。下面的代码就调用了一个有参数的构造方法进行了类对象的初始化。123Class clz = Apple.class;Constructor constructor = clz.getConstructor(String.class, int.class);Apple apple = (Apple)constructor.newInstance("红富士", 15); 通过反射获取类属性、方法、构造器我们通过 Class 对象的 getFields() 方法可以获取 Class 类的属性，但无法获取私有属性。 12345Class clz = Apple.class;Field[] fields = clz.getFields();for (Field field : fields) &#123; System.out.println(field.getName());&#125; 输出结果是： 1price 而如果使用 Class 对象的 getDeclaredFields() 方法则可以获取包括私有属性在内的所有属性： 12345Class clz = Apple.class;Field[] fields = clz.getDeclaredFields();for (Field field : fields) &#123; System.out.println(field.getName());&#125; 输出结果是： 12nameprice 与获取类属性一样，当我们去获取类方法、类构造器时，如果要获取私有方法或私有构造器，则必须使用有 declared 关键字的方法。 反射源码解析当我们懂得了如何使用反射后，今天我们就来看看 JDK 源码中是如何实现反射的。或许大家平时没有使用过反射，但是在开发 Web 项目的时候会遇到过下面的异常： 1234java.lang.NullPointerException ...sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) 可以看到异常堆栈指出了异常在 Method 的第 497 的 invoke 方法中，其实这里指的 invoke 方法就是我们反射调用方法中的 invoke。 12Method method = clz.getMethod("setPrice", int.class); method.invoke(object, 4); //就是这里的invoke方法 例如我们经常使用的 Spring 配置中，经常会有相关 Bean 的配置： 12&lt;bean class="com.chenshuyi.Apple"&gt;&lt;/bean&gt; 当我们在 XML 文件中配置了上面这段配置之后，Spring 便会在启动的时候利用反射去加载对应的 Apple 类。而当 Apple 类不存在或发生启发异常时，异常堆栈便会将异常指向调用的 invoke 方法。 从这里可以看出，我们平常很多框架都使用了反射，而反射中最最终的就是 Method 类的 invoke 方法了。 下面我们来看看 JDK 的 invoke 方法到底做了些什么。 进入 Method 的 invoke 方法我们可以看到，一开始是进行了一些权限的检查，最后是调用了 MethodAccessor 类的 invoke 方法进行进一步处理，如下图红色方框所示。 reflect1 那么 MethodAccessor 又是什么呢？其实 MethodAccessor 是一个接口，定义了方法调用的具体操作，而它有三个具体的实现类： sun.reflect.DelegatingMethodAccessorImpl sun.reflect.MethodAccessorImpl sun.reflect.NativeMethodAccessorImpl 而要看 ma.invoke() 到底调用的是哪个类的 invoke 方法，则需要看看 MethodAccessor 对象返回的到底是哪个类对象，所以我们需要进入 acquireMethodAccessor() 方法中看看。 reflect2 从 acquireMethodAccessor() 方法我们可以看到，代码先判断是否存在对应的 MethodAccessor 对象，如果存在那么就复用之前的 MethodAccessor 对象，否则调用 ReflectionFactory 对象的 newMethodAccessor 方法生成一个 MethodAccessor 对象。 reflect3 在 ReflectionFactory 类的 newMethodAccessor 方法里，我们可以看到首先是生成了一个 NativeMethodAccessorImpl 对象，再这个对象作为参数调用 DelegatingMethodAccessorImpl 类的构造方法。 这里的实现是使用了代理模式，将 NativeMethodAccessorImpl 对象交给 DelegatingMethodAccessorImpl 对象代理。我们查看 DelegatingMethodAccessorImpl 类的构造方法可以知道，其实是将 NativeMethodAccessorImpl 对象赋值给 DelegatingMethodAccessorImpl 类的 delegate 属性。 reflect4 所以说ReflectionFactory 类的 newMethodAccessor 方法最终返回 DelegatingMethodAccessorImpl 类对象。所以我们在前面的 ma.invoke() 里，其将会进入 DelegatingMethodAccessorImpl 类的 invoke 方法中。 reflect5 进入 DelegatingMethodAccessorImpl 类的 invoke 方法后，这里调用了 delegate 属性的 invoke 方法，它又有两个实现类，分别是：DelegatingMethodAccessorImpl 和 NativeMethodAccessorImpl。按照我们前面说到的，这里的 delegate 其实是一个 NativeMethodAccessorImpl 对象，所以这里会进入 NativeMethodAccessorImpl 的 invoke 方法。 reflect6 而在 NativeMethodAccessorImpl 的 invoke 方法里，其会判断调用次数是否超过阀值（numInvocations）。如果超过该阀值，那么就会生成另一个MethodAccessor 对象，并将原来 DelegatingMethodAccessorImpl 对象中的 delegate 属性指向最新的 MethodAccessor 对象。 到这里，其实我们可以知道 MethodAccessor 对象其实就是具体去生成反射类的入口。通过查看源码上的注释，我们可以了解到 MethodAccessor 对象的一些设计信息。 1234567&quot;Inflation&quot; mechanism. Loading bytecodes to implement Method.invoke() and Constructor.newInstance() currently costs 3-4x more than an invocation via native code for the first invocation (though subsequent invocations have been benchmarked to be over 20x faster).Unfortunately this cost increases startup time for certain applications that use reflection intensively (but only once per class) to bootstrap themselves.Inflation 机制。初次加载字节码实现反射，使用 Method.invoke() 和 Constructor.newInstance() 加载花费的时间是使用原生代码加载花费时间的 3 - 4 倍。这使得那些频繁使用反射的应用需要花费更长的启动时间。To avoid this penalty we reuse the existing JVM entry points for the first few invocations of Methods and Constructors and then switch to the bytecode-based implementations. Package-private to be accessible to NativeMethodAccessorImpl and NativeConstructorAccessorImpl.为了避免这种痛苦的加载时间，我们在第一次加载的时候重用了 JVM 的入口，之后切换到字节码实现的实现。 就像注释里说的，实际的 MethodAccessor 实现有两个版本，一个是 Native 版本，一个是 Java 版本。 Native 版本一开始启动快，但是随着运行时间边长，速度变慢。Java 版本一开始加载慢，但是随着运行时间边长，速度变快。正是因为两种存在这些问题，所以第一次加载的时候我们会发现使用的是 NativeMethodAccessorImpl 的实现，而当反射调用次数超过 15 次之后，则使用 MethodAccessorGenerator 生成的 MethodAccessorImpl 对象去实现反射。 Method 类的 invoke 方法整个流程可以表示成如下的时序图： reflect7 讲到这里，我们了解了 Method 类的 invoke 方法的具体实现方式。知道了原来 invoke 方法内部有两种实现方式，一种是 native 原生的实现方式，一种是 Java 实现方式，这两种各有千秋。而为了最大化性能优势，JDK 源码使用了代理的设计模式去实现最大化性能。]]></content>
      <categories>
        <category>Java乐园</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[保存对象]]></title>
    <url>%2F2019%2F04%2F12%2F%E4%BF%9D%E5%AD%98%E5%AF%B9%E8%B1%A1%2F</url>
    <content type="text"><![CDATA[如果你正在编写游戏，就得有存储和恢复游戏的功能。如果你编写的是创建图表的程序，也必须有存储/打开的功能。如果程序需要存储状态，有两种方式： 写入文件的序列化对象 写入文本文件 概述 对象有状态和行为两种属性。行为存在于类中，而状态存在于个别对象中。 如果你正在编写游戏，就得有存储和恢复游戏的功能。如果你编写的是创建图表的程序，也必须有存储/打开的功能。如果程序需要存储状态，有两种方式： 只有自己写的java程序会用到这些数据：用序列化（serialization）。这采用了面向对象的方式来做，将被序列化的对象写到文件中，然后就可以让你的程序去文件中读取序列化的对象并把它们展开回到活生生的状态。 如果数据需要被其他程序引用：写一个纯文本文件。用其他程序可以解析的特殊字符写到文件中，例如写成用tab字符来隔的档案以便让电子表格或数据库应用程序能够应用。 序列化序列化下面是将对象序列化的方法步骤。 Serializable1 12345678910111213//创建出FileOutputStreamFileOutputStream fileStream = new FileOutputStream("MyGame.ser");//创建ObjectOutputStreamObjectOutputStream os = new ObjectOutputStream(fileStream);//写入对象os.writeObject(characterOne);os.writeObject(characterTwo);os.writeObject(characterThree);//关闭ObjectOutputStreamos.close(); 解序列化下面是解序列化的方法步骤。 Serializable2 12345678910111213//创建出FileInputStreamFileInputStream fileStream = new FileIntStream("MyGame.ser");//创建ObjectInputStreamObjecInputStream os = new ObjecInputStream(fileStream);//写入对象Object one = os.readObject();Object two = os.writeObject();Object three = os.writeObject();//关闭ObjectInputStreamos.close(); 接下来我们通过一个实例来进一步了解序列化的用法代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public class GameCharacter implements Serializable &#123; private int power; private String type; private Weapon weapon; public int getPower() &#123; return power; &#125; public void setPower(int power) &#123; this.power = power; &#125; public String getType() &#123; return type; &#125; public void setType(String type) &#123; this.type = type; &#125; public Weapon getWeapon() &#123; return weapon; &#125; public void setWeapon(Weapon weapon) &#123; this.weapon = weapon; &#125; public void useWeapon()&#123; System.out.println("user weapon"); &#125; @Override public String toString() &#123; return "GameCharacter&#123;" + "power=" + power + ", type='" + type + '\'' + ", weapon=" + weapon + '&#125;'; &#125; public static void main(String[] args) &#123; GameCharacter gameCharacter = new GameCharacter(); gameCharacter.setPower(3); gameCharacter.setType("士兵"); Weapon weapon = new Weapon(1,"长矛"); gameCharacter.setWeapon(weapon); try &#123; //创建出FileOutputStream FileOutputStream fileStream = new FileOutputStream("d://MyGame.ser"); //创建ObjectOutputStream ObjectOutputStream os = new ObjectOutputStream(fileStream); //写入对象 os.writeObject(gameCharacter); //关闭ObjectOutputStream os.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;&#125;&#125;public class Weapon implements Serializable &#123; int id; String name; public Weapon(int id, String name) &#123; this.id = id; this.name = name; &#125;&#125; 当对象被序列化时，被该对象引用的实例 变量也会被序列化。（也就是当保存gameCharacter对象时，所有的对象都会被保存），所以如果对象被实例化时，被该对象引用的实例变量也需要实现Serializable接口。否则会抛出下面这个异常： Serializable3 如果某实例变量不能或不应该被实例化，就把它标记为transient（瞬时）的。 Serializable4 为什么有些变量不能被序列化？ 可能是设计者忘记实现Serializable。 或者动态数据只可以在执行时求出而不能或不必储存。 VersionID: 序列化的识别（版本控制）如果你将对象序列化，你必须有该类才能还原和使用该对象。但若你同时修改了该类会发生什么事情？假设你尝试把GameCharacter对象带回来，而非transient的变量type已经从String被改成int。这样会严重的违反java大的类型安全性。在对象被序列化之后类有了不同的serialVersionUID，则会还原失败。 Serializable5 会损害序列化的修改： 删除实例变量 改变实例变量的类型 将非瞬时的实例变量该为瞬时的 改变类的继承层次 将类从可序列化改成不可序列化 将实例变量改成静态的 通常不会有事的修改： 加入新的实例变量（还原时会使用默认值） 在继承层次中加入新的类 从继承层次中删除类 改变类的继承层次 不会影响解序列化程序设定变量值的层次修改 将实例变量从瞬时改成非瞬时（会使用默认值） 如果你认为类有可能会演化，就把版本识别ID放在类中 Serializable6 因此解决方案就是把serialVersionUID放在class中，让类在演化过程中还维持相同的ID。 但这只会在你有很小心地维护类的变动才办得到！也就是你得要对带回旧对象的任何问题负起全责。 文件输入输出]]></content>
      <categories>
        <category>Java乐园</category>
      </categories>
      <tags>
        <tag>序列化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring IoC容器浅析]]></title>
    <url>%2F2019%2F04%2F11%2FSpring%20IoC%E5%AE%B9%E5%99%A8%E6%B5%85%E6%9E%90%2F</url>
    <content type="text"><![CDATA[在Spring中，它会认为一切Java类都是资源，而资源都是Bean，容纳这些Bean的是Spring所提供的IoC容器（所以Spring是一种基于Bean的编程）。 Spring IoC概述 控制反转是一种通过描述（在Java中可以是XML或者是注解）并通过第三方去产生或获取特定对象的方式。而在Spring中实现控制反转的是IoC容器，其实现方式是依赖注入。 控制反转的思想在理解上是有一定的困难的，接下来我们通过一个现实中的例子来尝试解释一下： 现实系统的开发者是一个团队，团队由许多开发者组成。现在假设你在一个电商网站负责开发工作，你熟悉商品交易流程，但是对财务处理却不怎么熟悉，而团队中有些成员对于财务处理十分熟悉，在交易的过程中，商品交易流程需要调度财务的相关接口，才能得以实现，那么你期望的应该是： 熟悉财务流程的成员开发对应的接口。 接口逻辑尽量简单，内部复杂的业务逻辑并不需要自己去了解，你只要通过简单的调用就能使用。 通过简单的描述就能获取这个接口实例，且描述应该尽量简单。 到这里有一个事实需要注意，财务接口对象的创建并不是自己的行为，而是财务开发同事的行为，但也完全达到了你的要求，而在潜意识里你会觉得对象应该由你主动创建，但事实上这并不是你真实的需要，也许你对这一领域并不精通，这个时候可以把创建对象的主动权转交别人，这就是控制反转的概念。 这理念的一个坏处是理解上的困难，但是它最大的好处在于降低对象之间的耦合，在一个系统中有些类，具体如何实现并不需要去理解，只需要知道它有什么用就可以了。只是这里对象的产生依靠于IoC容器，而不是开发者主动的行为。 Spring IoC的原理实现原生的 JavaEE 技术中各个模块之间的联系较强，即耦合度较高。而 Spring 框架的核心–IoC（控制反转）很好的解决了这一问题。 接下来我们通过在web层创建业务层的一个类，讲述一下Spring IoC的原理实现。 开始我们先直接通过UserService创建一个类： 1UserService us = new UserService(); 但我们都知道这种方式不好，因为它没有面向接口编程，所以接下来我们选择面向接口编程： 1UserService us = new UserServiceImpl(); 但由于我们在web层直接创建了接口的实现类，那这样业务层就和web层产生耦合了。这时候我们就需要提及ocp原则（开闭原则）了 open-close原则：对程序扩展是open的，对修改程序代码是close的。（尽量不修改程序的源码，实现对程序的扩展） 我们可以想到使用一个设计模式：工厂模式。 现在我们就可以通过工厂类来创建UserService的实例对象：123456class FactoryBean&#123; public static UserService getUs()&#123; return new UserServiceImpl(); &#125; //...&#125; 这样我们的接口和实现类就没有耦合了，但接口和工厂类就会产生耦合1UserService us = FactoryBean.getUs(); 那么这里我们就可以通过工厂+反射+配置文件来实现解耦合：1&lt;bean id="us" class="com.Kyrie.UserServiceImpl"/&gt; 123456class FactoryBean()&#123; public static Object getBean(String id)&#123; //解析xml，找到class //反射 &#125;&#125; 我们在getBean中传入一个id，那就会返回一个class，接着我们通过反射去生成我们一个实例化对象。 这就是Spring来完成解耦合的思想。 IoC容器通过上面我们知道了Spring IoC容器的作用，它可以容纳我们所开发的各种Bean，并且我们可以从中获取各种发布在Spring IoC容器里的Bean，并且通过描述可以得到它。 IoC容器的设计Spring IoC容器的设计主要是基于Bean Factory和ApplicationContext两个接口，其中ApplicationContext是Bean Factory的子接口之一，ApplicationContext对Bean Factory功能做了很多有用的拓展，所以大多数的工作场景下，都会使用ApplicationContext作为Spring IoC容器。 下图展示的是Spring相关的IoC容器接口的主要设计。 SpringIoC1 我们可以清晰地看到BeanFactory位于设计的最底层，它提供了Spring IoC最底层的设计，所以我们来看看它的源码： 12345678910111213141516171819202122232425262728293031323334353637383940package org.springframework.beans.factory;import org.springframework.beans.BeansException;import org.springframework.core.ResolvableType;import org.springframework.lang.Nullable;public interface BeanFactory &#123; String FACTORY_BEAN_PREFIX = "&amp;"; // getBean()的多个方法用于获取配置给Spring IoC容器的Bean。 Object getBean(String var1) throws BeansException; &lt;T&gt; T getBean(String var1, Class&lt;T&gt; var2) throws BeansException; Object getBean(String var1, Object... var2) throws BeansException; &lt;T&gt; T getBean(Class&lt;T&gt; var1) throws BeansException; &lt;T&gt; T getBean(Class&lt;T&gt; var1, Object... var2) throws BeansException; &lt;T&gt; ObjectProvider&lt;T&gt; getBeanProvider(Class&lt;T&gt; var1); &lt;T&gt; ObjectProvider&lt;T&gt; getBeanProvider(ResolvableType var1); boolean containsBean(String var1); // isSingleton用于判断是否单例 boolean isSingleton(String var1) throws NoSuchBeanDefinitionException; boolean isPrototype(String var1) throws NoSuchBeanDefinitionException; boolean isTypeMatch(String var1, ResolvableType var2) throws NoSuchBeanDefinitionException; // 按Java类型匹配的方式 boolean isTypeMatch(String var1, Class&lt;?&gt; var2) throws NoSuchBeanDefinitionException; @Nullable Class&lt;?&gt; getType(String var1) throws NoSuchBeanDefinitionException; //获取别名 String[] getAliases(String var1);&#125; 接下来我们来认识一个ApplicationContext的子类–ClassPathXmlApplicationContext，先创建一个applicationContext.xml文件：12345678&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:p="http://www.springframework.org/schema/p" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;bean id="userService" class="com.Kyrie.ioc.demo1.UserServiceImpl"&gt; &lt;property name="name" value="李四"/&gt; &lt;/bean&gt; &lt;/beans&gt; 这里定义了一个Bean，这样Spring IoC在初始化的时候就能找到它，然后使用ClassPathXmlApplicationContext容器就可以将其初始化，代码如下：1234567//创建工厂类BeanFactory beanFactory = new XmlBeanFactory(new ClassPathResource("applicationContext.xml"));//通过工厂获得类UserService userService = (UserService) beanFactory.getBean("userService");userService.sayHello(); 这样就会使用Application的实现类ClassPathXmlApplicationContext去初始化Spring IoC容器，然后开发者就可以通过IoC容器获得资源了。 Spring IoC容器的初始化和依赖注入Bean的定义和初始化在Spring IoC容器中是两大步骤，它是先定义，然后初始化和依赖注入的。 Bean的定义分为3步1.Resource定位，Spring IoC根据开发者的配置，进行资源定位。在Spring的开发中，通过XML或者注解都是十分常见的形式，定位的内容由开发者提供。2.BeanDefinition的载入，这个时候只是将Resource定位到的信息，保存到Bean定义（BeanDefinition）中，此时并不会创建Bean的实例。3.BeanDefinition的注册，这个过程就是将BeanDefinition的信息发布到Spring IoC中，要注意的是，此时仍旧没有对应的Bean实例创建。 初始化和依赖注入做完上述3步，Bean就在Spring IoC中被定义了，而没有被初始化。对于初始化和依赖注入，Spring Bean还有一个配置选项–lazy-init，其含义是是否初始化Spring Bean。在没有任何配置的情况下，它的默认值为default，实际值为false，也就是Spring IoC默认会初始化Bean。如果将其设置为true，那么只有我们使用Spring IoC容器的getBean方法获取它时，它才会进行Bean的初始化，完成依赖注入。 Spring Bean的生命周期生命周期主要是为了了解Spring IoC容器初始化和销毁Bean的过程，通过对它的学习就可以知道如何在初始化和销毁的时候加入自定义方法。 SpringIoC2 SpringIoC3]]></content>
      <categories>
        <category>Java乐园</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[选择Java接口还是抽象类]]></title>
    <url>%2F2019%2F03%2F30%2F%E9%80%89%E6%8B%A9Java%E6%8E%A5%E5%8F%A3%E8%BF%98%E6%98%AF%E6%8A%BD%E8%B1%A1%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[很多人有过这样的疑问：为什么有的地方必须使用接口而不是抽象类，而在另一些地方，又必须使用抽象类而不是接口呢？或者说，在考虑Java类的一般化问题时，很多人会在接口和抽象类之间犹豫不决，甚至随便选择一种。 实际上接口和抽象类的选择不是随心所欲的。要理解接口和抽象类的选择原则，有两个概念很重要：对象的行为和对象的实现。如果一个实体可以有多种实现方式，则在设计实体行为的描述方式时，应当达到这样一个目标：在使用实体的时候，无需详细了解实体行为的实现方式。也就是说，要把对象的行为和对象的实现分离开来。既然Java的接口和抽象类都可以定义不提供具体实现的方法，在分离对象的行为和对象的实现时，到底应该使用接口还是使用抽象类呢？ 通过抽象类建立行为模型 在接口和抽象类的选择上，必须遵守这样一个原则：行为模型应该总是通过接口而不是抽象类定义。为了说明其原因，下面试着通过抽象类建立行为模型，看看会出现什么问题。 假设要为销售部门设计一个软件，这个软件包含一个“发动机”（Motor）实体。显然无法在发动机对象中详细地描述发动机的方方面面，只能描述某些对当前软件来说重要的特征。至于发动机的哪些特征是重要的，则要与用户（销售部门）交流才能确定。 销售部门的人要求每一个发动机都有一个称为马力的参数。对于他们来说，这是惟一值得关心的参数。基于这一判断，可以把发动机的行为定义为以下行为。 行为1：查询发动机的马力，发动机将返回一个表示马力的整数。 虽然还不清楚发动机如何取得马力这个参数，但可以肯定发动机一定支持这个行为，而且这是所有发动机惟一值得关注的行为特征。这个行为特征既可以用接口定义，也可以用抽象类定义。为了说明用抽象类定义可能出现的问题，下面用抽象类建立发动机的行为模型，并用Java方法描述行为1，代码如下：123public abstract Motor&#123; abstract public int getHorsepower();&#125; 在Motor抽象类的基础上构造出多种具体实现，例如A型发动机、B型发动机等，再加上系统的其它部分，最后得到1.0版的软件并交付使用。一段时间过去了，要设计2.0版的软件。在评估2.0版软件需求的过程中，发现一小部分发动机是电池驱动的，而电池需要一定的充电时间。销售部门的人希望能够通过计算机查阅充电时间，并根据这一要求定义了一个新的行为。 行为2：查询电驱动发动机的充电时间，发动机将返回一个表示充电时间的整数。 用Java方法来描述这个行为，代码如下：123public abstract BatteryPoweredMotor extends Motor&#123; abstract public int getTimeToRecharge();&#125; 在销售部门的软件中，电驱动发动机也以类的形式实现，但这些类从BatteryPoweredMotor而不是Motor派生。这些改动加入到2.0版软件之后，销售部门很满意。随着业务的不断发展，不久之后光驱动的发动机出现了。销售部门要求光驱动发动机需要一定光能才能运转，光能以流明（Lumen）度量。这个信息对客户很重要，因为下雨或多云的天气里，某些光驱动发动机可能无法运转。销售部门要求为软件增加对光驱动发动机的支持，所以要定义一个新的行为。 行为3：查询光驱动发动机能够正常运转所需要的最小流明数，发动机返回一个整数。 再定义一个抽象类并把行为3转换成Java方法，代码如下：123public abstract SolarPoweredMotor extends Motor&#123; abstract public int getLumensToOperate();&#125; SolarPoweredMotor和BatteryPoweredMotor都从Motor抽象类派生。在整个软件中，90%以上的代码以相同的方式对待所有的发动机。偶尔需要检查一下发动机是光驱动还是电驱动，使用instanceof实现，代码如下：12if (instanceof SolarPoweredMotor)&#123;...&#125;if (instanceof BatteryPoweredMotor)&#123;...&#125; 无论是哪种发动机，马力这个参数都很重要，所以在所有派生的抽象类（SolarPoweredMotor和BatteryPoweredMotor）中，getHorsepower()方法都有效。 销售部门又有了一种新的发动机，它是一种既有电驱动又有光驱动的双重驱动发动机。光驱动和电驱动的行为本身没有变化，但新的发动机同时支持两种行为。在考虑如何定义新型的光电驱动发动机时，接口和抽象类的差别开始显示出来了。新的目标是在增加新型发动机的前提下尽量少改动代码。因为与光驱动发动机、电驱动发动机有关的代码已经过全面的测试，不存在已知的Bug。为了增加光电驱动发动机，要定义一个新的SolarBatteryPowered抽象类。如果让SolarBatteryPowered从Motor抽象类派生，SolarBatteryPowered将不支持针对光驱动发动机和电驱动发动机的instanceof操作。也就是说，如果查询一个光电驱动的发动机是光驱动的，还是电驱动的，得到的答案是：都不是。 如果让SolarBatteryPowered从SolarPoweredMotor（或BatteryPoweredMotor）抽象类派生，类似的问题也会出现，SolarBatteryPowered将不支持针对BatteryPoweredMotor（或SolarPoweredMotor）的instanceof操作。从行为上看，光电驱动的发动机必须同时从两个抽象类派生，但Java语言不允许多重继承。之所以会出现这个问题，根本的原因在于使用抽象类不仅意味着定义特定的行为，而且意味着定义实现的模式。也就是说，应该定义一个发动机如何获得行为的模型，而不仅仅是声明发动机具有某一个行为。 通过接口建立行为模型 如果用接口来建立行为模型，就可以避免隐含地规定实现模式。例如，前面的几个行为改用接口定义如下。行为1：123public interface Motor()&#123; public int getHorsepower();&#125; 行为2：123public interface BatteryPoweredMotor extends Motor()&#123; public int getTimeToRecharge();&#125; 行为3：123public interface SolarPoweredMotor extends Motor&#123; abstract public int getLumensToOperate();&#125; 光电驱动的发动机可以描述为：1public DualPoweredMotor implements SolarPoweredMotor, BatteryPoweredMotor&#123;&#125; DualPoweredMotor只继承行为定义，而不是行为的实现模式。 在使用接口的同时仍旧可以使用抽象类，不过这时抽象类的作用是实现行为，而不是定义行为。只要实现行为的类遵从接口定义，即使它改变了父抽象类，也不用改变其它代码与之交互的方式。特别是对于公用的实现代码，抽象类有它的优点。抽象类能够保证实现的层次关系，避免代码重复。然而，即使在使用抽象类的场合，也不要忽视通过接口定义行为模型的原则。从实践的角度来看，如果依赖于抽象类来定义行为，往往导致过于复杂的继承关系，而通过接口定义行为能够更有效地分离行为与实现，为代码的维护和修改带来方便。]]></content>
      <categories>
        <category>Java乐园</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Scanner]]></title>
    <url>%2F2019%2F03%2F30%2FScanner%2F</url>
    <content type="text"><![CDATA[上星期在蓝桥杯考场上发现一个之前没有注意到的问题：Scanner类中的nextInt()、next()、nextLine()方法的使用。首先没有注意到：next()方法读取字符串的时候在遇到空格、换行符的时候都会结束截止（在这里读取数据的时候，就已经宣告我这道题解不出了。。）比完赛后百度，原来可以用nextLine()，这样读取字符串遇到空格就不会截止，而是等到回车。于是就写了下面这段代码进行验证。12345678public class A&#123; public static void main(String[] args)&#123; Scanner sc = new Scanner(System.in); sc.nextInt(); String s = sc.nextLine(); System.out.print(s); &#125;&#125; 不过在输入第一个数字验证的时候呢出现了如下结果： Scanner1 输入字符串的机会都不给我。。 这时我猜想，可能是写入了一个空字符或者转义字符之类的。这个时候我们去看官方文档： nextInt(): it only reads the int value, nextInt() places the cursor in the same line after reading the input. next(): read the input only till the space. It can’t read two words separated by space. Also, next() places the cursor in the same line after reading the input. nextLine(): reads input including space between the words (that is, it reads till the end of line \n). Once the input is read, nextLine() positions the cursor in the next line. 每一次读取过程是从光标位置开始的。所以，一开始那个程序当我们输入4并按下回车，由于nextInt()方法只读取数值而不会读取换行符，所以光标停在了4和\n之间，于是nextLine()方法将4后面的换行符给读掉了，所以造成字符串s是一个换行符。 为了完成最后的输入，程序应该这样写：123456789public class A&#123; public static void main(String[] args)&#123; Scanner sc = new Scanner(System.in); sc.nextInt(); sc.nextLine(); //读取掉数字后面的换行符 String s = sc.nextLine(); System.out.println(s); &#125;&#125; 结果如下： Scanner2]]></content>
      <categories>
        <category>Java乐园</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[学习新知识的心得体会]]></title>
    <url>%2F2019%2F03%2F17%2F%E5%AD%A6%E4%B9%A0%E6%96%B0%E7%9F%A5%E8%AF%86%E7%9A%84%E5%BF%83%E5%BE%97%E4%BD%93%E4%BC%9A%2F</url>
    <content type="text"><![CDATA[看到一个大佬总结的经验，觉得很有道理，所以先码下来。 learningskill]]></content>
      <categories>
        <category>人生苦旅</category>
      </categories>
      <tags>
        <tag>learnSkill</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[背包问题]]></title>
    <url>%2F2019%2F02%2F26%2F%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[整理一下0-1背包、完全背包、多重背包问题。 背包问题01背包概述01背包是在M件物品取出若干件放在空间为W的背包里，每件物品的体积为W1，W2至Wn，与之相对应的价值为P1,P2至Pn。（这是最基础的背包问题） 思路在前n件物品中，选取若干件物品放入所剩空间为w的背包中的所能获得的最大价值。（实际上是对一件件物品选与不选的问题）我们用f[i][j]表示在前 i 件物品中选择若干件放在已用空间为 j 的背包里所能获得的最大价值对一个物体，只有两种情况： 选：f[i][j] = f[i - 1][j - W[i]] + P[i] 不选：f[i][j] = f[i - 1][j] 由此可以得到状态转移方程：f[i][j] = max(f[i - 1][j - W[i]] + P[i], f[i - 1][j]); 代码12345678910111213141516171819202122232425262728293031/** * @param m 表示背包的容量 * @param n 表示物品的个数 * @param w 表示物品所占空间 * @param p 表示物品的价值**/public static int[][] backpack01(int m,int n,int[] w,int[] p)&#123; //f[i][v]表示前i件物品恰放入一个容量为m的背包可以获得的最大价值 int[][] f = new int[n + 1][m + 1]; for(int i = 0; i &lt; n + 1; i++)&#123; f[i][0] = 0; &#125; for(int j = 0; j &lt; m + 1; j++)&#123; f[0][j] = 0; &#125; for(int i = 1; i &lt; n + 1; i++)&#123; for(int j = 1; j &lt; m + 1; j++)&#123; if(w[i - 1] &lt;= j)&#123; //物品所占空间小于剩余空间，w[i-1]中i-1是对应数组w中的取值，下面w[i-1]p[i-1]同理 if(f[i - 1][j] &lt; f[i - 1][j - w[i - 1]] + p[i - 1])&#123; f[i][j] = f[i - 1][j - w[i - 1]] + p[i - 1]; &#125;else&#123; f[i][j] = f[i - 1][j]; &#125; &#125;else&#123; f[i][j] = f[i - 1][j]; &#125; &#125; &#125; return f;&#125; 完全背包概述完全背包问题跟01背包的区别是01背包每个物品只能选一次，总共就这几个，而完全背包问题是每个物品可以无限选，只要装得下。可以看成是有几种物品，每种都无限多个。 思路01背包在选第i个物品时，容积够用情况下，只有2种状态可选，放还是不放，找出最大价值的选择而完全背包在选第i种物品时，容积够用情况下，可能有2种以上状态可选，放1个，或者2个，3个，或者不放。找出最大价值的选择可以利用k = j/w[i]算出最多可以放几个，然后状态转移方程改为f[i][j] = max(f[i - 1][j - k*w[m]] + k * p[i]) 从0到k遍历一遍求出最大值即可 代码12345678910111213141516171819202122232425262728293031323334/** * @param m 表示背包的容量 * @param n 表示物品的个数 * @param w 表示物品所占空间 * @param p 表示物品的价值**/ //f[i][v]表示前i件物品恰放入一个容量为m的背包可以获得的最大价值 public static int[][] backpack02(int m,int n,int[] w,int[] p)&#123; int[][] f = new int[n + 1][m + 1]; //初始化边界 for(int i = 0; i &lt; n + 1; i++)&#123; f[i][0] = 0; &#125; for(int j = 0; j &lt; m + 1; j++)&#123; f[0][j] = 0; &#125; for(int i = 1; i &lt; n + 1; i++)&#123; for(int j = 1; j &lt; m + 1; j++)&#123; if(w[i - 1] &lt;= j)&#123; int k = j / w[i - 1]; for(int t = 0; t &lt; k + 1; t++)&#123; if(f[i - 1][j - t * w[i - 1]] + t * p[i - 1] &gt; f[i][j])&#123; f[i][j] = f[i - 1][j - t * w[i - 1]] + t * p[i - 1]; &#125; &#125; &#125;else&#123; f[i][j] = f[i - 1][j]; &#125; &#125; &#125; return f; &#125; 多重背包概述与“完全背包”相比，在每个物品的选取次数上给出了限定，即选取次数k不能无限的增大 思路其实与完全背包相似，只是k的限定条件发生了变化。 代码1234567891011121314151617181920212223242526272829303132/** * @param m 表示背包的容量 * @param n 表示物品的个数 * @param w 表示物品所占空间 * @param p 表示物品的价值 * @param num 表示物品的数量**/ //f[i][v]表示前i件物品恰放入一个容量为m的背包可以获得的最大价值 public static int[][] backpack03(int m,int n,int[] w,int[] p,int[] num)&#123; int[][] f = new int[n + 1][m + 1]; //初始化边界 for(int i = 0; i &lt; n + 1; i++)&#123; f[i][0] = 0; &#125; for(int j = 0; j &lt; m + 1; j++)&#123; f[0][j] = 0; &#125; for(int i = 1; i &lt; n + 1; i++) &#123; //遍历每个物品 for (int j = 1; j &lt; m + 1; j++) &#123; for (int k = 0; (k &lt;= num[i - 1]) &amp;&amp; (k &gt;= 0); k++) &#123; if (j &gt; k * w[i - 1]) &#123; if (f[i - 1][j - k * w[i - 1]] + k * p[i - 1] &gt; f[i][j]) &#123; f[i][j] = f[i - 1][j - k * w[i - 1]] + k * p[i - 1]; &#125; &#125; &#125; &#125; &#125; return f; &#125;]]></content>
      <categories>
        <category>Algorithms</category>
      </categories>
      <tags>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Manacher算法]]></title>
    <url>%2F2019%2F02%2F13%2FManacher%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[查找一个字符串的最长回文子串的线性算法。 Manacher算法部分转载自：http://blog.csdn.net/dyx404514/article/details/42061017 概述Manacher算法是查找一个字符串的最长回文子串的线性算法。 在介绍算法之前，首先介绍一下什么是回文串，所谓回文串，简单来说就是正着读和反着读都是一样的字符串，比如abba，noon等等，一个字符串的最长回文子串即为这个字符串的子串中，是回文串的最长的那个。 Manacher算法的原理与实现下面介绍Manacher算法的原理与步骤。 首先，Manacher算法提供了一种巧妙地办法，将长度为奇数的回文串和长度为偶数的回文串一起考虑，具体做法是，在原字符串的每个相邻两个字符中间插入一个分隔符，同时在首尾也要添加一个分隔符，分隔符的要求是不在原串中出现，一般情况下可以用#号。下面举一个例子： Manacher1 Len数组简介与性质 Manacher算法用一个辅助数组Len[i]表示以字符T[i]为中心的最长回文字串的最右字符到T[i]的长度，比如以T[i]为中心的最长回文字串是T[l,r],那么Len[i]=r-i+1。 对于上面的例子，可以得出Len[i]数组为: Manacher2 Len数组有一个性质，那就是Len[i]-1就是该回文子串在原字符串S中的长度，至于证明，首先在转换得到的字符串T中，所有的回文字串的长度都为奇数，那么对于以T[i]为中心的最长回文字串，其长度就为2*Len[i]-1,经过观察可知，T中所有的回文子串，其中分隔符的数量一定比其他字符的数量多1，也就是有Len[i]个分隔符，剩下Len[i]-1个字符来自原字符串，所以该回文串在原字符串中的长度就为Len[i]-1。 有了这个性质，那么原问题就转化为求所有的Len[i]。下面介绍如何在线性时间复杂度内求出所有的Len。 Len数组的计算 首先从左往右依次计算Len[i]，当计算Len[i]时，Lenj已经计算完毕。设P为之前计算中最长回文子串的右端点的最大值，并且设取得这个最大值的位置为po，分两种情况： 第一种情况：i&lt;=P 那么找到i相对于po的对称位置，设为j，那么如果Len[j]&lt;P-i，如下图： Manacher3 那么说明以j为中心的回文串一定在以po为中心的回文串的内部，且j和i关于位置po对称，由回文串的定义可知，一个回文串反过来还是一个回文串，所以以i为中心的回文串的长度至少和以j为中心的回文串一样，即Len[i]&gt;=Len[j]。因为Len[j]&lt;P-i,所以说i+Len[j]&lt;P。由对称性可知Len[i]=Len[j]。 如果Len[j]&gt;=P-i,由对称性，说明以i为中心的回文串可能会延伸到P之外，而大于P的部分我们还没有进行匹配，所以要从P+1位置开始一个一个进行匹配，直到发生失配，从而更新P和对应的po以及Len[i]。 Manacher4 第二种情况: i&gt;P 如果i比P还要大，说明对于中点为i的回文串还一点都没有匹配，这个时候，就只能老老实实地一个一个匹配了，匹配完成后要更新P的位置和对应的po以及Len[i]。 Manacher5 时间复杂度分析Manacher算法的时间复杂度分析和Z算法类似，因为算法只有遇到还没有匹配的位置时才进行匹配，已经匹配过的位置不再进行匹配，所以对于T字符串中的每一个位置，只进行一次匹配，所以Manacher算法的总体时间复杂度为O(n)，其中n为T字符串的长度，由于T的长度事实上是S的两倍，所以时间复杂度依然是线性的。 下面是算法的实现，注意，为了避免更新P的时候导致越界，我们在字符串T的前增加一个特殊字符，比如说‘$’,所以算法中字符串是从1开始的。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class Solution2 &#123; private String s;//原字符串 private char[] temp;//转换后的字符数组 private int[] len; public String Manacher(String str) &#123; s = str; ChangeToTemp();// 将s转换为temp数组 len = new int[2 * s.length() + 3]; int max = 0;//max为当前回文串最右边字符的最大值 int p0 = 0;//p0为当前回文字符串的中间值 for(int i = 1; i &lt; 2 * s.length() + 3; i++) &#123; if(max &gt; i) len[i] = Math.min(max - i, len[2 * p0 - i]);//在len[j]和max-i中取小值 else len[i] = 1;//如果i&gt;max，要从头开始匹配 while((i - len[i]) &gt; 0 &amp;&amp; (i + len[i]) &lt; 2 * s.length() + 3 &amp;&amp; temp[i - len[i]] == temp[i + len[i]]) len[i]++; if(len[i] + i &gt; max) &#123;//若新计算的回文串右端点的位置大于max，就要更新p0和max的值 max = len[i] + i; p0 = i; &#125; &#125; //输出最长回文串 int lenth = 0; int center = 0; for(int i = 0; i &lt; len.length; i++) &#123; if(len[i] &gt; lenth) &#123; lenth = len[i]; center = i; &#125; &#125; return s.substring((center - lenth) / 2, (center - 1 + lenth) / 2); &#125; private void ChangeToTemp() &#123; temp = new char[s.length() * 2 + 3]; temp[0] = '$';//为字符数组开头增加一个特殊字符，防止越界 for(int i = 0; i &lt; s.length(); i++) &#123; temp[2 * i + 1] = '#'; temp[2 * i + 2] = s.charAt(i); &#125; temp[2 * s.length() + 1] = '#'; temp[2 * s.length() + 2] = '*';//结尾加一个特殊字符，防止越界 &#125;&#125; 拓展中心扩展算法马拉车算法是一个非同寻常的算法，在45分钟的编码时间内提出这个算法将会是一个不折不扣的挑战，这里我们也提供另一种算法：中心扩展算法。 事实上，只需使用恒定的空间，我们就可以在 O(n2) 的时间内解决这个问题。 我们观察到回文中心的两侧互为镜像。因此，回文可以从它的中心展开，并且只有 2n - 1 个这样的中心。 你可能会问，为什么会是 2n - 1 个，而不是 n 个中心？原因在于所含字母数为偶数的回文的中心可以处于两字母之间（例如 “abba” 的中心在两个 ‘b’ 之间）。 12345678910111213141516171819202122232425Class Solution&#123; public String longestPalindrome(String s) &#123; if (s == null || s.length() &lt; 1) return ""; int start = 0, end = 0; for (int i = 0; i &lt; s.length(); i++) &#123; int len1 = expandAroundCenter(s, i, i); int len2 = expandAroundCenter(s, i, i + 1); int len = Math.max(len1, len2); if (len &gt; end - start) &#123; start = i - (len - 1) / 2; end = i + len / 2; &#125; &#125; return s.substring(start, end + 1); &#125; private int expandAroundCenter(String s, int left, int right) &#123; int L = left, R = right; while (L &gt;= 0 &amp;&amp; R &lt; s.length() &amp;&amp; s.charAt(L) == s.charAt(R)) &#123; L--; R++; &#125; return R - L - 1; &#125;&#125; 时间复杂度：O(n2)， 由于围绕中心来扩展回文会耗去 O(n) 的时间，所以总的复杂度为O(n2) 。]]></content>
      <categories>
        <category>Algorithms</category>
      </categories>
      <tags>
        <tag>字符串</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[滑动窗口]]></title>
    <url>%2F2019%2F02%2F13%2F%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%2F</url>
    <content type="text"><![CDATA[滑动窗口是数组/字符串问题中常用的抽象概念。今天我们通过一道算法题目来理解一下滑动窗口。 滑动窗口滑动窗口是数组/字符串问题中常用的抽象概念。今天我们通过一道算法题目来理解一下滑动窗口。 经典实例给定一个字符串，请你找出其中不含有重复字符的最长子串的长度。123输入: &quot;abcabcbb&quot;输出: 3 解释: 因为无重复字符的最长子串是 &quot;abc&quot;，所以其长度为 3。 暴力算法思路逐个检查所有的子字符串，看它是否不含有重复的字符。 代码1234567891011121314151617181920public class Solution &#123; public int lengthOfLongestSubstring(String s) &#123; int n = s.length(); int ans = 0; for (int i = 0; i &lt; n; i++) for (int j = i + 1; j &lt;= n; j++) if (allUnique(s, i, j)) ans = Math.max(ans, j - i); return ans; &#125; public boolean allUnique(String s, int start, int end) &#123; Set&lt;Character&gt; set = new HashSet&lt;&gt;(); for (int i = start; i &lt; end; i++) &#123; Character ch = s.charAt(i); if (set.contains(ch)) return false; set.add(ch); &#125; return true; &#125;&#125; 其时间复杂度为O(n3)，在暴力法中，我们会反复检查一个子字符串是否含有有重复的字符，但这是没有必要的。如果从索引 i 到 j−1 之间的子字符串 sij已经被检查为没有重复字符。我们只需要检查 s[j] 对应的字符是否已经存在于子字符串 sij 中。 滑动窗口思路 窗口通常是在数组/字符串中由开始和结束索引定义的一系列元素的集合，即 [i, j)（左闭，右开）。而滑动窗口是可以将两个边界向某一方向“滑动”的窗口。例如，我们将 [i, j) 向右滑动 1 个元素，则它将变为 [i+1, j+1)（左闭，右开）。 通过使用 HashSet 作为滑动窗口，我们可以用 O(1)的时间来完成对字符是否在当前的子字符串中的检查。我们使用 HashSet 将字符存储在当前窗口 [i, j)（最初 j = i）中。 然后我们向右侧滑动索引 j，如果它不在 HashSet 中，我们会继续滑动 j。直到 s[j] 已经存在于 HashSet 中。此时，我们找到的没有重复字符的最长子字符串将会以索引i 开头。如果我们对所有的 i 这样做，就可以得到答案。 代码123456789101112131415161718class Solution &#123; public int lengthOfLongestSubstring(String s) &#123; int n = s.length(); Set&lt;Character&gt; set = new HashSet&lt;&gt;(); int ans = 0, i = 0, j = 0; while (i &lt; n &amp;&amp; j &lt; n) &#123; //滑动窗口 // try to extend the range [i, j] if (!set.contains(s.charAt(j)))&#123; set.add(s.charAt(j++)); ans = Math.max(ans, j - i); &#125; else &#123; set.remove(s.charAt(i++)); &#125; &#125; return ans; &#125;&#125; 其时间复杂度为O(2n) = O(n)，事实上，它可以被进一步优化为仅需要 n 个步骤。我们可以定义字符到索引的映射，而不是使用集合来判断一个字符是否存在。 当我们找到重复的字符时，我们可以立即跳过该窗口。 优化后的滑动窗口思路如果 s[j] 在 [i, j) 范围内有与 j’重复的字符，我们不需要逐渐增加 i 。 我们可以直接跳过 [i，j’]范围内的所有元素，并将 i 变为 j’ + 1。 代码123456789101112131415public class Solution &#123; public int lengthOfLongestSubstring(String s) &#123; int n = s.length(), ans = 0; Map&lt;Character, Integer&gt; map = new HashMap&lt;&gt;(); // current index of character // try to extend the range [i, j] for (int j = 0, i = 0; j &lt; n; j++) &#123; if (map.containsKey(s.charAt(j))) &#123; i = Math.max(map.get(s.charAt(j)), i); &#125; ans = Math.max(ans, j - i + 1); map.put(s.charAt(j), j + 1); &#125; return ans; &#125;&#125; 其时间复杂度为O(n)。]]></content>
      <categories>
        <category>Algorithms</category>
      </categories>
      <tags>
        <tag>字符串</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[理解Java的多态性]]></title>
    <url>%2F2019%2F02%2F12%2F%E7%90%86%E8%A7%A3java%E7%9A%84%E5%A4%9A%E6%80%81%E6%80%A7%2F</url>
    <content type="text"><![CDATA[运行时多态性是面向对象程序设计代码重用的一个最强大机制，动态性的概念也可以被说成“一个接口，多个方法”。Java实现运行时多态性的基础是动态方法调度，它是一种在运行时而不是在编译期调用重载方法的机制。 理解java的多态性参考自：https://blog.csdn.net/thinkGhoster/article/details/2307001 经典实例1234567891011121314151617181920212223242526272829303132333435363738class A &#123; public String show(D obj)&#123; return ("A and D"); &#125; public String show(A obj)&#123; return ("A and A"); &#125; &#125; class B extends A&#123; public String show(B obj)&#123; return ("B and B"); &#125; public String show(A obj)&#123; return ("B and A"); &#125; &#125;class C extends B&#123;&#125; class D extends B&#123;&#125; public class Test &#123; public static void main(String[] args) &#123; A a1 = new A(); A a2 = new B(); B b = new B(); C c = new C(); D d = new D(); System.out.println("1--" + a1.show(b)); System.out.println("2--" + a1.show(c)); System.out.println("3--" + a1.show(d)); System.out.println("4--" + a2.show(b)); System.out.println("5--" + a2.show(c)); System.out.println("6--" + a2.show(d)); System.out.println("7--" + b.show(b)); System.out.println("8--" + b.show(c)); System.out.println("9--" + b.show(d)); &#125;&#125; 运行结果：1234567891--A and A2--A and A3--A and D4--B and A5--B and A6--A and D7--B and B8--B and B9--A and D 我们先来复习一下多态性运行时多态性是面向对象程序设计代码重用的一个最强大机制，动态性的概念也可以被说成“一个接口，多个方法”。Java实现运行时多态性的基础是动态方法调度，它是一种在运行时而不是在编译期调用重载方法的机制。 方法的重写（Overriding）和重载（Overloading）是Java多态性的不同表现。重写（Overriding）是父类与子类之间多态性的一种表现，重载（Overloading）是一个类中多态性的一种表现。如果在子类中定义某方法与其父类有相同的名称和参数，我们说该方法被重写(Overriding)。子类的对象使用这个方法时，将调用子类中的定义，对它而言，父类中的定义如同被“屏蔽”了。如果在一个类中定义了多个同名的方法，它们或有不同的参数个数或有不同的参数类型，则称为方法的重载(Overloading)。重载（Overloading）的方法是可以改变返回值的类型。 当超类对象引用变量引用子类对象时，是被引用对象的类型而不是引用变量的类型决定了调用谁的成员方法，但是这个被调用的方法必须是在超类中定义过的，也就是说被子类覆盖的方法。 分析例题例题实际上涉及到了方法调用的优先问题： this.show(O)、super.show(O)、this.show((super)O)、super.show((super)O). 我们看看 4 – a2.show(b)。a2是一个引用变量，类型是A，则this是a2，b是B的一个实例，于是它到类A里面找show(B obj)方法，没有找到，于是到A的super(超类)找，而A没有超类，因此转到第三优先级this.show((super)O)，this仍然是a2，这里O为B，(super)O即(super)B即A，因此它到类A里面找show(A obj)的方法，类A有这个方法，但是由于a2引用的是类B的一个对象，B覆盖了A的show(A obj)方法，因此最终锁定到类B的show(A obj)，输出为”B and A”。 再看看 8 – b.show(c)。b是一个引用变量，类型为B，则this为b，c是C的一个实例，于是它到类B找show(C obj)方法，没有找到，转而到B的超类A里面找，A里面也没有，因此也转到第三优先级this.show((super)O)，this为b，O为C，(super)O即(super)C即B，因此它到B里面找show(B obj)方法，找到了，由于b引用的是类B的一个对象，因此直接锁定到类B的show(B obj)，输出为”B and B”。 按照上面的方法，可以正确得到其他的结果。]]></content>
      <categories>
        <category>Java乐园</category>
      </categories>
      <tags>
        <tag>多态</tag>
      </tags>
  </entry>
</search>
